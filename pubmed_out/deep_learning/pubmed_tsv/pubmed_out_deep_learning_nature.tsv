Authors	Title	Journal	Year	Publication_citation	Abstract	Keywords	Date_epublished	PMID
Shi, Liang; Li, Beichen; Kim, Changil; Kellnhofer, Petr; Matusik, Wojciech	Towards real-time photorealistic 3D holography with deep neural networks.	Nature	2021	Nature. 2021 Mar;591(7849):234-239. doi: 10.1038/s41586-020-03152-0. Epub 2021 Mar 10.	The ability to present three-dimensional (3D) scenes with continuous depth sensation has a profound impact on virtual and augmented reality, human-computer interaction, education and training. Computer-generated holography (CGH) enables high-spatio-angular-resolution 3D projection via numerical simulation of diffraction and interference(1). Yet, existing physically based methods fail to produce holograms with both per-pixel focal control and accurate occlusion(2,3). The computationally taxing Fresnel diffraction simulation further places an explicit trade-off between image quality and runtime, making dynamic holography impractical(4). Here we demonstrate a deep-learning-based CGH pipeline capable of synthesizing a photorealistic colour 3D hologram from a single RGB-depth image in real time. Our convolutional neural network (CNN) is extremely memory efficient (below 620 kilobytes) and runs at 60 hertz for a resolution of 1,920 x 1,080 pixels on a single consumer-grade graphics processing unit. Leveraging low-power on-device artificial intelligence acceleration chips, our CNN also runs interactively on mobile (iPhone 11 Pro at 1.1 hertz) and edge (Google Edge TPU at 2.0 hertz) devices, promising real-time performance in future-generation virtual and augmented-reality mobile headsets. We enable this pipeline by introducing a large-scale CGH dataset (MIT-CGH-4K) with 4,000 pairs of RGB-depth images and corresponding 3D holograms. Our CNN is trained with differentiable wave-based loss functions(5) and physically approximates Fresnel diffraction. With an anti-aliasing phase-only encoding method, we experimentally demonstrate speckle-free, natural-looking, high-resolution 3D holograms. Our learning-based approach and the Fresnel hologram dataset will help to unlock the full potential of holography and enable applications in metasurface design(6,7), optical and acoustic tweezer-based microscopic manipulation(8-10), holographic microscopy(11) and single-exposure volumetric 3D printing(12,13).		20210310	https://pubmed.ncbi.nlm.nih.gov/33692557
Ou, Xiangyu; Qin, Xian; Huang, Bolong; Zan, Jie; Wu, Qinxia; Hong, Zhongzhu; Xie, Lili; Bian, Hongyu; Yi, Zhigao; Chen, Xiaofeng; Wu, Yiming; Song, Xiaorong; Li, Juan; Chen, Qiushui; Yang, Huanghao; Liu, Xiaogang	High-resolution X-ray luminescence extension imaging.	Nature	2021	Nature. 2021 Feb;590(7846):410-415. doi: 10.1038/s41586-021-03251-6. Epub 2021 Feb 17.	Current X-ray imaging technologies involving flat-panel detectors have difficulty in imaging three-dimensional objects because fabrication of large-area, flexible, silicon-based photodetectors on highly curved surfaces remains a challenge(1-3). Here we demonstrate ultralong-lived X-ray trapping for flat-panel-free, high-resolution, three-dimensional imaging using a series of solution-processable, lanthanide-doped nanoscintillators. Corroborated by quantum mechanical simulations of defect formation and electronic structures, our experimental characterizations reveal that slow hopping of trapped electrons due to radiation-triggered anionic migration in host lattices can induce more than 30 days of persistent radioluminescence. We further demonstrate X-ray luminescence extension imaging with resolution greater than 20 line pairs per millimetre and optical memory longer than 15 days. These findings provide insight into mechanisms underlying X-ray energy conversion through enduring electron trapping and offer a paradigm to motivate future research in wearable X-ray detectors for patient-centred radiography and mammography, imaging-guided therapeutics, high-energy physics and deep learning in radiology.		20210217	https://pubmed.ncbi.nlm.nih.gov/33597760
Perkel, Jeffrey M	Ten computer codes that transformed science.	Nature	2021	Nature. 2021 Jan;589(7842):344-348. doi: 10.1038/d41586-021-00075-2.	?	Computer science; Mathematics and computing; Software; Technology	?	https://pubmed.ncbi.nlm.nih.gov/33473232
Cowen, Alan S; Keltner, Dacher; Schroff, Florian; Jou, Brendan; Adam, Hartwig; Prasad, Gautam	Sixteen facial expressions occur in similar contexts worldwide.	Nature	2021	Nature. 2021 Jan;589(7841):251-257. doi: 10.1038/s41586-020-3037-7. Epub 2020 Dec 16.	Understanding the degree to which human facial expressions co-vary with specific social contexts across cultures is central to the theory that emotions enable adaptive responses to important challenges and opportunities(1-6). Concrete evidence linking social context to specific facial expressions is sparse and is largely based on survey-based approaches, which are often constrained by language and small sample sizes(7-13). Here, by applying machine-learning methods to real-world, dynamic behaviour, we ascertain whether naturalistic social contexts (for example, weddings or sporting competitions) are associated with specific facial expressions(14) across different cultures. In two experiments using deep neural networks, we examined the extent to which 16 types of facial expression occurred systematically in thousands of contexts in 6 million videos from 144 countries. We found that each kind of facial expression had distinct associations with a set of contexts that were 70% preserved across 12 world regions. Consistent with these associations, regions varied in how frequently different facial expressions were produced as a function of which contexts were most salient. Our results reveal fine-grained patterns in human facial expressions that are preserved across the modern world.		20201216	https://pubmed.ncbi.nlm.nih.gov/33328631
Callaway, Ewen	'It will change everything': DeepMind's AI makes gigantic leap in solving protein structures.	Nature	2020	Nature. 2020 Dec;588(7837):203-204. doi: 10.1038/d41586-020-03348-4.	?	Computational biology and bioinformatics; Drug discovery; Structural biology	?	https://pubmed.ncbi.nlm.nih.gov/33257889
Brandt, Martin; Tucker, Compton J; Kariryaa, Ankit; Rasmussen, Kjeld; Abel, Christin; Small, Jennifer; Chave, Jerome; Rasmussen, Laura Vang; Hiernaux, Pierre; Diouf, Abdoul Aziz; Kergoat, Laurent; Mertz, Ole; Igel, Christian; Gieseke, Fabian; Schoning, Johannes; Li, Sizhuo; Melocik, Katherine; Meyer, Jesse; Sinno, Scott; Romero, Eric; Glennie, Erin; Montagu, Amandine; Dendoncker, Morgane; Fensholt, Rasmus	An unexpectedly large count of trees in the West African Sahara and Sahel.	Nature	2020	Nature. 2020 Nov;587(7832):78-82. doi: 10.1038/s41586-020-2824-5. Epub 2020 Oct 14.	A large proportion of dryland trees and shrubs (hereafter referred to collectively as trees) grow in isolation, without canopy closure. These non-forest trees have a crucial role in biodiversity, and provide ecosystem services such as carbon storage, food resources and shelter for humans and animals(1,2). However, most public interest relating to trees is devoted to forests, and trees outside of forests are not well-documented(3). Here we map the crown size of each tree more than 3 m(2) in size over a land area that spans 1.3 million km(2) in the West African Sahara, Sahel and sub-humid zone, using submetre-resolution satellite imagery and deep learning(4). We detected over 1.8 billion individual trees (13.4 trees per hectare), with a median crown size of 12 m(2), along a rainfall gradient from 0 to 1,000 mm per year. The canopy cover increases from 0.1% (0.7 trees per hectare) in hyper-arid areas, through 1.6% (9.9 trees per hectare) in arid and 5.6% (30.1 trees per hectare) in semi-arid zones, to 13.3% (47 trees per hectare) in sub-humid areas. Although the overall canopy cover is low, the relatively high density of isolated trees challenges prevailing narratives about dryland desertification(5-7), and even the desert shows a surprisingly high tree density. Our assessment suggests a way to monitor trees outside of forests globally, and to explore their role in mitigating degradation, climate change and poverty.		20201014	https://pubmed.ncbi.nlm.nih.gov/33057199
Muller, Johannes B; Geyer, Philipp E; Colaco, Ana R; Treit, Peter V; Strauss, Maximilian T; Oroshi, Mario; Doll, Sophia; Virreira Winter, Sebastian; Bader, Jakob M; Kohler, Niklas; Theis, Fabian; Santos, Alberto; Mann, Matthias	The proteome landscape of the kingdoms of life.	Nature	2020	Nature. 2020 Jun;582(7813):592-596. doi: 10.1038/s41586-020-2402-x. Epub 2020 Jun 17.	Proteins carry out the vast majority of functions in all biological domains, but for technological reasons their large-scale investigation has lagged behind the study of genomes. Since the first essentially complete eukaryotic proteome was reported(1), advances in mass-spectrometry-based proteomics(2) have enabled increasingly comprehensive identification and quantification of the human proteome(3-6). However, there have been few comparisons across species(7,8), in stark contrast with genomics initiatives(9). Here we use an advanced proteomics workflow-in which the peptide separation step is performed by a microstructured and extremely reproducible chromatographic system-for the in-depth study of 100 taxonomically diverse organisms. With two million peptide and 340,000 stringent protein identifications obtained in a standardized manner, we double the number of proteins with solid experimental evidence known to the scientific community. The data also provide a large-scale case study for sequence-based machine learning, as we demonstrate by experimentally confirming the predicted properties of peptides from Bacteroides uniformis. Our results offer a comparative view of the functional organization of organisms across the entire evolutionary range. A remarkably high fraction of the total proteome mass in all kingdoms is dedicated to protein homeostasis and folding, highlighting the biological challenge of maintaining protein structure in all branches of life. Likewise, a universally high fraction is involved in supplying energy resources, although these pathways range from photosynthesis through iron sulfur metabolism to carbohydrate metabolism. Generally, however, proteins and proteomes are remarkably diverse between organisms, and they can readily be explored and functionally compared at www.proteomesoflife.org.		20200617	https://pubmed.ncbi.nlm.nih.gov/32555458
Landhuis, Esther	Deep learning takes on tumours.	Nature	2020	Nature. 2020 Apr;580(7804):551-553. doi: 10.1038/d41586-020-01128-8.	?	Cancer; Computational biology and bioinformatics; Computer science; Microscopy	?	https://pubmed.ncbi.nlm.nih.gov/32317799
Chabon, Jacob J; Hamilton, Emily G; Kurtz, David M; Esfahani, Mohammad S; Moding, Everett J; Stehr, Henning; Schroers-Martin, Joseph; Nabet, Barzin Y; Chen, Binbin; Chaudhuri, Aadel A; Liu, Chih Long; Hui, Angela B; Jin, Michael C; Azad, Tej D; Almanza, Diego; Jeon, Young-Jun; Nesselbush, Monica C; Co Ting Keh, Lyron; Bonilla, Rene F; Yoo, Christopher H; Ko, Ryan B; Chen, Emily L; Merriott, David J; Massion, Pierre P; Mansfield, Aaron S; Jen, Jin; Ren, Hong Z; Lin, Steven H; Costantino, Christina L; Burr, Risa; Tibshirani, Robert; Gambhir, Sanjiv S; Berry, Gerald J; Jensen, Kristin C; West, Robert B; Neal, Joel W; Wakelee, Heather A; Loo, Billy W Jr; Kunder, Christian A; Leung, Ann N; Lui, Natalie S; Berry, Mark F; Shrager, Joseph B; Nair, Viswam S; Haber, Daniel A; Sequist, Lecia V; Alizadeh, Ash A; Diehn, Maximilian	Integrating genomic features for non-invasive early lung cancer detection.	Nature	2020	Nature. 2020 Apr;580(7802):245-251. doi: 10.1038/s41586-020-2140-0. Epub 2020 Mar 25.	Radiologic screening of high-risk adults reduces lung-cancer-related mortality(1,2); however, a small minority of eligible individuals undergo such screening in the United States(3,4). The availability of blood-based tests could increase screening uptake. Here we introduce improvements to cancer personalized profiling by deep sequencing (CAPP-Seq)(5), a method for the analysis of circulating tumour DNA (ctDNA), to better facilitate screening applications. We show that, although levels are very low in early-stage lung cancers, ctDNA is present prior to treatment in most patients and its presence is strongly prognostic. We also find that the majority of somatic mutations in the cell-free DNA (cfDNA) of patients with lung cancer and of risk-matched controls reflect clonal haematopoiesis and are non-recurrent. Compared with tumour-derived mutations, clonal haematopoiesis mutations occur on longer cfDNA fragments and lack mutational signatures that are associated with tobacco smoking. Integrating these findings with other molecular features, we develop and prospectively validate a machine-learning method termed 'lung cancer likelihood in plasma' (Lung-CLiP), which can robustly discriminate early-stage lung cancer patients from risk-matched controls. This approach achieves performance similar to that of tumour-informed ctDNA detection and enables tuning of assay specificity in order to facilitate distinct clinical applications. Our findings establish the potential of cfDNA for lung cancer screening and highlight the importance of risk-matching cases and controls in cfDNA-based screening studies.		20200325	https://pubmed.ncbi.nlm.nih.gov/32269342
Ouyang, David; He, Bryan; Ghorbani, Amirata; Yuan, Neal; Ebinger, Joseph; Langlotz, Curtis P; Heidenreich, Paul A; Harrington, Robert A; Liang, David H; Ashley, Euan A; Zou, James Y	Video-based AI for beat-to-beat assessment of cardiac function.	Nature	2020	Nature. 2020 Apr;580(7802):252-256. doi: 10.1038/s41586-020-2145-8. Epub 2020 Mar 25.	Accurate assessment of cardiac function is crucial for the diagnosis of cardiovascular disease(1), screening for cardiotoxicity(2) and decisions regarding the clinical management of patients with a critical illness(3). However, human assessment of cardiac function focuses on a limited sampling of cardiac cycles and has considerable inter-observer variability despite years of training(4,5). Here, to overcome this challenge, we present a video-based deep learning algorithm-EchoNet-Dynamic-that surpasses the performance of human experts in the critical tasks of segmenting the left ventricle, estimating ejection fraction and assessing cardiomyopathy. Trained on echocardiogram videos, our model accurately segments the left ventricle with a Dice similarity coefficient of 0.92, predicts ejection fraction with a mean absolute error of 4.1% and reliably classifies heart failure with reduced ejection fraction (area under the curve of 0.97). In an external dataset from another healthcare system, EchoNet-Dynamic predicts the ejection fraction with a mean absolute error of 6.0% and classifies heart failure with reduced ejection fraction with an area under the curve of 0.96. Prospective evaluation with repeated human measurements confirms that the model has variance that is comparable to or less than that of human experts. By leveraging information across multiple cardiac cycles, our model can rapidly identify subtle changes in ejection fraction, is more reproducible than human evaluation and lays the foundation for precise diagnosis of cardiovascular disease in real time. As a resource to promote further innovation, we also make publicly available a large dataset of 10,030 annotated echocardiogram videos.		20200325	https://pubmed.ncbi.nlm.nih.gov/32269341
AlQuraishi, Mohammed	A watershed moment for protein structure prediction.	Nature	2020	Nature. 2020 Jan;577(7792):627-628. doi: 10.1038/d41586-019-03951-0.	?	Computational biology and bioinformatics	?	https://pubmed.ncbi.nlm.nih.gov/31988401
Senior, Andrew W; Evans, Richard; Jumper, John; Kirkpatrick, James; Sifre, Laurent; Green, Tim; Qin, Chongli; Zidek, Augustin; Nelson, Alexander W R; Bridgland, Alex; Penedones, Hugo; Petersen, Stig; Simonyan, Karen; Crossan, Steve; Kohli, Pushmeet; Jones, David T; Silver, David; Kavukcuoglu, Koray; Hassabis, Demis	Improved protein structure prediction using potentials from deep learning.	Nature	2020	Nature. 2020 Jan;577(7792):706-710. doi: 10.1038/s41586-019-1923-7. Epub 2020 Jan 15.	Protein structure prediction can be used to determine the three-dimensional shape of a protein from its amino acid sequence(1). This problem is of fundamental importance as the structure of a protein largely determines its function(2); however, protein structures can be difficult to determine experimentally. Considerable progress has recently been made by leveraging genetic information. It is possible to infer which amino acid residues are in contact by analysing covariation in homologous sequences, which aids in the prediction of protein structures(3). Here we show that we can train a neural network to make accurate predictions of the distances between pairs of residues, which convey more information about the structure than contact predictions. Using this information, we construct a potential of mean force(4) that can accurately describe the shape of a protein. We find that the resulting potential can be optimized by a simple gradient descent algorithm to generate structures without complex sampling procedures. The resulting system, named AlphaFold, achieves high accuracy, even for sequences with fewer homologous sequences. In the recent Critical Assessment of Protein Structure Prediction(5) (CASP13)-a blind assessment of the state of the field-AlphaFold created high-accuracy structures (with template modelling (TM) scores(6) of 0.7 or higher) for 24 out of 43 free modelling domains, whereas the next best method, which used sampling and contact information, achieved such accuracy for only 14 out of 43 domains. AlphaFold represents a considerable advance in protein-structure prediction. We expect this increased accuracy to enable insights into the function and malfunction of proteins, especially in cases for which no structures for homologous proteins have been experimentally determined(7).		20200115	https://pubmed.ncbi.nlm.nih.gov/31942072
Reardon, Sara	Rise of Robot Radiologists.	Nature	2019	Nature. 2019 Dec;576(7787):S54-S58. doi: 10.1038/d41586-019-03847-z.	?	Computer science; Health care	?	https://pubmed.ncbi.nlm.nih.gov/31853073
Wallis, Claudia	How Artificial Intelligence Will Change Medicine.	Nature	2019	Nature. 2019 Dec;576(7787):S48. doi: 10.1038/d41586-019-03845-1.	?	Computer science; Health care	?	https://pubmed.ncbi.nlm.nih.gov/31853072
Schittko, Robert	Power play.	Nature	2019	Nature. 2019 Nov;575(7781):54-55. doi: 10.1038/d41586-019-03359-w.	?	Energy	?	https://pubmed.ncbi.nlm.nih.gov/31680126
Vinyals, Oriol; Babuschkin, Igor; Czarnecki, Wojciech M; Mathieu, Michael; Dudzik, Andrew; Chung, Junyoung; Choi, David H; Powell, Richard; Ewalds, Timo; Georgiev, Petko; Oh, Junhyuk; Horgan, Dan; Kroiss, Manuel; Danihelka, Ivo; Huang, Aja; Sifre, Laurent; Cai, Trevor; Agapiou, John P; Jaderberg, Max; Vezhnevets, Alexander S; Leblond, Remi; Pohlen, Tobias; Dalibard, Valentin; Budden, David; Sulsky, Yury; Molloy, James; Paine, Tom L; Gulcehre, Caglar; Wang, Ziyu; Pfaff, Tobias; Wu, Yuhuai; Ring, Roman; Yogatama, Dani; Wunsch, Dario; McKinney, Katrina; Smith, Oliver; Schaul, Tom; Lillicrap, Timothy; Kavukcuoglu, Koray; Hassabis, Demis; Apps, Chris; Silver, David	Grandmaster level in StarCraft II using multi-agent reinforcement learning.	Nature	2019	Nature. 2019 Nov;575(7782):350-354. doi: 10.1038/s41586-019-1724-z. Epub 2019 Oct 30.	Many real-world applications require artificial agents to compete and coordinate with other agents in complex environments. As a stepping stone to this goal, the domain of StarCraft has emerged as an important challenge for artificial intelligence research, owing to its iconic and enduring status among the most difficult professional esports and its relevance to the real world in terms of its raw complexity and multi-agent challenges. Over the course of a decade and numerous competitions(1-3), the strongest agents have simplified important aspects of the game, utilized superhuman capabilities, or employed hand-crafted sub-systems(4). Despite these advantages, no previous agent has come close to matching the overall skill of top StarCraft players. We chose to address the challenge of StarCraft using general-purpose learning methods that are in principle applicable to other complex domains: a multi-agent reinforcement learning algorithm that uses data from both human and agent games within a diverse league of continually adapting strategies and counter-strategies, each represented by deep neural networks(5,6). We evaluated our agent, AlphaStar, in the full game of StarCraft II, through a series of online games against human players. AlphaStar was rated at Grandmaster level for all three StarCraft races and above 99.8% of officially ranked human players.		20191030	https://pubmed.ncbi.nlm.nih.gov/31666705
Heaven, Douglas	Why deep-learning AIs are so easy to fool.	Nature	2019	Nature. 2019 Oct;574(7777):163-166. doi: 10.1038/d41586-019-03013-5.	?	Computer science; Information technology	?	https://pubmed.ncbi.nlm.nih.gov/31597977
Mignan, Arnaud; Broccardo, Marco	One neuron versus deep learning in aftershock prediction.	Nature	2019	Nature. 2019 Oct;574(7776):E1-E3. doi: 10.1038/s41586-019-1582-8. Epub 2019 Oct 2.	?		20191002	https://pubmed.ncbi.nlm.nih.gov/31578475
Meade, Brendan J	Reply to: One neuron versus deep learning in aftershock prediction.	Nature	2019	Nature. 2019 Oct;574(7776):E4. doi: 10.1038/s41586-019-1583-7.	?		?	https://pubmed.ncbi.nlm.nih.gov/31578474
Kwok, Roberta	Deep learning powers a motion-tracking revolution.	Nature	2019	Nature. 2019 Oct;574(7776):137-138. doi: 10.1038/d41586-019-02942-5.	?	Animal behaviour; Computational biology and bioinformatics; Conservation biology; Ecology	?	https://pubmed.ncbi.nlm.nih.gov/31570871
Ham, Yoo-Geun; Kim, Jeong-Hwan; Luo, Jing-Jia	Deep learning for multi-year ENSO forecasts.	Nature	2019	Nature. 2019 Sep;573(7775):568-572. doi: 10.1038/s41586-019-1559-7. Epub 2019 Sep 18.	Variations in the El Nino/Southern Oscillation (ENSO) are associated with a wide array of regional climate extremes and ecosystem impacts(1). Robust, long-lead forecasts would therefore be valuable for managing policy responses. But despite decades of effort, forecasting ENSO events at lead times of more than one year remains problematic(2). Here we show that a statistical forecast model employing a deep-learning approach produces skilful ENSO forecasts for lead times of up to one and a half years. To circumvent the limited amount of observation data, we use transfer learning to train a convolutional neural network (CNN) first on historical simulations(3) and subsequently on reanalysis from 1871 to 1973. During the validation period from 1984 to 2017, the all-season correlation skill of the Nino3.4 index of the CNN model is much higher than those of current state-of-the-art dynamical forecast systems. The CNN model is also better at predicting the detailed zonal distribution of sea surface temperatures, overcoming a weakness of dynamical forecast models. A heat map analysis indicates that the CNN model predicts ENSO events using physically reasonable precursors. The CNN model is thus a powerful tool for both the prediction of ENSO events and for the analysis of their associated complex mechanisms.		20190918	https://pubmed.ncbi.nlm.nih.gov/31534218
Tomasev, Nenad; Glorot, Xavier; Rae, Jack W; Zielinski, Michal; Askham, Harry; Saraiva, Andre; Mottram, Anne; Meyer, Clemens; Ravuri, Suman; Protsyuk, Ivan; Connell, Alistair; Hughes, Cian O; Karthikesalingam, Alan; Cornebise, Julien; Montgomery, Hugh; Rees, Geraint; Laing, Chris; Baker, Clifton R; Peterson, Kelly; Reeves, Ruth; Hassabis, Demis; King, Dominic; Suleyman, Mustafa; Back, Trevor; Nielson, Christopher; Ledsam, Joseph R; Mohamed, Shakir	A clinically applicable approach to continuous prediction of future acute kidney injury.	Nature	2019	Nature. 2019 Aug;572(7767):116-119. doi: 10.1038/s41586-019-1390-1. Epub 2019 Jul 31.	The early prediction of deterioration could have an important role in supporting healthcare professionals, as an estimated 11% of deaths in hospital follow a failure to promptly recognize and treat deteriorating patients(1). To achieve this goal requires predictions of patient risk that are continuously updated and accurate, and delivered at an individual level with sufficient context and enough time to act. Here we develop a deep learning approach for the continuous risk prediction of future deterioration in patients, building on recent work that models adverse events from electronic health records(2-17) and using acute kidney injury-a common and potentially life-threatening condition(18)-as an exemplar. Our model was developed on a large, longitudinal dataset of electronic health records that cover diverse clinical environments, comprising 703,782 adult patients across 172 inpatient and 1,062 outpatient sites. Our model predicts 55.8% of all inpatient episodes of acute kidney injury, and 90.2% of all acute kidney injuries that required subsequent administration of dialysis, with a lead time of up to 48 h and a ratio of 2 false alerts for every true alert. In addition to predicting future acute kidney injury, our model provides confidence assessments and a list of the clinical features that are most salient to each prediction, alongside predicted future trajectories for clinically relevant blood tests(9). Although the recognition and prompt treatment of acute kidney injury is known to be challenging, our approach may offer opportunities for identifying patients at risk within a time window that enables early treatment.		20190731	https://pubmed.ncbi.nlm.nih.gov/31367026
Topol, Eric J	Deep learning detects impending organ injury in the clinic.	Nature	2019	Nature. 2019 Aug;572(7767):36-37. doi: 10.1038/d41586-019-02308-x.	?	Medical research	?	https://pubmed.ncbi.nlm.nih.gov/31367025
Sundaram, Subramanian; Kellnhofer, Petr; Li, Yunzhu; Zhu, Jun-Yan; Torralba, Antonio; Matusik, Wojciech	Learning the signatures of the human grasp using a scalable tactile glove.	Nature	2019	Nature. 2019 May;569(7758):698-702. doi: 10.1038/s41586-019-1234-z. Epub 2019 May 29.	Humans can feel, weigh and grasp diverse objects, and simultaneously infer their material properties while applying the right amount of force-a challenging set of tasks for a modern robot(1). Mechanoreceptor networks that provide sensory feedback and enable the dexterity of the human grasp(2) remain difficult to replicate in robots. Whereas computer-vision-based robot grasping strategies(3-5) have progressed substantially with the abundance of visual data and emerging machine-learning tools, there are as yet no equivalent sensing platforms and large-scale datasets with which to probe the use of the tactile information that humans rely on when grasping objects. Studying the mechanics of how humans grasp objects will complement vision-based robotic object handling. Importantly, the inability to record and analyse tactile signals currently limits our understanding of the role of tactile information in the human grasp itself-for example, how tactile maps are used to identify objects and infer their properties is unknown(6). Here we use a scalable tactile glove and deep convolutional neural networks to show that sensors uniformly distributed over the hand can be used to identify individual objects, estimate their weight and explore the typical tactile patterns that emerge while grasping objects. The sensor array (548 sensors) is assembled on a knitted glove, and consists of a piezoresistive film connected by a network of conductive thread electrodes that are passively probed. Using a low-cost (about US$10) scalable tactile glove sensor array, we record a large-scale tactile dataset with 135,000 frames, each covering the full hand, while interacting with 26 different objects. This set of interactions with different objects reveals the key correspondences between different regions of a human hand while it is manipulating objects. Insights from the tactile signatures of the human grasp-through the lens of an artificial analogue of the natural mechanoreceptor network-can thus aid the future design of prosthetics(7), robot grasping tools and human-robot interactions(1,8-10).		20190529	https://pubmed.ncbi.nlm.nih.gov/31142856
Feldmann, J; Youngblood, N; Wright, C D; Bhaskaran, H; Pernice, W H P	All-optical spiking neurosynaptic networks with self-learning capabilities.	Nature	2019	Nature. 2019 May;569(7755):208-214. doi: 10.1038/s41586-019-1157-8. Epub 2019 May 8.	Software implementations of brain-inspired computing underlie many important computational tasks, from image processing to speech recognition, artificial intelligence and deep learning applications. Yet, unlike real neural tissue, traditional computing architectures physically separate the core computing functions of memory and processing, making fast, efficient and low-energy computing difficult to achieve. To overcome such limitations, an attractive alternative is to design hardware that mimics neurons and synapses. Such hardware, when connected in networks or neuromorphic systems, processes information in a way more analogous to brains. Here we present an all-optical version of such a neurosynaptic system, capable of supervised and unsupervised learning. We exploit wavelength division multiplexing techniques to implement a scalable circuit architecture for photonic neural networks, successfully demonstrating pattern recognition directly in the optical domain. Such photonic neurosynaptic networks promise access to the high speed and high bandwidth inherent to optical systems, thus enabling the direct processing of optical telecommunication and visual data.		20190508	https://pubmed.ncbi.nlm.nih.gov/31068721
Kates-Harbeck, Julian; Svyatkovskiy, Alexey; Tang, William	Predicting disruptive instabilities in controlled fusion plasmas through deep learning.	Nature	2019	Nature. 2019 Apr;568(7753):526-531. doi: 10.1038/s41586-019-1116-4. Epub 2019 Apr 17.	Nuclear fusion power delivered by magnetic-confinement tokamak reactors holds the promise of sustainable and clean energy(1). The avoidance of large-scale plasma instabilities called disruptions within these reactors(2,3) is one of the most pressing challenges(4,5), because disruptions can halt power production and damage key components. Disruptions are particularly harmful for large burning-plasma systems such as the multibillion-dollar International Thermonuclear Experimental Reactor (ITER) project(6) currently under construction, which aims to be the first reactor that produces more power from fusion than is injected to heat the plasma. Here we present a method based on deep learning for forecasting disruptions. Our method extends considerably the capabilities of previous strategies such as first-principles-based(5) and classical machine-learning(7-11) approaches. In particular, it delivers reliable predictions for machines other than the one on which it was trained-a crucial requirement for future large reactors that cannot afford training disruptions. Our approach takes advantage of high-dimensional training data to boost predictive performance while also engaging supercomputing resources at the largest scale to improve accuracy and speed. Trained on experimental data from the largest tokamaks in the United States (DIII-D(12)) and the world (Joint European Torus, JET(13)), our method can also be applied to specific tasks such as prediction with long warning times: this opens up the possibility of moving from passive disruption prediction to active reactor control and optimization. These initial results illustrate the potential for deep learning to accelerate progress in fusion-energy science and, more generally, in the understanding and prediction of complex physical systems.		20190417	https://pubmed.ncbi.nlm.nih.gov/30996348
?	Artificial intelligence alone won't solve the complexity of Earth sciences.	Nature	2019	Nature. 2019 Feb;566(7743):153. doi: 10.1038/d41586-019-00556-5.	?	Atmospheric science; Climate sciences; Geophysics; Ocean sciences	?	https://pubmed.ncbi.nlm.nih.gov/30867602
Reichstein, Markus; Camps-Valls, Gustau; Stevens, Bjorn; Jung, Martin; Denzler, Joachim; Carvalhais, Nuno; Prabhat	Deep learning and process understanding for data-driven Earth system science.	Nature	2019	Nature. 2019 Feb;566(7743):195-204. doi: 10.1038/s41586-019-0912-1. Epub 2019 Feb 13.	Machine learning approaches are increasingly used to extract patterns and insights from the ever-increasing stream of geospatial data, but current approaches may not be optimal when system behaviour is dominated by spatial or temporal context. Here, rather than amending classical machine learning, we argue that these contextual cues should be used as part of deep learning (an approach that is able to extract spatio-temporal features automatically) to gain further process understanding of Earth system science problems, improving the predictive ability of seasonal forecasting and modelling of long-range spatial connections across multiple timescales, for example. The next step will be a hybrid modelling approach, coupling physical process models with the versatility of data-driven machine learning.		20190213	https://pubmed.ncbi.nlm.nih.gov/30760912
Fessenden, Marissa	Technologies to watch in 2019.	Nature	2019	Nature. 2019 Jan;565(7740):521-523. doi: 10.1038/d41586-019-00218-6.	?	Developmental biology; Genomics; Microscopy; Structural biology	?	https://pubmed.ncbi.nlm.nih.gov/30675053
Maxmen, Amy	Machine learning spots natural selection at work in human genome.	Nature	2018	Nature. 2018 Nov;563(7730):167. doi: 10.1038/d41586-018-07225-z.	?	Biological techniques; Computational biology and bioinformatics; Diseases; Evolution	?	https://pubmed.ncbi.nlm.nih.gov/30401843
Beroza, Gregory C	Machine learning improves forecasts of aftershock locations.	Nature	2018	Nature. 2018 Aug;560(7720):556-557. doi: 10.1038/d41586-018-06030-y.	?	Computer science; Geophysics; Solid Earth sciences	?	https://pubmed.ncbi.nlm.nih.gov/30158611
DeVries, Phoebe M R; Viegas, Fernanda; Wattenberg, Martin; Meade, Brendan J	Deep learning of aftershock patterns following large earthquakes.	Nature	2018	Nature. 2018 Aug;560(7720):632-634. doi: 10.1038/s41586-018-0438-y. Epub 2018 Aug 29.	Aftershocks are a response to changes in stress generated by large earthquakes and represent the most common observations of the triggering of earthquakes. The maximum magnitude of aftershocks and their temporal decay are well described by empirical laws (such as Bath's law(1) and Omori's law(2)), but explaining and forecasting the spatial distribution of aftershocks is more difficult. Coulomb failure stress change(3) is perhaps the most widely used criterion to explain the spatial distributions of aftershocks(4-8), but its applicability has been disputed(9-11). Here we use a deep-learning approach to identify a static-stress-based criterion that forecasts aftershock locations without prior assumptions about fault orientation. We show that a neural network trained on more than 131,000 mainshock-aftershock pairs can predict the locations of aftershocks in an independent test dataset of more than 30,000 mainshock-aftershock pairs more accurately (area under curve of 0.849) than can classic Coulomb failure stress change (area under curve of 0.583). We find that the learned aftershock pattern is physically interpretable: the maximum change in shear stress, the von Mises yield criterion (a scaled version of the second invariant of the deviatoric stress-change tensor) and the sum of the absolute values of the independent components of the stress-change tensor each explain more than 98 per cent of the variance in the neural-network prediction. This machine-learning-driven insight provides improved forecasts of aftershock locations and identifies physical quantities that may control earthquake triggering during the most active part of the seismic cycle.		20180829	https://pubmed.ncbi.nlm.nih.gov/30158606
Banino, Andrea; Barry, Caswell; Uria, Benigno; Blundell, Charles; Lillicrap, Timothy; Mirowski, Piotr; Pritzel, Alexander; Chadwick, Martin J; Degris, Thomas; Modayil, Joseph; Wayne, Greg; Soyer, Hubert; Viola, Fabio; Zhang, Brian; Goroshin, Ross; Rabinowitz, Neil; Pascanu, Razvan; Beattie, Charlie; Petersen, Stig; Sadik, Amir; Gaffney, Stephen; King, Helen; Kavukcuoglu, Koray; Hassabis, Demis; Hadsell, Raia; Kumaran, Dharshan	Vector-based navigation using grid-like representations in artificial agents.	Nature	2018	Nature. 2018 May;557(7705):429-433. doi: 10.1038/s41586-018-0102-6. Epub 2018 May 9.	Deep neural networks have achieved impressive successes in fields ranging from object recognition to complex games such as Go(1,2). Navigation, however, remains a substantial challenge for artificial agents, with deep neural networks trained by reinforcement learning(3-5) failing to rival the proficiency of mammalian spatial behaviour, which is underpinned by grid cells in the entorhinal cortex (6) . Grid cells are thought to provide a multi-scale periodic representation that functions as a metric for coding space(7,8) and is critical for integrating self-motion (path integration)(6,7,9) and planning direct trajectories to goals (vector-based navigation)(7,10,11). Here we set out to leverage the computational functions of grid cells to develop a deep reinforcement learning agent with mammal-like navigational abilities. We first trained a recurrent network to perform path integration, leading to the emergence of representations resembling grid cells, as well as other entorhinal cell types (12) . We then showed that this representation provided an effective basis for an agent to locate goals in challenging, unfamiliar, and changeable environments-optimizing the primary objective of navigation through deep reinforcement learning. The performance of agents endowed with grid-like representations surpassed that of an expert human and comparison agents, with the metric quantities necessary for vector-based navigation derived from grid-like units within the network. Furthermore, grid-like representations enabled agents to conduct shortcut behaviours reminiscent of those performed by mammals. Our findings show that emergent grid-like representations furnish agents with a Euclidean spatial metric and associated vector operations, providing a foundation for proficient navigation. As such, our results support neuroscientific theories that see grid cells as critical for vector-based navigation(7,10,11), demonstrating that the latter can be combined with path-based strategies to support navigation in challenging environments.		20180509	https://pubmed.ncbi.nlm.nih.gov/29743670
Zhu, Bo; Liu, Jeremiah Z; Cauley, Stephen F; Rosen, Bruce R; Rosen, Matthew S	Image reconstruction by domain-transform manifold learning.	Nature	2018	Nature. 2018 Mar 21;555(7697):487-492. doi: 10.1038/nature25988.	Image reconstruction is essential for imaging applications across the physical and life sciences, including optical and radar systems, magnetic resonance imaging, X-ray computed tomography, positron emission tomography, ultrasound imaging and radio astronomy. During image acquisition, the sensor encodes an intermediate representation of an object in the sensor domain, which is subsequently reconstructed into an image by an inversion of the encoding function. Image reconstruction is challenging because analytic knowledge of the exact inverse transform may not exist a priori, especially in the presence of sensor non-idealities and noise. Thus, the standard reconstruction approach involves approximating the inverse function with multiple ad hoc stages in a signal processing chain, the composition of which depends on the details of each acquisition strategy, and often requires expert parameter tuning to optimize reconstruction performance. Here we present a unified framework for image reconstruction-automated transform by manifold approximation (AUTOMAP)-which recasts image reconstruction as a data-driven supervised learning task that allows a mapping between the sensor and the image domain to emerge from an appropriate corpus of training data. We implement AUTOMAP with a deep neural network and exhibit its flexibility in learning reconstruction transforms for various magnetic resonance imaging acquisition strategies, using the same network architecture and hyperparameters. We further demonstrate that manifold learning during training results in sparse representations of domain transforms along low-dimensional data manifolds, and observe superior immunity to noise and a reduction in reconstruction artefacts compared with conventional handcrafted reconstruction methods. In addition to improving the reconstruction performance of existing acquisition methodologies, we anticipate that AUTOMAP and other learned reconstruction approaches will accelerate the development of new acquisition strategies across imaging modalities.		?	https://pubmed.ncbi.nlm.nih.gov/29565357
?	An efficient deep-learning tool for detecting eye disease.	Nature	2018	Nature. 2018 Mar;555(7694):9. doi: 10.1038/d41586-018-02431-1.	?	Technology	?	https://pubmed.ncbi.nlm.nih.gov/32094890
Webb, Sarah	Deep learning for biology.	Nature	2018	Nature. 2018 Feb 22;554(7693):555-557. doi: 10.1038/d41586-018-02174-z.	?		?	https://pubmed.ncbi.nlm.nih.gov/29469107
Webb, Sarah	Deep learning for biology.	Nature	2018	Nature. 2018 Feb;554(7693):555-557. doi: 10.1038/d41586-018-02174-z.	?	Computational biology and bioinformatics; Computer science	?	https://pubmed.ncbi.nlm.nih.gov/32094952
Maxmen, Amy	Deep learning sharpens views of cells and genes.	Nature	2018	Nature. 2018 Jan 4;553(7686):9-10. doi: 10.1038/d41586-018-00004-w.	?		?	https://pubmed.ncbi.nlm.nih.gov/29300023
Maxmen, Amy	Deep learning sharpens views of cells and genes.	Nature	2018	Nature. 2018 Jan;553(7686):9-10. doi: 10.1038/d41586-018-00004-w.	?	Biological techniques; Cell biology; Computer science; Technology	?	https://pubmed.ncbi.nlm.nih.gov/32076277
Silver, David; Schrittwieser, Julian; Simonyan, Karen; Antonoglou, Ioannis; Huang, Aja; Guez, Arthur; Hubert, Thomas; Baker, Lucas; Lai, Matthew; Bolton, Adrian; Chen, Yutian; Lillicrap, Timothy; Hui, Fan; Sifre, Laurent; van den Driessche, George; Graepel, Thore; Hassabis, Demis	Mastering the game of Go without human knowledge.	Nature	2017	Nature. 2017 Oct 18;550(7676):354-359. doi: 10.1038/nature24270.	A long-standing goal of artificial intelligence is an algorithm that learns, tabula rasa, superhuman proficiency in challenging domains. Recently, AlphaGo became the first program to defeat a world champion in the game of Go. The tree search in AlphaGo evaluated positions and selected moves using deep neural networks. These neural networks were trained by supervised learning from human expert moves, and by reinforcement learning from self-play. Here we introduce an algorithm based solely on reinforcement learning, without human data, guidance or domain knowledge beyond game rules. AlphaGo becomes its own teacher: a neural network is trained to predict AlphaGo's own move selections and also the winner of AlphaGo's games. This neural network improves the strength of the tree search, resulting in higher quality move selection and stronger self-play in the next iteration. Starting tabula rasa, our new program AlphaGo Zero achieved superhuman performance, winning 100-0 against the previously published, champion-defeating AlphaGo.		?	https://pubmed.ncbi.nlm.nih.gov/29052630
Hazlett, Heather Cody; Gu, Hongbin; Munsell, Brent C; Kim, Sun Hyung; Styner, Martin; Wolff, Jason J; Elison, Jed T; Swanson, Meghan R; Zhu, Hongtu; Botteron, Kelly N; Collins, D Louis; Constantino, John N; Dager, Stephen R; Estes, Annette M; Evans, Alan C; Fonov, Vladimir S; Gerig, Guido; Kostopoulos, Penelope; McKinstry, Robert C; Pandey, Juhi; Paterson, Sarah; Pruett, John R; Schultz, Robert T; Shaw, Dennis W; Zwaigenbaum, Lonnie; Piven, Joseph	Early brain development in infants at high risk for autism spectrum disorder.	Nature	2017	Nature. 2017 Feb 15;542(7641):348-351. doi: 10.1038/nature21369.	Brain enlargement has been observed in children with autism spectrum disorder (ASD), but the timing of this phenomenon, and the relationship between ASD and the appearance of behavioural symptoms, are unknown. Retrospective head circumference and longitudinal brain volume studies of two-year olds followed up at four years of age have provided evidence that increased brain volume may emerge early in development. Studies of infants at high familial risk of autism can provide insight into the early development of autism and have shown that characteristic social deficits in ASD emerge during the latter part of the first and in the second year of life. These observations suggest that prospective brain-imaging studies of infants at high familial risk of ASD might identify early postnatal changes in brain volume that occur before an ASD diagnosis. In this prospective neuroimaging study of 106 infants at high familial risk of ASD and 42 low-risk infants, we show that hyperexpansion of the cortical surface area between 6 and 12 months of age precedes brain volume overgrowth observed between 12 and 24 months in 15 high-risk infants who were diagnosed with autism at 24 months. Brain volume overgrowth was linked to the emergence and severity of autistic social deficits. A deep-learning algorithm that primarily uses surface area information from magnetic resonance imaging of the brain of 6-12-month-old individuals predicted the diagnosis of autism in individual high-risk children at 24 months (with a positive predictive value of 81% and a sensitivity of 88%). These findings demonstrate that early brain changes occur during the period in which autistic behaviours are first emerging.		?	https://pubmed.ncbi.nlm.nih.gov/28202961
Silver, David; Huang, Aja; Maddison, Chris J; Guez, Arthur; Sifre, Laurent; van den Driessche, George; Schrittwieser, Julian; Antonoglou, Ioannis; Panneershelvam, Veda; Lanctot, Marc; Dieleman, Sander; Grewe, Dominik; Nham, John; Kalchbrenner, Nal; Sutskever, Ilya; Lillicrap, Timothy; Leach, Madeleine; Kavukcuoglu, Koray; Graepel, Thore; Hassabis, Demis	Mastering the game of Go with deep neural networks and tree search.	Nature	2016	Nature. 2016 Jan 28;529(7587):484-9. doi: 10.1038/nature16961.	The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses 'value networks' to evaluate board positions and 'policy networks' to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8% winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away.		?	https://pubmed.ncbi.nlm.nih.gov/26819042
Hao, Shuang; Tang, Bin; Wu, Zhenyu; Ure, Kerstin; Sun, Yaling; Tao, Huifang; Gao, Yan; Patel, Akash J; Curry, Daniel J; Samaco, Rodney C; Zoghbi, Huda Y; Tang, Jianrong	Forniceal deep brain stimulation rescues hippocampal memory in Rett syndrome mice.	Nature	2015	Nature. 2015 Oct 15;526(7573):430-4. doi: 10.1038/nature15694.	Deep brain stimulation (DBS) has improved the prospects for many individuals with diseases affecting motor control, and recently it has shown promise for improving cognitive function as well. Several studies in individuals with Alzheimer disease and in amnesic rats have demonstrated that DBS targeted to the fimbria-fornix, the region that appears to regulate hippocampal activity, can mitigate defects in hippocampus-dependent memory. Despite these promising results, DBS has not been tested for its ability to improve cognition in any childhood intellectual disability disorder. Such disorders are a pressing concern: they affect as much as 3% of the population and involve hundreds of different genes. We proposed that stimulating the neural circuits that underlie learning and memory might provide a more promising route to treating these otherwise intractable disorders than seeking to adjust levels of one molecule at a time. We therefore studied the effects of forniceal DBS in a well-characterized mouse model of Rett syndrome (RTT), which is a leading cause of intellectual disability in females. Caused by mutations that impair the function of MeCP2 (ref. 6), RTT appears by the second year of life in humans, causing profound impairment in cognitive, motor and social skills, along with an array of neurological features. RTT mice, which reproduce the broad phenotype of this disorder, also show clear deficits in hippocampus-dependent learning and memory and hippocampal synaptic plasticity. Here we show that forniceal DBS in RTT mice rescues contextual fear memory as well as spatial learning and memory. In parallel, forniceal DBS restores in vivo hippocampal long-term potentiation and hippocampal neurogenesis. These results indicate that forniceal DBS might mitigate cognitive dysfunction in RTT.		?	https://pubmed.ncbi.nlm.nih.gov/26469053
Cully, Antoine; Clune, Jeff; Tarapore, Danesh; Mouret, Jean-Baptiste	Robots that can adapt like animals.	Nature	2015	Nature. 2015 May 28;521(7553):503-7. doi: 10.1038/nature14422.	Robots have transformed many industries, most notably manufacturing, and have the power to deliver tremendous benefits to society, such as in search and rescue, disaster response, health care and transportation. They are also invaluable tools for scientific exploration in environments inaccessible to humans, from distant planets to deep oceans. A major obstacle to their widespread adoption in more complex environments outside factories is their fragility. Whereas animals can quickly adapt to injuries, current robots cannot 'think outside the box' to find a compensatory behaviour when they are damaged: they are limited to their pre-specified self-sensing abilities, can diagnose only anticipated failure modes, and require a pre-programmed contingency plan for every type of potential damage, an impracticality for complex robots. A promising approach to reducing robot fragility involves having robots learn appropriate behaviours in response to damage, but current techniques are slow even with small, constrained search spaces. Here we introduce an intelligent trial-and-error algorithm that allows robots to adapt to damage in less than two minutes in large search spaces without requiring self-diagnosis or pre-specified contingency plans. Before the robot is deployed, it uses a novel technique to create a detailed map of the space of high-performing behaviours. This map represents the robot's prior knowledge about what behaviours it can perform and their value. When the robot is damaged, it uses this prior knowledge to guide a trial-and-error learning algorithm that conducts intelligent experiments to rapidly discover a behaviour that compensates for the damage. Experiments reveal successful adaptations for a legged robot injured in five different ways, including damaged, broken, and missing legs, and for a robotic arm with joints broken in 14 different ways. This new algorithm will enable more robust, effective, autonomous robots, and may shed light on the principles that animals use to adapt to injury.		?	https://pubmed.ncbi.nlm.nih.gov/26017452
LeCun, Yann; Bengio, Yoshua; Hinton, Geoffrey	Deep learning.	Nature	2015	Nature. 2015 May 28;521(7553):436-44. doi: 10.1038/nature14539.	Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.		?	https://pubmed.ncbi.nlm.nih.gov/26017442
Mnih, Volodymyr; Kavukcuoglu, Koray; Silver, David; Rusu, Andrei A; Veness, Joel; Bellemare, Marc G; Graves, Alex; Riedmiller, Martin; Fidjeland, Andreas K; Ostrovski, Georg; Petersen, Stig; Beattie, Charles; Sadik, Amir; Antonoglou, Ioannis; King, Helen; Kumaran, Dharshan; Wierstra, Daan; Legg, Shane; Hassabis, Demis	Human-level control through deep reinforcement learning.	Nature	2015	Nature. 2015 Feb 26;518(7540):529-33. doi: 10.1038/nature14236.	The theory of reinforcement learning provides a normative account, deeply rooted in psychological and neuroscientific perspectives on animal behaviour, of how agents may optimize their control of an environment. To use reinforcement learning successfully in situations approaching real-world complexity, however, agents are confronted with a difficult task: they must derive efficient representations of the environment from high-dimensional sensory inputs, and use these to generalize past experience to new situations. Remarkably, humans and other animals seem to solve this problem through a harmonious combination of reinforcement learning and hierarchical sensory processing systems, the former evidenced by a wealth of neural data revealing notable parallels between the phasic signals emitted by dopaminergic neurons and temporal difference reinforcement learning algorithms. While reinforcement learning agents have achieved some successes in a variety of domains, their applicability has previously been limited to domains in which useful features can be handcrafted, or to domains with fully observed, low-dimensional state spaces. Here we use recent advances in training deep neural networks to develop a novel artificial agent, termed a deep Q-network, that can learn successful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning. We tested this agent on the challenging domain of classic Atari 2600 games. We demonstrate that the deep Q-network agent, receiving only the pixels and the game score as inputs, was able to surpass the performance of all previous algorithms and achieve a level comparable to that of a professional human games tester across a set of 49 games, using the same algorithm, network architecture and hyperparameters. This work bridges the divide between high-dimensional sensory inputs and actions, resulting in the first artificial agent that is capable of learning to excel at a diverse array of challenging tasks.		?	https://pubmed.ncbi.nlm.nih.gov/25719670
Mante, Valerio; Sussillo, David; Shenoy, Krishna V; Newsome, William T	Context-dependent computation by recurrent dynamics in prefrontal cortex.	Nature	2013	Nature. 2013 Nov 7;503(7474):78-84. doi: 10.1038/nature12742.	Prefrontal cortex is thought to have a fundamental role in flexible, context-dependent behaviour, but the exact nature of the computations underlying this role remains largely unknown. In particular, individual prefrontal neurons often generate remarkably complex responses that defy deep understanding of their contribution to behaviour. Here we study prefrontal cortex activity in macaque monkeys trained to flexibly select and integrate noisy sensory inputs towards a choice. We find that the observed complexity and functional roles of single neurons are readily understood in the framework of a dynamical process unfolding at the level of the population. The population dynamics can be reproduced by a trained recurrent neural network, which suggests a previously unknown mechanism for selection and integration of task-relevant inputs. This mechanism indicates that selection and integration are two aspects of a single dynamical process unfolding within the same prefrontal circuits, and potentially provides a novel, general framework for understanding context-dependent computations.		?	https://pubmed.ncbi.nlm.nih.gov/24201281
Tsai, Peter T; Hull, Court; Chu, YunXiang; Greene-Colozzi, Emily; Sadowski, Abbey R; Leech, Jarrett M; Steinberg, Jason; Crawley, Jacqueline N; Regehr, Wade G; Sahin, Mustafa	Autistic-like behaviour and cerebellar dysfunction in Purkinje cell Tsc1 mutant mice.	Nature	2012	Nature. 2012 Aug 30;488(7413):647-51. doi: 10.1038/nature11310.	Autism spectrum disorders (ASDs) are highly prevalent neurodevelopmental disorders, but the underlying pathogenesis remains poorly understood. Recent studies have implicated the cerebellum in these disorders, with post-mortem studies in ASD patients showing cerebellar Purkinje cell (PC) loss, and isolated cerebellar injury has been associated with a higher incidence of ASDs. However, the extent of cerebellar contribution to the pathogenesis of ASDs remains unclear. Tuberous sclerosis complex (TSC) is a genetic disorder with high rates of comorbid ASDs that result from mutation of either TSC1 or TSC2, whose protein products dimerize and negatively regulate mammalian target of rapamycin (mTOR) signalling. TSC is an intriguing model to investigate the cerebellar contribution to the underlying pathogenesis of ASDs, as recent studies in TSC patients demonstrate cerebellar pathology and correlate cerebellar pathology with increased ASD symptomatology. Functional imaging also shows that TSC patients with ASDs display hypermetabolism in deep cerebellar structures, compared to TSC patients without ASDs. However, the roles of Tsc1 and the sequelae of Tsc1 dysfunction in the cerebellum have not been investigated so far. Here we show that both heterozygous and homozygous loss of Tsc1 in mouse cerebellar PCs results in autistic-like behaviours, including abnormal social interaction, repetitive behaviour and vocalizations, in addition to decreased PC excitability. Treatment of mutant mice with the mTOR inhibitor, rapamycin, prevented the pathological and behavioural deficits. These findings demonstrate new roles for Tsc1 in PC function and define a molecular basis for a cerebellar contribution to cognitive disorders such as autism.		?	https://pubmed.ncbi.nlm.nih.gov/22763451
Huber, D; Gutnisky, D A; Peron, S; O'Connor, D H; Wiegert, J S; Tian, L; Oertner, T G; Looger, L L; Svoboda, K	Multiple dynamic representations in the motor cortex during sensorimotor learning.	Nature	2012	Nature. 2012 Apr 25;484(7395):473-8. doi: 10.1038/nature11039.	The mechanisms linking sensation and action during learning are poorly understood. Layer 2/3 neurons in the motor cortex might participate in sensorimotor integration and learning; they receive input from sensory cortex and excite deep layer neurons, which control movement. Here we imaged activity in the same set of layer 2/3 neurons in the motor cortex over weeks, while mice learned to detect objects with their whiskers and report detection with licking. Spatially intermingled neurons represented sensory (touch) and motor behaviours (whisker movements and licking). With learning, the population-level representation of task-related licking strengthened. In trained mice, population-level representations were redundant and stable, despite dynamism of single-neuron representations. The activity of a subpopulation of neurons was consistent with touch driving licking behaviour. Our results suggest that ensembles of motor cortex neurons couple sensory input to multiple, related motor programs during learning.		20120425	https://pubmed.ncbi.nlm.nih.gov/22538608
Li, Bo; Piriz, Joaquin; Mirrione, Martine; Chung, ChiHye; Proulx, Christophe D; Schulz, Daniela; Henn, Fritz; Malinow, Roberto	Synaptic potentiation onto habenula neurons in the learned helplessness model of depression.	Nature	2011	Nature. 2011 Feb 24;470(7335):535-9. doi: 10.1038/nature09742.	The cellular basis of depressive disorders is poorly understood. Recent studies in monkeys indicate that neurons in the lateral habenula (LHb), a nucleus that mediates communication between forebrain and midbrain structures, can increase their activity when an animal fails to receive an expected positive reward or receives a stimulus that predicts aversive conditions (that is, disappointment or anticipation of a negative outcome). LHb neurons project to, and modulate, dopamine-rich regions, such as the ventral tegmental area (VTA), that control reward-seeking behaviour and participate in depressive disorders. Here we show that in two learned helplessness models of depression, excitatory synapses onto LHb neurons projecting to the VTA are potentiated. Synaptic potentiation correlates with an animal's helplessness behaviour and is due to an enhanced presynaptic release probability. Depleting transmitter release by repeated electrical stimulation of LHb afferents, using a protocol that can be effective for patients who are depressed, markedly suppresses synaptic drive onto VTA-projecting LHb neurons in brain slices and can significantly reduce learned helplessness behaviour in rats. Our results indicate that increased presynaptic action onto LHb neurons contributes to the rodent learned helplessness model of depression.		?	https://pubmed.ncbi.nlm.nih.gov/21350486
Oda, Y; Kawasaki, K; Morita, M; Korn, H; Matsui, H	Inhibitory long-term potentiation underlies auditory conditioning of goldfish escape behaviour.	Nature	1998	Nature. 1998 Jul 9;394(6689):182-5. doi: 10.1038/28172.	Long-term potentiation (LTP), the increase in synaptic strength evoked by high-frequency stimulation, is often considered to be a cellular model for learning and memory. The validity of this model depends on the assumptions that physiological stimuli can induce LTP in vivo and that the resulting synaptic modifications correlate with behavioural changes. However, modifiable synapses are generally embedded deep in complex circuits. In contrast, the goldfish Mauthner (M)-cell and its afferent synapses are easily accessible for electrophysiological studies, and firing of this neuron is sufficient to trigger fast escape behaviour in response to sudden stimuli. We have previously shown that tetanic stimulation can induce LTP of the feedforward inhibitory synapses that control the excitability of the M-cell. Here we report that natural sensory stimulation can induce potentiation of this inhibitory connection that resembles the LTP induced by afferent tetanization. Furthermore, comparable acoustic stimulation produced a parallel decrease in the probability of the sound-evoked escape reflex. Thus we demonstrate for the first time, to our knowledge, a behavioural role for the long-term synaptic strengthening of inhibitory synapses.		?	https://pubmed.ncbi.nlm.nih.gov/9671301
Wilkinson, F; Dodwell, P C	Young kittens can learn complex visual pattern discriminations.	Nature	1980	Nature. 1980 Mar 20;284(5753):258-9. doi: 10.1038/284258a0.	Kittens begin to display visually elicited responses shortly after eye opening. The pupillary reflex, optokinetic response, visual placing and avoidance of the deep side of the visual cliff all appear between the second and fifth weeks of life, and evidence of visual learning in homing behaviour has been described at the same early age. However, an attempt to elicit pattern preferences in kittens of this age (usually considered the easiest way to demonstrate discriminatory behaviour in immature organisms) was unsuccessful, evidently because such kittens show little spontaneous visual interest. This is surprising in view of electrophysiological findings which emphasise the importance of the fourth to sixth weeks in the development of cortical feature-analysing mechanisms; perhaps the stimulus-seeking methodology of Dodwell et al. is anappropriate for the visual modality at such an early age. Recently, visual acuity measurements have been reported for kittens as young as 30 d of age using a contour versus no-contour discrimination on a modified Lashley jumping stand. With this technique we have now trained kittens of under 50 d of age to perform more complex pattern discriminations.		?	https://pubmed.ncbi.nlm.nih.gov/7360257
