Authors	Title	Journal	Year	Publication_citation	Abstract	Keywords	Date_epublished	PMID
Pierson, Emma; Cutler, David M; Leskovec, Jure; Mullainathan, Sendhil; Obermeyer, Ziad	An algorithmic approach to reducing unexplained pain disparities in underserved populations.	Nat Med	2021	Nat Med. 2021 Jan;27(1):136-140. doi: 10.1038/s41591-020-01192-7. Epub 2021 Jan 13.	Underserved populations experience higher levels of pain. These disparities persist even after controlling for the objective severity of diseases like osteoarthritis, as graded by human physicians using medical images, raising the possibility that underserved patients' pain stems from factors external to the knee, such as stress. Here we use a deep learning approach to measure the severity of osteoarthritis, by using knee X-rays to predict patients' experienced pain. We show that this approach dramatically reduces unexplained racial disparities in pain. Relative to standard measures of severity graded by radiologists, which accounted for only 9% (95% confidence interval (CI), 3-16%) of racial disparities in pain, algorithmic predictions accounted for 43% of disparities, or 4.7x more (95% CI, 3.2-11.8x), with similar results for lower-income and less-educated patients. This suggests that much of underserved patients' pain stems from factors within the knee not reflected in standard radiographic measures of severity. We show that the algorithm's ability to reduce unexplained disparities is rooted in the racial and socioeconomic diversity of the training set. Because algorithmic severity measures better capture underserved patients' pain, and severity measures influence treatment decisions, algorithmic predictions could potentially redress disparities in access to treatments like arthroplasty.		20210113	https://pubmed.ncbi.nlm.nih.gov/33442014
Lotter, William; Diab, Abdul Rahman; Haslam, Bryan; Kim, Jiye G; Grisot, Giorgia; Wu, Eric; Wu, Kevin; Onieva, Jorge Onieva; Boyer, Yun; Boxerman, Jerrold L; Wang, Meiyun; Bandler, Mack; Vijayaraghavan, Gopal R; Gregory Sorensen, A	Robust breast cancer detection in mammography and digital breast tomosynthesis using an annotation-efficient deep learning approach.	Nat Med	2021	Nat Med. 2021 Feb;27(2):244-249. doi: 10.1038/s41591-020-01174-9. Epub 2021 Jan 11.	Breast cancer remains a global challenge, causing over 600,000 deaths in 2018 (ref. (1)). To achieve earlier cancer detection, health organizations worldwide recommend screening mammography, which is estimated to decrease breast cancer mortality by 20-40% (refs. (2,3)). Despite the clear value of screening mammography, significant false positive and false negative rates along with non-uniformities in expert reader availability leave opportunities for improving quality and access(4,5). To address these limitations, there has been much recent interest in applying deep learning to mammography(6-18), and these efforts have highlighted two key difficulties: obtaining large amounts of annotated training data and ensuring generalization across populations, acquisition equipment and modalities. Here we present an annotation-efficient deep learning approach that (1) achieves state-of-the-art performance in mammogram classification, (2) successfully extends to digital breast tomosynthesis (DBT; '3D mammography'), (3) detects cancers in clinically negative prior mammograms of patients with cancer, (4) generalizes well to a population with low screening rates and (5) outperforms five out of five full-time breast-imaging specialists with an average increase in sensitivity of 14%. By creating new 'maximum suspicion projection' (MSP) images from DBT data, our progressively trained, multiple-instance learning approach effectively trains on DBT exams using only breast-level labels while maintaining localization-based interpretability. Altogether, our results demonstrate promise towards software that can improve the accuracy of and access to screening mammography worldwide.		20210111	https://pubmed.ncbi.nlm.nih.gov/33432172
AbdulJabbar, Khalid; Raza, Shan E Ahmed; Rosenthal, Rachel; Jamal-Hanjani, Mariam; Veeriah, Selvaraju; Akarca, Ayse; Lund, Tom; Moore, David A; Salgado, Roberto; Al Bakir, Maise; Zapata, Luis; Hiley, Crispin T; Officer, Leah; Sereno, Marco; Smith, Claire Rachel; Loi, Sherene; Hackshaw, Allan; Marafioti, Teresa; Quezada, Sergio A; McGranahan, Nicholas; Le Quesne, John; Swanton, Charles; Yuan, Yinyin	Geospatial immune variability illuminates differential evolution of lung adenocarcinoma.	Nat Med	2020	Nat Med. 2020 Jul;26(7):1054-1062. doi: 10.1038/s41591-020-0900-x. Epub 2020 May 27.	Remarkable progress in molecular analyses has improved our understanding of the evolution of cancer cells toward immune escape(1-5). However, the spatial configurations of immune and stromal cells, which may shed light on the evolution of immune escape across tumor geographical locations, remain unaddressed. We integrated multiregion exome and RNA-sequencing (RNA-seq) data with spatial histology mapped by deep learning in 100 patients with non-small cell lung cancer from the TRACERx cohort(6). Cancer subclones derived from immune cold regions were more closely related in mutation space, diversifying more recently than subclones from immune hot regions. In TRACERx and in an independent multisample cohort of 970 patients with lung adenocarcinoma, tumors with more than one immune cold region had a higher risk of relapse, independently of tumor size, stage and number of samples per patient. In lung adenocarcinoma, but not lung squamous cell carcinoma, geometrical irregularity and complexity of the cancer-stromal cell interface significantly increased in tumor regions without disruption of antigen presentation. Decreased lymphocyte accumulation in adjacent stroma was observed in tumors with low clonal neoantigen burden. Collectively, immune geospatial variability elucidates tumor ecological constraints that may shape the emergence of immune-evading subclones and aggressive clinical phenotypes.		20200527	https://pubmed.ncbi.nlm.nih.gov/32461698
Liu, Yuan; Jain, Ayush; Eng, Clara; Way, David H; Lee, Kang; Bui, Peggy; Kanada, Kimberly; de Oliveira Marinho, Guilherme; Gallegos, Jessica; Gabriele, Sara; Gupta, Vishakha; Singh, Nalini; Natarajan, Vivek; Hofmann-Wellenhof, Rainer; Corrado, Greg S; Peng, Lily H; Webster, Dale R; Ai, Dennis; Huang, Susan J; Liu, Yun; Dunn, R Carter; Coz, David	A deep learning system for differential diagnosis of skin diseases.	Nat Med	2020	Nat Med. 2020 Jun;26(6):900-908. doi: 10.1038/s41591-020-0842-3. Epub 2020 May 18.	Skin conditions affect 1.9 billion people. Because of a shortage of dermatologists, most cases are seen instead by general practitioners with lower diagnostic accuracy. We present a deep learning system (DLS) to provide a differential diagnosis of skin conditions using 16,114 de-identified cases (photographs and clinical data) from a teledermatology practice serving 17 sites. The DLS distinguishes between 26 common skin conditions, representing 80% of cases seen in primary care, while also providing a secondary prediction covering 419 skin conditions. On 963 validation cases, where a rotating panel of three board-certified dermatologists defined the reference standard, the DLS was non-inferior to six other dermatologists and superior to six primary care physicians (PCPs) and six nurse practitioners (NPs) (top-1 accuracy: 0.66 DLS, 0.63 dermatologists, 0.44 PCPs and 0.40 NPs). These results highlight the potential of the DLS to assist general practitioners in diagnosing skin conditions.		20200518	https://pubmed.ncbi.nlm.nih.gov/32424212
Yim, Jason; Chopra, Reena; Spitz, Terry; Winkens, Jim; Obika, Annette; Kelly, Christopher; Askham, Harry; Lukic, Marko; Huemer, Josef; Fasler, Katrin; Moraes, Gabriella; Meyer, Clemens; Wilson, Marc; Dixon, Jonathan; Hughes, Cian; Rees, Geraint; Khaw, Peng T; Karthikesalingam, Alan; King, Dominic; Hassabis, Demis; Suleyman, Mustafa; Back, Trevor; Ledsam, Joseph R; Keane, Pearse A; De Fauw, Jeffrey	Predicting conversion to wet age-related macular degeneration using deep learning.	Nat Med	2020	Nat Med. 2020 Jun;26(6):892-899. doi: 10.1038/s41591-020-0867-7. Epub 2020 May 18.	Progression to exudative 'wet' age-related macular degeneration (exAMD) is a major cause of visual deterioration. In patients diagnosed with exAMD in one eye, we introduce an artificial intelligence (AI) system to predict progression to exAMD in the second eye. By combining models based on three-dimensional (3D) optical coherence tomography images and corresponding automatic tissue maps, our system predicts conversion to exAMD within a clinically actionable 6-month time window, achieving a per-volumetric-scan sensitivity of 80% at 55% specificity, and 34% sensitivity at 90% specificity. This level of performance corresponds to true positives in 78% and 41% of individual eyes, and false positives in 56% and 17% of individual eyes at the high sensitivity and high specificity points, respectively. Moreover, we show that automatic tissue segmentation can identify anatomical changes before conversion and high-risk subgroups. This AI system overcomes substantial interobserver variability in expert predictions, performing better than five out of six experts, and demonstrates the potential of using AI to predict disease progression.		20200518	https://pubmed.ncbi.nlm.nih.gov/32424211
Raghunath, Sushravya; Ulloa Cerna, Alvaro E; Jing, Linyuan; vanMaanen, David P; Stough, Joshua; Hartzel, Dustin N; Leader, Joseph B; Kirchner, H Lester; Stumpe, Martin C; Hafez, Ashraf; Nemani, Arun; Carbonati, Tanner; Johnson, Kipp W; Young, Katelyn; Good, Christopher W; Pfeifer, John M; Patel, Aalpen A; Delisle, Brian P; Alsaid, Amro; Beer, Dominik; Haggerty, Christopher M; Fornwalt, Brandon K	Prediction of mortality from 12-lead electrocardiogram voltage data using a deep neural network.	Nat Med	2020	Nat Med. 2020 Jun;26(6):886-891. doi: 10.1038/s41591-020-0870-z. Epub 2020 May 11.	The electrocardiogram (ECG) is a widely used medical test, consisting of voltage versus time traces collected from surface recordings over the heart(1). Here we hypothesized that a deep neural network (DNN) can predict an important future clinical event, 1-year all-cause mortality, from ECG voltage-time traces. By using ECGs collected over a 34-year period in a large regional health system, we trained a DNN with 1,169,662 12-lead resting ECGs obtained from 253,397 patients, in which 99,371 events occurred. The model achieved an area under the curve (AUC) of 0.88 on a held-out test set of 168,914 patients, in which 14,207 events occurred. Even within the large subset of patients (n = 45,285) with ECGs interpreted as 'normal' by a physician, the performance of the model in predicting 1-year mortality remained high (AUC = 0.85). A blinded survey of cardiologists demonstrated that many of the discriminating features of these normal ECGs were not apparent to expert reviewers. Finally, a Cox proportional-hazard model revealed a hazard ratio of 9.5 (P < 0.005) for the two predicted groups (dead versus alive 1 year after ECG) over a 25-year follow-up period. These results show that deep learning can add substantial prognostic information to the interpretation of 12-lead resting ECGs, even in cases that are interpreted as normal by physicians.		20200511	https://pubmed.ncbi.nlm.nih.gov/32393799
Han, Xintian; Hu, Yuxuan; Foschini, Luca; Chinitz, Larry; Jankelson, Lior; Ranganath, Rajesh	Deep learning models for electrocardiograms are susceptible to adversarial attack.	Nat Med	2020	Nat Med. 2020 Mar;26(3):360-363. doi: 10.1038/s41591-020-0791-x. Epub 2020 Mar 9.	Electrocardiogram (ECG) acquisition is increasingly widespread in medical and commercial devices, necessitating the development of automated interpretation strategies. Recently, deep neural networks have been used to automatically analyze ECG tracings and outperform physicians in detecting certain rhythm irregularities(1). However, deep learning classifiers are susceptible to adversarial examples, which are created from raw data to fool the classifier such that it assigns the example to the wrong class, but which are undetectable to the human eye(2,3). Adversarial examples have also been created for medical-related tasks(4,5). However, traditional attack methods to create adversarial examples do not extend directly to ECG signals, as such methods introduce square-wave artefacts that are not physiologically plausible. Here we develop a method to construct smoothed adversarial examples for ECG tracings that are invisible to human expert evaluation and show that a deep learning model for arrhythmia detection from single-lead ECG(6) is vulnerable to this type of attack. Moreover, we provide a general technique for collating and perturbing known adversarial examples to create multiple new ones. The susceptibility of deep learning ECG algorithms to adversarial misclassification implies that care should be taken when evaluating these models on ECGs that may have been altered, particularly when incentives for causing misclassification exist.		20200309	https://pubmed.ncbi.nlm.nih.gov/32152582
Morse, Keith E; Bagley, Steven C; Shah, Nigam H	Estimate the hidden deployment cost of predictive models to improve patient care.	Nat Med	2020	Nat Med. 2020 Jan;26(1):18-19. doi: 10.1038/s41591-019-0651-8.	?		?	https://pubmed.ncbi.nlm.nih.gov/31932778
Hollon, Todd C; Pandian, Balaji; Adapa, Arjun R; Urias, Esteban; Save, Akshay V; Khalsa, Siri Sahib S; Eichberg, Daniel G; D'Amico, Randy S; Farooq, Zia U; Lewis, Spencer; Petridis, Petros D; Marie, Tamara; Shah, Ashish H; Garton, Hugh J L; Maher, Cormac O; Heth, Jason A; McKean, Erin L; Sullivan, Stephen E; Hervey-Jumper, Shawn L; Patil, Parag G; Thompson, B Gregory; Sagher, Oren; McKhann, Guy M 2nd; Komotar, Ricardo J; Ivan, Michael E; Snuderl, Matija; Otten, Marc L; Johnson, Timothy D; Sisti, Michael B; Bruce, Jeffrey N; Muraszko, Karin M; Trautman, Jay; Freudiger, Christian W; Canoll, Peter; Lee, Honglak; Camelo-Piragua, Sandra; Orringer, Daniel A	Near real-time intraoperative brain tumor diagnosis using stimulated Raman histology and deep neural networks.	Nat Med	2020	Nat Med. 2020 Jan;26(1):52-58. doi: 10.1038/s41591-019-0715-9. Epub 2020 Jan 6.	Intraoperative diagnosis is essential for providing safe and effective care during cancer surgery(1). The existing workflow for intraoperative diagnosis based on hematoxylin and eosin staining of processed tissue is time, resource and labor intensive(2,3). Moreover, interpretation of intraoperative histologic images is dependent on a contracting, unevenly distributed, pathology workforce(4). In the present study, we report a parallel workflow that combines stimulated Raman histology (SRH)(5-7), a label-free optical imaging method and deep convolutional neural networks (CNNs) to predict diagnosis at the bedside in near real-time in an automated fashion. Specifically, our CNNs, trained on over 2.5 million SRH images, predict brain tumor diagnosis in the operating room in under 150 s, an order of magnitude faster than conventional techniques (for example, 20-30 min)(2). In a multicenter, prospective clinical trial (n = 278), we demonstrated that CNN-based diagnosis of SRH images was noninferior to pathologist-based interpretation of conventional histologic images (overall accuracy, 94.6% versus 93.9%). Our CNNs learned a hierarchy of recognizable histologic feature representations to classify the major histopathologic classes of brain tumors. In addition, we implemented a semantic segmentation method to identify tumor-infiltrated diagnostic regions within SRH images. These results demonstrate how intraoperative cancer diagnosis can be streamlined, creating a complementary pathway for tissue diagnosis that is independent of a traditional pathology laboratory.		20200106	https://pubmed.ncbi.nlm.nih.gov/31907460
Courtiol, Pierre; Maussion, Charles; Moarii, Matahi; Pronier, Elodie; Pilcer, Samuel; Sefta, Meriem; Manceron, Pierre; Toldo, Sylvain; Zaslavskiy, Mikhail; Le Stang, Nolwenn; Girard, Nicolas; Elemento, Olivier; Nicholson, Andrew G; Blay, Jean-Yves; Galateau-Salle, Francoise; Wainrib, Gilles; Clozel, Thomas	Deep learning-based classification of mesothelioma improves prediction of patient outcome.	Nat Med	2019	Nat Med. 2019 Oct;25(10):1519-1525. doi: 10.1038/s41591-019-0583-3. Epub 2019 Oct 7.	Malignant mesothelioma (MM) is an aggressive cancer primarily diagnosed on the basis of histological criteria(1). The 2015 World Health Organization classification subdivides mesothelioma tumors into three histological types: epithelioid, biphasic and sarcomatoid MM. MM is a highly complex and heterogeneous disease, rendering its diagnosis and histological typing difficult and leading to suboptimal patient care and decisions regarding treatment modalities(2). Here we have developed a new approach-based on deep convolutional neural networks-called MesoNet to accurately predict the overall survival of mesothelioma patients from whole-slide digitized images, without any pathologist-provided locally annotated regions. We validated MesoNet on both an internal validation cohort from the French MESOBANK and an independent cohort from The Cancer Genome Atlas (TCGA). We also demonstrated that the model was more accurate in predicting patient survival than using current pathology practices. Furthermore, unlike classical black-box deep learning methods, MesoNet identified regions contributing to patient outcome prediction. Strikingly, we found that these regions are mainly located in the stroma and are histological features associated with inflammation, cellular diversity and vacuolization. These findings suggest that deep learning models can identify new features predictive of patient survival and potentially lead to new biomarker discoveries.		20191007	https://pubmed.ncbi.nlm.nih.gov/31591589
Campanella, Gabriele; Hanna, Matthew G; Geneslaw, Luke; Miraflor, Allen; Werneck Krauss Silva, Vitor; Busam, Klaus J; Brogi, Edi; Reuter, Victor E; Klimstra, David S; Fuchs, Thomas J	Clinical-grade computational pathology using weakly supervised deep learning on whole slide images.	Nat Med	2019	Nat Med. 2019 Aug;25(8):1301-1309. doi: 10.1038/s41591-019-0508-1. Epub 2019 Jul 15.	The development of decision support systems for pathology and their deployment in clinical practice have been hindered by the need for large manually annotated datasets. To overcome this problem, we present a multiple instance learning-based deep learning system that uses only the reported diagnoses as labels for training, thereby avoiding expensive and time-consuming pixel-wise manual annotations. We evaluated this framework at scale on a dataset of 44,732 whole slide images from 15,187 patients without any form of data curation. Tests on prostate cancer, basal cell carcinoma and breast cancer metastases to axillary lymph nodes resulted in areas under the curve above 0.98 for all cancer types. Its clinical application would allow pathologists to exclude 65-75% of slides while retaining 100% sensitivity. Our results show that this system has the ability to train accurate classification models at unprecedented scale, laying the foundation for the deployment of computational decision support systems in clinical practice.		20190715	https://pubmed.ncbi.nlm.nih.gov/31308507
Ardila, Diego; Kiraly, Atilla P; Bharadwaj, Sujeeth; Choi, Bokyung; Reicher, Joshua J; Peng, Lily; Tse, Daniel; Etemadi, Mozziyar; Ye, Wenxing; Corrado, Greg; Naidich, David P; Shetty, Shravya	Author Correction: End-to-end lung cancer screening with three-dimensional deep learning on low-dose chest computed tomography.	Nat Med	2019	Nat Med. 2019 Aug;25(8):1319. doi: 10.1038/s41591-019-0536-x.	An amendment to this paper has been published and can be accessed via a link at the top of the paper.		?	https://pubmed.ncbi.nlm.nih.gov/31253948
Kather, Jakob Nikolas; Pearson, Alexander T; Halama, Niels; Jager, Dirk; Krause, Jeremias; Loosen, Sven H; Marx, Alexander; Boor, Peter; Tacke, Frank; Neumann, Ulf Peter; Grabsch, Heike I; Yoshikawa, Takaki; Brenner, Hermann; Chang-Claude, Jenny; Hoffmeister, Michael; Trautwein, Christian; Luedde, Tom	Deep learning can predict microsatellite instability directly from histology in gastrointestinal cancer.	Nat Med	2019	Nat Med. 2019 Jul;25(7):1054-1056. doi: 10.1038/s41591-019-0462-y. Epub 2019 Jun 3.	Microsatellite instability determines whether patients with gastrointestinal cancer respond exceptionally well to immunotherapy. However, in clinical practice, not every patient is tested for MSI, because this requires additional genetic or immunohistochemical tests. Here we show that deep residual learning can predict MSI directly from H&E histology, which is ubiquitously available. This approach has the potential to provide immunotherapy to a much broader subset of patients with gastrointestinal cancer.		20190603	https://pubmed.ncbi.nlm.nih.gov/31160815
Ardila, Diego; Kiraly, Atilla P; Bharadwaj, Sujeeth; Choi, Bokyung; Reicher, Joshua J; Peng, Lily; Tse, Daniel; Etemadi, Mozziyar; Ye, Wenxing; Corrado, Greg; Naidich, David P; Shetty, Shravya	End-to-end lung cancer screening with three-dimensional deep learning on low-dose chest computed tomography.	Nat Med	2019	Nat Med. 2019 Jun;25(6):954-961. doi: 10.1038/s41591-019-0447-x. Epub 2019 May 20.	With an estimated 160,000 deaths in 2018, lung cancer is the most common cause of cancer death in the United States(1). Lung cancer screening using low-dose computed tomography has been shown to reduce mortality by 20-43% and is now included in US screening guidelines(1-6). Existing challenges include inter-grader variability and high false-positive and false-negative rates(7-10). We propose a deep learning algorithm that uses a patient's current and prior computed tomography volumes to predict the risk of lung cancer. Our model achieves a state-of-the-art performance (94.4% area under the curve) on 6,716 National Lung Cancer Screening Trial cases, and performs similarly on an independent clinical validation set of 1,139 cases. We conducted two reader studies. When prior computed tomography imaging was not available, our model outperformed all six radiologists with absolute reductions of 11% in false positives and 5% in false negatives. Where prior computed tomography imaging was available, the model performance was on-par with the same radiologists. This creates an opportunity to optimize the screening process via computer assistance and automation. While the vast majority of patients remain unscreened, we show the potential for deep learning models to increase the accuracy, consistency and adoption of lung cancer screening worldwide.		20190520	https://pubmed.ncbi.nlm.nih.gov/31110349
Liang, Huiying; Tsui, Brian Y; Ni, Hao; Valentim, Carolina C S; Baxter, Sally L; Liu, Guangjian; Cai, Wenjia; Kermany, Daniel S; Sun, Xin; Chen, Jiancong; He, Liya; Zhu, Jie; Tian, Pin; Shao, Hua; Zheng, Lianghong; Hou, Rui; Hewett, Sierra; Li, Gen; Liang, Ping; Zang, Xuan; Zhang, Zhiqi; Pan, Liyan; Cai, Huimin; Ling, Rujuan; Li, Shuhua; Cui, Yongwang; Tang, Shusheng; Ye, Hong; Huang, Xiaoyan; He, Waner; Liang, Wenqing; Zhang, Qing; Jiang, Jianmin; Yu, Wei; Gao, Jianqun; Ou, Wanxing; Deng, Yingmin; Hou, Qiaozhen; Wang, Bei; Yao, Cuichan; Liang, Yan; Zhang, Shu; Duan, Yaou; Zhang, Runze; Gibson, Sarah; Zhang, Charlotte L; Li, Oulan; Zhang, Edward D; Karin, Gabriel; Nguyen, Nathan; Wu, Xiaokang; Wen, Cindy; Xu, Jie; Xu, Wenqin; Wang, Bochu; Wang, Winston; Li, Jing; Pizzato, Bianca; Bao, Caroline; Xiang, Daoman; He, Wanting; He, Suiqin; Zhou, Yugui; Haw, Weldon; Goldbaum, Michael; Tremoulet, Adriana; Hsu, Chun-Nan; Carter, Hannah; Zhu, Long; Zhang, Kang; Xia, Huimin	Evaluation and accurate diagnoses of pediatric diseases using artificial intelligence.	Nat Med	2019	Nat Med. 2019 Mar;25(3):433-438. doi: 10.1038/s41591-018-0335-9. Epub 2019 Feb 11.	Artificial intelligence (AI)-based methods have emerged as powerful tools to transform medical care. Although machine learning classifiers (MLCs) have already demonstrated strong performance in image-based diagnoses, analysis of diverse and massive electronic health record (EHR) data remains challenging. Here, we show that MLCs can query EHRs in a manner similar to the hypothetico-deductive reasoning used by physicians and unearth associations that previous statistical methods have not found. Our model applies an automated natural language processing system using deep learning techniques to extract clinically relevant information from EHRs. In total, 101.6 million data points from 1,362,559 pediatric patient visits presenting to a major referral center were analyzed to train and validate the framework. Our model demonstrates high diagnostic accuracy across multiple organ systems and is comparable to experienced pediatricians in diagnosing common childhood diseases. Our study provides a proof of concept for implementing an AI-based system as a means to aid physicians in tackling large amounts of data, augmenting diagnostic evaluations, and to provide clinical decision support in cases of diagnostic uncertainty or complexity. Although this impact may be most evident in areas where healthcare providers are in relative shortage, the benefits of such an AI system are likely to be universal.		20190211	https://pubmed.ncbi.nlm.nih.gov/30742121
Topol, Eric J	High-performance medicine: the convergence of human and artificial intelligence.	Nat Med	2019	Nat Med. 2019 Jan;25(1):44-56. doi: 10.1038/s41591-018-0300-7. Epub 2019 Jan 7.	The use of artificial intelligence, and the deep-learning subtype in particular, has been enabled by the use of labeled big data, along with markedly enhanced computing power and cloud storage, across all sectors. In medicine, this is beginning to have an impact at three levels: for clinicians, predominantly via rapid, accurate image interpretation; for health systems, by improving workflow and the potential for reducing medical errors; and for patients, by enabling them to process their own data to promote health. The current limitations, including bias, privacy and security, and lack of transparency, along with the future directions of these applications will be discussed in this article. Over time, marked improvements in accuracy, productivity, and workflow will likely be actualized, but whether that will be used to improve the patient-doctor relationship or facilitate its erosion remains to be seen.		20190107	https://pubmed.ncbi.nlm.nih.gov/30617339
Norgeot, Beau; Glicksberg, Benjamin S; Butte, Atul J	A call for deep-learning healthcare.	Nat Med	2019	Nat Med. 2019 Jan;25(1):14-15. doi: 10.1038/s41591-018-0320-3.	?		?	https://pubmed.ncbi.nlm.nih.gov/30617337
Esteva, Andre; Robicquet, Alexandre; Ramsundar, Bharath; Kuleshov, Volodymyr; DePristo, Mark; Chou, Katherine; Cui, Claire; Corrado, Greg; Thrun, Sebastian; Dean, Jeff	A guide to deep learning in healthcare.	Nat Med	2019	Nat Med. 2019 Jan;25(1):24-29. doi: 10.1038/s41591-018-0316-z. Epub 2019 Jan 7.	Here we present deep-learning techniques for healthcare, centering our discussion on deep learning in computer vision, natural language processing, reinforcement learning, and generalized methods. We describe how these computational techniques can impact a few key areas of medicine and explore how to build end-to-end systems. Our discussion of computer vision focuses largely on medical imaging, and we describe the application of natural language processing to domains such as electronic health record data. Similarly, reinforcement learning is discussed in the context of robotic-assisted surgery, and generalized deep-learning methods for genomics are reviewed.		20190107	https://pubmed.ncbi.nlm.nih.gov/30617335
Gottesman, Omer; Johansson, Fredrik; Komorowski, Matthieu; Faisal, Aldo; Sontag, David; Doshi-Velez, Finale; Celi, Leo Anthony	Guidelines for reinforcement learning in healthcare.	Nat Med	2019	Nat Med. 2019 Jan;25(1):16-18. doi: 10.1038/s41591-018-0310-5.	?		?	https://pubmed.ncbi.nlm.nih.gov/30617332
Gurovich, Yaron; Hanani, Yair; Bar, Omri; Nadav, Guy; Fleischer, Nicole; Gelbman, Dekel; Basel-Salmon, Lina; Krawitz, Peter M; Kamphausen, Susanne B; Zenker, Martin; Bird, Lynne M; Gripp, Karen W	Identifying facial phenotypes of genetic disorders using deep learning.	Nat Med	2019	Nat Med. 2019 Jan;25(1):60-64. doi: 10.1038/s41591-018-0279-0. Epub 2019 Jan 7.	Syndromic genetic conditions, in aggregate, affect 8% of the population(1). Many syndromes have recognizable facial features(2) that are highly informative to clinical geneticists(3-5). Recent studies show that facial analysis technologies measured up to the capabilities of expert clinicians in syndrome identification(6-9). However, these technologies identified only a few disease phenotypes, limiting their role in clinical settings, where hundreds of diagnoses must be considered. Here we present a facial image analysis framework, DeepGestalt, using computer vision and deep-learning algorithms, that quantifies similarities to hundreds of syndromes. DeepGestalt outperformed clinicians in three initial experiments, two with the goal of distinguishing subjects with a target syndrome from other syndromes, and one of separating different genetic subtypes in Noonan syndrome. On the final experiment reflecting a real clinical setting problem, DeepGestalt achieved 91% top-10 accuracy in identifying the correct syndrome on 502 different images. The model was trained on a dataset of over 17,000 images representing more than 200 syndromes, curated through a community-driven phenotyping platform. DeepGestalt potentially adds considerable value to phenotypic evaluations in clinical genetics, genetic testing, research and precision medicine.		20190107	https://pubmed.ncbi.nlm.nih.gov/30617323
Abbott, Brianna	Deeper learning.	Nat Med	2019	Nat Med. 2019 Jan;25(1):9-11. doi: 10.1038/s41591-018-0313-2.	?		?	https://pubmed.ncbi.nlm.nih.gov/30617322
Hannun, Awni Y; Rajpurkar, Pranav; Haghpanahi, Masoumeh; Tison, Geoffrey H; Bourn, Codie; Turakhia, Mintu P; Ng, Andrew Y	Cardiologist-level arrhythmia detection and classification in ambulatory electrocardiograms using a deep neural network.	Nat Med	2019	Nat Med. 2019 Jan;25(1):65-69. doi: 10.1038/s41591-018-0268-3. Epub 2019 Jan 7.	Computerized electrocardiogram (ECG) interpretation plays a critical role in the clinical ECG workflow(1). Widely available digital ECG data and the algorithmic paradigm of deep learning(2) present an opportunity to substantially improve the accuracy and scalability of automated ECG analysis. However, a comprehensive evaluation of an end-to-end deep learning approach for ECG analysis across a wide variety of diagnostic classes has not been previously reported. Here, we develop a deep neural network (DNN) to classify 12 rhythm classes using 91,232 single-lead ECGs from 53,549 patients who used a single-lead ambulatory ECG monitoring device. When validated against an independent test dataset annotated by a consensus committee of board-certified practicing cardiologists, the DNN achieved an average area under the receiver operating characteristic curve (ROC) of 0.97. The average F1 score, which is the harmonic mean of the positive predictive value and sensitivity, for the DNN (0.837) exceeded that of average cardiologists (0.780). With specificity fixed at the average specificity achieved by cardiologists, the sensitivity of the DNN exceeded the average cardiologist sensitivity for all rhythm classes. These findings demonstrate that an end-to-end deep learning approach can classify a broad range of distinct arrhythmias from single-lead ECGs with high diagnostic performance similar to that of cardiologists. If confirmed in clinical settings, this approach could reduce the rate of misdiagnosed computerized ECG interpretations and improve the efficiency of expert human ECG interpretation by accurately triaging or prioritizing the most urgent conditions.		20190107	https://pubmed.ncbi.nlm.nih.gov/30617320
Arnaout, Rima	Toward a clearer picture of health.	Nat Med	2019	Nat Med. 2019 Jan;25(1):12. doi: 10.1038/s41591-018-0318-x.	?		?	https://pubmed.ncbi.nlm.nih.gov/30613101
Schwemmer, Michael A; Skomrock, Nicholas D; Sederberg, Per B; Ting, Jordyn E; Sharma, Gaurav; Bockbrader, Marcia A; Friedenberg, David A	Meeting brain-computer interface user performance expectations using a deep neural network decoding framework.	Nat Med	2018	Nat Med. 2018 Nov;24(11):1669-1676. doi: 10.1038/s41591-018-0171-y. Epub 2018 Sep 24.	Brain-computer interface (BCI) neurotechnology has the potential to reduce disability associated with paralysis by translating neural activity into control of assistive devices(1-9). Surveys of potential end-users have identified key BCI system features(10-14), including high accuracy, minimal daily setup, rapid response times, and multifunctionality. These performance characteristics are primarily influenced by the BCI's neural decoding algorithm(1,15), which is trained to associate neural activation patterns with intended user actions. Here, we introduce a new deep neural network(16) decoding framework for BCI systems enabling discrete movements that addresses these four key performance characteristics. Using intracortical data from a participant with tetraplegia, we provide offline results demonstrating that our decoder is highly accurate, sustains this performance beyond a year without explicit daily retraining by combining it with an unsupervised updating procedure(3,17-20), responds faster than competing methods(8), and can increase functionality with minimal retraining by using a technique known as transfer learning(21). We then show that our participant can use the decoder in real-time to reanimate his paralyzed forearm with functional electrical stimulation (FES), enabling accurate manipulation of three objects from the grasp and release test (GRT)(22). These results demonstrate that deep neural network decoders can advance the clinical translation of BCI technology.		20180924	https://pubmed.ncbi.nlm.nih.gov/30250141
Coudray, Nicolas; Ocampo, Paolo Santiago; Sakellaropoulos, Theodore; Narula, Navneet; Snuderl, Matija; Fenyo, David; Moreira, Andre L; Razavian, Narges; Tsirigos, Aristotelis	Classification and mutation prediction from non-small cell lung cancer histopathology images using deep learning.	Nat Med	2018	Nat Med. 2018 Oct;24(10):1559-1567. doi: 10.1038/s41591-018-0177-5. Epub 2018 Sep 17.	Visual inspection of histopathology slides is one of the main methods used by pathologists to assess the stage, type and subtype of lung tumors. Adenocarcinoma (LUAD) and squamous cell carcinoma (LUSC) are the most prevalent subtypes of lung cancer, and their distinction requires visual inspection by an experienced pathologist. In this study, we trained a deep convolutional neural network (inception v3) on whole-slide images obtained from The Cancer Genome Atlas to accurately and automatically classify them into LUAD, LUSC or normal lung tissue. The performance of our method is comparable to that of pathologists, with an average area under the curve (AUC) of 0.97. Our model was validated on independent datasets of frozen tissues, formalin-fixed paraffin-embedded tissues and biopsies. Furthermore, we trained the network to predict the ten most commonly mutated genes in LUAD. We found that six of them-STK11, EGFR, FAT1, SETBP1, KRAS and TP53-can be predicted from pathology images, with AUCs from 0.733 to 0.856 as measured on a held-out population. These findings suggest that deep-learning models can assist pathologists in the detection of cancer subtype or gene mutations. Our approach can be applied to any cancer type, and the code is available at https://github.com/ncoudray/DeepPATH .		20180917	https://pubmed.ncbi.nlm.nih.gov/30224757
Lynch, Charles J; Liston, Conor	New machine-learning technologies for computer-aided diagnosis.	Nat Med	2018	Nat Med. 2018 Sep;24(9):1304-1305. doi: 10.1038/s41591-018-0178-4.	?		?	https://pubmed.ncbi.nlm.nih.gov/30177823
De Fauw, Jeffrey; Ledsam, Joseph R; Romera-Paredes, Bernardino; Nikolov, Stanislav; Tomasev, Nenad; Blackwell, Sam; Askham, Harry; Glorot, Xavier; O'Donoghue, Brendan; Visentin, Daniel; van den Driessche, George; Lakshminarayanan, Balaji; Meyer, Clemens; Mackinder, Faith; Bouton, Simon; Ayoub, Kareem; Chopra, Reena; King, Dominic; Karthikesalingam, Alan; Hughes, Cian O; Raine, Rosalind; Hughes, Julian; Sim, Dawn A; Egan, Catherine; Tufail, Adnan; Montgomery, Hugh; Hassabis, Demis; Rees, Geraint; Back, Trevor; Khaw, Peng T; Suleyman, Mustafa; Cornebise, Julien; Keane, Pearse A; Ronneberger, Olaf	Clinically applicable deep learning for diagnosis and referral in retinal disease.	Nat Med	2018	Nat Med. 2018 Sep;24(9):1342-1350. doi: 10.1038/s41591-018-0107-6. Epub 2018 Aug 13.	The volume and complexity of diagnostic imaging is increasing at a pace faster than the availability of human expertise to interpret it. Artificial intelligence has shown great promise in classifying two-dimensional photographs of some common diseases and typically relies on databases of millions of annotated images. Until now, the challenge of reaching the performance of expert clinicians in a real-world clinical pathway with three-dimensional diagnostic scans has remained unsolved. Here, we apply a novel deep learning architecture to a clinically heterogeneous set of three-dimensional optical coherence tomography scans from patients referred to a major eye hospital. We demonstrate performance in making a referral recommendation that reaches or exceeds that of experts on a range of sight-threatening retinal diseases after training on only 14,884 scans. Moreover, we demonstrate that the tissue segmentations produced by our architecture act as a device-independent representation; referral accuracy is maintained when using tissue segmentations from a different type of device. Our work removes previous barriers to wider clinical use without prohibitive training data requirements across multiple pathologies in a real-world setting.		20180813	https://pubmed.ncbi.nlm.nih.gov/30104768
Ting, Daniel S W; Liu, Yong; Burlina, Philippe; Xu, Xinxing; Bressler, Neil M; Wong, Tien Y	AI for medical imaging goes deep.	Nat Med	2018	Nat Med. 2018 May;24(5):539-540. doi: 10.1038/s41591-018-0029-3.	?		?	https://pubmed.ncbi.nlm.nih.gov/29736024
Richerson, George B; Bekkers, John M	Learning to take a deep breath--with BDNF.	Nat Med	2004	Nat Med. 2004 Jan;10(1):25-6. doi: 10.1038/nm0104-25.	?		?	https://pubmed.ncbi.nlm.nih.gov/14702628
