Authors	Title	Journal	Year	Publication_citation	Abstract	Keywords	Date_epublished	PMID
Gottlieb, Klaus; Requa, James; Karnes, William; Chandra Gudivada, Ranga; Shen, Jie; Rael, Efren; Arora, Vipin; Dao, Tyler; Ninh, Andrew; McGill, James	Central Reading of Ulcerative Colitis Clinical Trial Videos Using Neural Networks.	Gastroenterology	2021	Gastroenterology. 2021 Feb;160(3):710-719.e2. doi: 10.1053/j.gastro.2020.10.024. Epub 2020 Oct 21.	BACKGROUND AND AIMS: Endoscopic disease activity scoring in ulcerative colitis (UC) is useful in clinical practice but done infrequently. It is required in clinical trials, where it is expensive and slow because human central readers are needed. A machine learning algorithm automating the process could elevate clinical care and facilitate clinical research. Prior work using single-institution databases and endoscopic still images has been promising. METHODS: Seven hundred and ninety-five full-length endoscopy videos were prospectively collected from a phase 2 trial of mirikizumab with 249 patients from 14 countries, totaling 19.5 million image frames. Expert central readers assigned each full-length endoscopy videos 1 endoscopic Mayo score (eMS) and 1 Ulcerative Colitis Endoscopic Index of Severity (UCEIS) score. Initially, video data were cleaned and abnormality features extracted using convolutional neural networks. Subsequently, a recurrent neural network was trained on the features to predict eMS and UCEIS from individual full-length endoscopy videos. RESULTS: The primary metric to assess the performance of the recurrent neural network model was quadratic weighted kappa (QWK) comparing the agreement of the machine-read endoscopy score with the human central reader score. QWK progressively penalizes disagreements that exceed 1 level. The model's agreement metric was excellent, with a QWK of 0.844 (95% confidence interval, 0.787-0.901) for eMS and 0.855 (95% confidence interval, 0.80-0.91) for UCEIS. CONCLUSIONS: We found that a deep learning algorithm can be trained to predict levels of UC severity from full-length endoscopy videos. Our data set was prospectively collected in a multinational clinical trial, videos rather than still images were used, UCEIS and eMS were reported, and machine learning algorithm performance metrics met or exceeded those previously published for UC severity scores.	Computer Vision; Efficacy End Points; Endoscopic Scores; Machine Learning	20201021	https://pubmed.ncbi.nlm.nih.gov/33098883
Echle, Amelie; Grabsch, Heike Irmgard; Quirke, Philip; van den Brandt, Piet A; West, Nicholas P; Hutchins, Gordon G A; Heij, Lara R; Tan, Xiuxiang; Richman, Susan D; Krause, Jeremias; Alwers, Elizabeth; Jenniskens, Josien; Offermans, Kelly; Gray, Richard; Brenner, Hermann; Chang-Claude, Jenny; Trautwein, Christian; Pearson, Alexander T; Boor, Peter; Luedde, Tom; Gaisa, Nadine Therese; Hoffmeister, Michael; Kather, Jakob Nikolas	Clinical-Grade Detection of Microsatellite Instability in Colorectal Tumors by Deep Learning.	Gastroenterology	2020	Gastroenterology. 2020 Oct;159(4):1406-1416.e11. doi: 10.1053/j.gastro.2020.06.021. Epub 2020 Jun 17.	BACKGROUND & AIMS: Microsatellite instability (MSI) and mismatch-repair deficiency (dMMR) in colorectal tumors are used to select treatment for patients. Deep learning can detect MSI and dMMR in tumor samples on routine histology slides faster and less expensively than molecular assays. However, clinical application of this technology requires high performance and multisite validation, which have not yet been performed. METHODS: We collected H&E-stained slides and findings from molecular analyses for MSI and dMMR from 8836 colorectal tumors (of all stages) included in the MSIDETECT consortium study, from Germany, the Netherlands, the United Kingdom, and the United States. Specimens with dMMR were identified by immunohistochemistry analyses of tissue microarrays for loss of MLH1, MSH2, MSH6, and/or PMS2. Specimens with MSI were identified by genetic analyses. We trained a deep-learning detector to identify samples with MSI from these slides; performance was assessed by cross-validation (N = 6406 specimens) and validated in an external cohort (n = 771 specimens). Prespecified endpoints were area under the receiver operating characteristic (AUROC) curve and area under the precision-recall curve (AUPRC). RESULTS: The deep-learning detector identified specimens with dMMR or MSI with a mean AUROC curve of 0.92 (lower bound, 0.91; upper bound, 0.93) and an AUPRC of 0.63 (range, 0.59-0.65), or 67% specificity and 95% sensitivity, in the cross-validation development cohort. In the validation cohort, the classifier identified samples with dMMR with an AUROC of 0.95 (range, 0.92-0.96) without image preprocessing and an AUROC of 0.96 (range, 0.93-0.98) after color normalization. CONCLUSIONS: We developed a deep-learning system that detects colorectal cancer specimens with dMMR or MSI using H&E-stained slides; it detected tissues with dMMR with an AUROC of 0.96 in a large, international validation cohort. This system might be used for high-throughput, low-cost evaluation of colorectal tissue specimens.	Lynch syndrome; biomarker; cancer immunotherapy; mutation	20200617	https://pubmed.ncbi.nlm.nih.gov/32562722
Wang, Pu; Liu, Peixi; Glissen Brown, Jeremy R; Berzin, Tyler M; Zhou, Guanyu; Lei, Shan; Liu, Xiaogang; Li, Liangping; Xiao, Xun	Lower Adenoma Miss Rate of Computer-Aided Detection-Assisted Colonoscopy vs Routine White-Light Colonoscopy in a Prospective Tandem Study.	Gastroenterology	2020	Gastroenterology. 2020 Oct;159(4):1252-1261.e5. doi: 10.1053/j.gastro.2020.06.023. Epub 2020 Jun 17.	BACKGROUND AND AIMS: Up to 30% of adenomas might be missed during screening colonoscopy-these could be polyps that appear on-screen but are not recognized by endoscopists or polyps that are in locations that do not appear on the screen at all. Computer-aided detection (CADe) systems, based on deep learning, might reduce rates of missed adenomas by displaying visual alerts that identify precancerous polyps on the endoscopy monitor in real time. We compared adenoma miss rates of CADe colonoscopy vs routine white-light colonoscopy. METHODS: We performed a prospective study of patients, 18-75 years old, referred for diagnostic, screening, or surveillance colonoscopies at a single endoscopy center of Sichuan Provincial People's Hospital from June 3, 2019 through September 24, 2019. Same day, tandem colonoscopies were performed for each participant by the same endoscopist. Patients were randomly assigned to groups that received either CADe colonoscopy (n=184) or routine colonoscopy (n=185) first, followed immediately by the other procedure. Endoscopists were blinded to the group each patient was assigned to until immediately before the start of each colonoscopy. Polyps that were missed by the CADe system but detected by endoscopists were classified as missed polyps. False polyps were those continuously traced by the CADe system but then determined not to be polyps by the endoscopists. The primary endpoint was adenoma miss rate, which was defined as the number of adenomas detected in the second-pass colonoscopy divided by the total number of adenomas detected in both passes. RESULTS: The adenoma miss rate was significantly lower with CADe colonoscopy (13.89%; 95% CI, 8.24%-19.54%) than with routine colonoscopy (40.00%; 95% CI, 31.23%-48.77%, P<.0001). The polyp miss rate was significantly lower with CADe colonoscopy (12.98%; 95% CI, 9.08%-16.88%) than with routine colonoscopy (45.90%; 95% CI, 39.65%-52.15%) (P<.0001). Adenoma miss rates in ascending, transverse, and descending colon were significantly lower with CADe colonoscopy than with routine colonoscopy (ascending colon 6.67% vs 39.13%; P=.0095; transverse colon 16.33% vs 45.16%; P=.0065; and descending colon 12.50% vs 40.91%, P=.0364). CONCLUSIONS: CADe colonoscopy reduced the overall miss rate of adenomas by endoscopists using white-light endoscopy. Routine use of CADe might reduce the incidence of interval colon cancers. chictr.org.cn study no: ChiCTR1900023086.	AMR; Artificial Intelligence; Early Detection; Neoplasm	20200617	https://pubmed.ncbi.nlm.nih.gov/32562721
Repici, Alessandro; Badalamenti, Matteo; Maselli, Roberta; Correale, Loredana; Radaelli, Franco; Rondonotti, Emanuele; Ferrara, Elisa; Spadaccini, Marco; Alkandari, Asma; Fugazza, Alessandro; Anderloni, Andrea; Galtieri, Piera Alessia; Pellegatta, Gaia; Carrara, Silvia; Di Leo, Milena; Craviotto, Vincenzo; Lamonaca, Laura; Lorenzetti, Roberto; Andrealli, Alida; Antonelli, Giulio; Wallace, Michael; Sharma, Prateek; Rosch, Thomas; Hassan, Cesare	Efficacy of Real-Time Computer-Aided Detection of Colorectal Neoplasia in a Randomized Trial.	Gastroenterology	2020	Gastroenterology. 2020 Aug;159(2):512-520.e7. doi: 10.1053/j.gastro.2020.04.062. Epub 2020 May 1.	BACKGROUND & AIMS: One-fourth of colorectal neoplasias are missed during screening colonoscopies; these can develop into colorectal cancer (CRC). Deep learning systems allow for real-time computer-aided detection (CADe) of polyps with high accuracy. We performed a multicenter, randomized trial to assess the safety and efficacy of a CADe system in detection of colorectal neoplasias during real-time colonoscopy. METHODS: We analyzed data from 685 subjects (61.32 +/- 10.2 years old; 337 men) undergoing screening colonoscopies for CRC, post-polypectomy surveillance, or workup due to positive results from a fecal immunochemical test or signs or symptoms of CRC, at 3 centers in Italy from September through November 2019. Patients were randomly assigned (1:1) to groups who underwent high-definition colonoscopies with the CADe system or without (controls). The CADe system included an artificial intelligence-based medical device (GI-Genius, Medtronic) trained to process colonoscopy images and superimpose them, in real time, on the endoscopy display a green box over suspected lesions. A minimum withdrawal time of 6 minutes was required. Lesions were collected and histopathology findings were used as the reference standard. The primary outcome was adenoma detection rate (ADR, the percentage of patients with at least 1 histologically proven adenoma or carcinoma). Secondary outcomes were adenomas detected per colonoscopy, non-neoplastic resection rate, and withdrawal time. RESULTS: The ADR was significantly higher in the CADe group (54.8%) than in the control group (40.4%) (relative risk [RR], 1.30; 95% confidence interval [CI], 1.14-1.45). Adenomas detected per colonoscopy were significantly higher in the CADe group (mean, 1.07 +/-1.54) than in the control group (mean 0.71 +/- 1.20) (incidence rate ratio, 1.46; 95% CI, 1.15-1.86). Adenomas 5 mm or smaller were detected in a significantly higher proportion of subjects in the CADe group (33.7%) than in the control group (26.5%; RR, 1.26; 95% CI, 1.01-1.52), as were adenomas of 6 to 9 mm (detected in 10.6% of subjects in the CADe group vs 5.8% in the control group; RR, 1.78; 95% CI, 1.09-2.86), regardless of morphology or location. There was no significant difference between groups in withdrawal time (417 +/- 101 seconds for the CADe group vs 435 +/- 149 for controls; P = .1) or proportion of subjects with resection of non-neoplastic lesions (26.0% in the CADe group vs 28.7% of controls; RR, 1.00; 95% CI, 0.90-1.12). CONCLUSIONS: In a multicenter, randomized trial, we found that including CADe in real-time colonoscopy significantly increases ADR and adenomas detected per colonoscopy without increasing withdrawal time. ClinicalTrials.gov no: 04079478.	Adenoma Per Colonoscopy; Artificial Intelligence; Comparison; Early Detection	20200501	https://pubmed.ncbi.nlm.nih.gov/32371116
Jin, Eun Hyo; Lee, Dongheon; Bae, Jung Ho; Kang, Hae Yeon; Kwak, Min-Sun; Seo, Ji Yeon; Yang, Jong In; Yang, Sun Young; Lim, Seon Hee; Yim, Jeong Yoon; Lim, Joo Hyun; Chung, Goh Eun; Chung, Su Jin; Choi, Ji Min; Han, Yoo Min; Kang, Seung Joo; Lee, Jooyoung; Chan Kim, Hee; Kim, Joo Sung	Improved Accuracy in Optical Diagnosis of Colorectal Polyps Using Convolutional Neural Networks with Visual Explanations.	Gastroenterology	2020	Gastroenterology. 2020 Jun;158(8):2169-2179.e8. doi: 10.1053/j.gastro.2020.02.036. Epub 2020 Feb 29.	BACKGROUND & AIMS: Narrow-band imaging (NBI) can be used to determine whether colorectal polyps are adenomatous or hyperplastic. We investigated whether an artificial intelligence (AI) system can increase the accuracy of characterizations of polyps by endoscopists of different skill levels. METHODS: We developed convolutional neural networks (CNNs) for evaluation of diminutive colorectal polyps, based on efficient neural architecture searches via parameter sharing with augmentation using NBIs of diminutive (</=5 mm) polyps, collected from October 2015 through October 2017 at the Seoul National University Hospital, Healthcare System Gangnam Center (training set). We trained the CNN using images from 1100 adenomatous polyps and 1050 hyperplastic polyps from 1379 patients. We then tested the system using 300 images of 180 adenomatous polyps and 120 hyperplastic polyps, obtained from January 2018 to May 2019. We compared the accuracy of 22 endoscopists of different skill levels (7 novices, 4 experts, and 11 NBI-trained experts) vs the CNN in evaluation of images (adenomatous vs hyperplastic) from 180 adenomatous and 120 hyperplastic polyps. The endoscopists then evaluated the polyp images with knowledge of the CNN-processed results. We conducted mixed-effect logistic and linear regression analyses to determine the effects of AI assistance on the accuracy of analysis of diminutive colorectal polyps by endoscopists (primary outcome). RESULTS: The CNN distinguished adenomatous vs hyperplastic diminutive polyps with 86.7% accuracy, based on histologic analysis as the reference standard. Endoscopists distinguished adenomatous vs hyperplastic diminutive polyps with 82.5% overall accuracy (novices, 73.8% accuracy; experts, 83.8% accuracy; and NBI-trained experts, 87.6% accuracy). With knowledge of the CNN-processed results, the overall accuracy of the endoscopists increased to 88.5% (P < .05). With knowledge of the CNN-processed results, the accuracy of novice endoscopists increased to 85.6% (P < .05). The CNN-processed results significantly reduced endoscopist time of diagnosis (from 3.92 to 3.37 seconds per polyp, P = .042). CONCLUSIONS: We developed a CNN that significantly increases the accuracy of evaluation of diminutive colorectal polyps (as adenomatous vs hyperplastic) and reduces the time of diagnosis by endoscopists. This AI assistance system significantly increased the accuracy of analysis by novice endoscopists, who achieved near-expert levels of accuracy without extra training. The CNN assistance system can reduce the skill-level dependence of endoscopists and costs.	Cancer Screening; Colorectal Cancer; Deep Learning; Diagnostic	20200229	https://pubmed.ncbi.nlm.nih.gov/32119927
Takenaka, Kento; Ohtsuka, Kazuo; Fujii, Toshimitsu; Negi, Mariko; Suzuki, Kohei; Shimizu, Hiromichi; Oshima, Shiori; Akiyama, Shintaro; Motobayashi, Maiko; Nagahori, Masakazu; Saito, Eiko; Matsuoka, Katsuyoshi; Watanabe, Mamoru	Development and Validation of a Deep Neural Network for Accurate Evaluation of Endoscopic Images From Patients With Ulcerative Colitis.	Gastroenterology	2020	Gastroenterology. 2020 Jun;158(8):2150-2157. doi: 10.1053/j.gastro.2020.02.012. Epub 2020 Feb 12.	BACKGROUND & AIMS: There are intra- and interobserver variations in endoscopic assessment of ulcerative colitis (UC) and biopsies are often collected for histologic evaluation. We sought to develop a deep neural network system for consistent, objective, and real-time analysis of endoscopic images from patients with UC. METHODS: We constructed the deep neural network for evaluation of UC (DNUC) algorithm using 40,758 images of colonoscopies and 6885 biopsy results from 2012 patients with UC who underwent colonoscopy from January 2014 through March 2018 at a single center in Japan (the training set). We validated the accuracy of the DNUC algorithm in a prospective study of 875 patients with UC who underwent colonoscopy from April 2018 through April 2019, with 4187 endoscopic images and 4104 biopsy specimens. Endoscopic remission was defined as a UC endoscopic index of severity score of 0; histologic remission was defined as a Geboes score of 3 points or less. RESULTS: In the prospective study, the DNUC identified patients with endoscopic remission with 90.1% accuracy (95% confidence interval [CI] 89.2%-90.9%) and a kappa coefficient of 0.798 (95% CI 0.780-0.814), using findings reported by endoscopists as the reference standard. The intraclass correlation coefficient between the DNUC and the endoscopists for UC endoscopic index of severity scoring was 0.917 (95% CI 0.911-0.921). The DNUC identified patients in histologic remission with 92.9% accuracy (95% CI 92.1%-93.7%); the kappa coefficient between the DNUC and the biopsy result was 0.859 (95% CI 0.841-0.875). CONCLUSIONS: We developed a deep neural network for evaluation of endoscopic images from patients with UC that identified those in endoscopic remission with 90.1% accuracy and histologic remission with 92.9% accuracy. The DNUC can therefore identify patients in remission without the need for mucosal biopsy collection and analysis. Trial number: UMIN000031430.	Artificial Intelligence; Diagnostic; IBD; Mucosal Healing	20200212	https://pubmed.ncbi.nlm.nih.gov/32060000
Thakkar, Shyam; Carleton, Neil M; Rao, Bharat; Syed, Aslam	Use of Artificial Intelligence-Based Analytics From Live Colonoscopies to Optimize the Quality of the Colonoscopy Examination in Real Time: Proof of Concept.	Gastroenterology	2020	Gastroenterology. 2020 Apr;158(5):1219-1221.e2. doi: 10.1053/j.gastro.2019.12.035. Epub 2020 Jan 13.	?		20200113	https://pubmed.ncbi.nlm.nih.gov/31945357
de Groof, Albert J; Struyvenberg, Maarten R; van der Putten, Joost; van der Sommen, Fons; Fockens, Kiki N; Curvers, Wouter L; Zinger, Sveta; Pouw, Roos E; Coron, Emmanuel; Baldaque-Silva, Francisco; Pech, Oliver; Weusten, Bas; Meining, Alexander; Neuhaus, Horst; Bisschops, Raf; Dent, John; Schoon, Erik J; de With, Peter H; Bergman, Jacques J	Deep-Learning System Detects Neoplasia in Patients With Barrett's Esophagus With Higher Accuracy Than Endoscopists in a Multistep Training and Validation Study With Benchmarking.	Gastroenterology	2020	Gastroenterology. 2020 Mar;158(4):915-929.e4. doi: 10.1053/j.gastro.2019.11.030. Epub 2019 Nov 22.	BACKGROUND & AIMS: We aimed to develop and validate a deep-learning computer-aided detection (CAD) system, suitable for use in real time in clinical practice, to improve endoscopic detection of early neoplasia in patients with Barrett's esophagus (BE). METHODS: We developed a hybrid ResNet-UNet model CAD system using 5 independent endoscopy data sets. We performed pretraining using 494,364 labeled endoscopic images collected from all intestinal segments. Then, we used 1704 unique esophageal high-resolution images of rigorously confirmed early-stage neoplasia in BE and nondysplastic BE, derived from 669 patients. System performance was assessed by using data sets 4 and 5. Data set 5 was also scored by 53 general endoscopists with a wide range of experience from 4 countries to benchmark CAD system performance. Coupled with histopathology findings, scoring of images that contained early-stage neoplasia in data sets 2-5 were delineated in detail for neoplasm position and extent by multiple experts whose evaluations served as the ground truth for segmentation. RESULTS: The CAD system classified images as containing neoplasms or nondysplastic BE with 89% accuracy, 90% sensitivity, and 88% specificity (data set 4, 80 patients and images). In data set 5 (80 patients and images) values for the CAD system vs those of the general endoscopists were 88% vs 73% accuracy, 93% vs 72% sensitivity, and 83% vs 74% specificity. The CAD system achieved higher accuracy than any of the individual 53 nonexpert endoscopists, with comparable delineation performance. CAD delineations of the area of neoplasm overlapped with those from the BE experts in all detected neoplasia in data sets 4 and 5. The CAD system identified the optimal site for biopsy of detected neoplasia in 97% and 92% of cases (data sets 4 and 5, respectively). CONCLUSIONS: We developed, validated, and benchmarked a deep-learning computer-aided system for primary detection of neoplasia in patients with BE. The system detected neoplasia with high accuracy and near-perfect delineation performance. The Netherlands National Trials Registry, Number: NTR7072.	Barrett surveillance; artificial intelligence; esophageal cancer; machine learning	20191122	https://pubmed.ncbi.nlm.nih.gov/31759929
Le Berre, Catherine; Sandborn, William J; Aridhi, Sabeur; Devignes, Marie-Dominique; Fournier, Laure; Smail-Tabbone, Malika; Danese, Silvio; Peyrin-Biroulet, Laurent	Application of Artificial Intelligence to Gastroenterology and Hepatology.	Gastroenterology	2020	Gastroenterology. 2020 Jan;158(1):76-94.e2. doi: 10.1053/j.gastro.2019.08.058. Epub 2019 Oct 5.	Since 2010, substantial progress has been made in artificial intelligence (AI) and its application to medicine. AI is explored in gastroenterology for endoscopic analysis of lesions, in detection of cancer, and to facilitate the analysis of inflammatory lesions or gastrointestinal bleeding during wireless capsule endoscopy. AI is also tested to assess liver fibrosis and to differentiate patients with pancreatic cancer from those with pancreatitis. AI might also be used to establish prognoses of patients or predict their response to treatments, based on multiple factors. We review the ways in which AI may help physicians make a diagnosis or establish a prognosis and discuss its limitations, knowing that further randomized controlled studies will be required before the approval of AI techniques by the health authorities.	Deep Learning; Digestive System; Machine Learning; Neural Network	20191005	https://pubmed.ncbi.nlm.nih.gov/31593701
Ding, Zhen; Shi, Huiying; Zhang, Hao; Meng, Lingjun; Fan, Mengke; Han, Chaoqun; Zhang, Kun; Ming, Fanhua; Xie, Xiaoping; Liu, Hao; Liu, Jun; Lin, Rong; Hou, Xiaohua	Gastroenterologist-Level Identification of Small-Bowel Diseases and Normal Variants by Capsule Endoscopy Using a Deep-Learning Model.	Gastroenterology	2019	Gastroenterology. 2019 Oct;157(4):1044-1054.e5. doi: 10.1053/j.gastro.2019.06.025. Epub 2019 Jun 25.	BACKGROUND & AIMS: Capsule endoscopy has revolutionized investigation of the small bowel. However, this technique produces a video that is 8-10 hours long, so analysis is time consuming for gastroenterologists. Deep convolutional neural networks (CNNs) can recognize specific images among a large variety. We aimed to develop a CNN-based algorithm to assist in the evaluation of small bowel capsule endoscopy (SB-CE) images. METHODS: We collected 113,426,569 images from 6970 patients who had SB-CE at 77 medical centers from July 2016 through July 2018. A CNN-based auxiliary reading model was trained to differentiate abnormal from normal images using 158,235 SB-CE images from 1970 patients. Images were categorized as normal, inflammation, ulcer, polyps, lymphangiectasia, bleeding, vascular disease, protruding lesion, lymphatic follicular hyperplasia, diverticulum, parasite, and other. The model was further validated in 5000 patients (no patient was overlap with the 1970 patients in the training set); the same patients were evaluated by conventional analysis and CNN-based auxiliary analysis by 20 gastroenterologists. If there was agreement in image categorization between the conventional analysis and CNN model, no further evaluation was performed. If there was disagreement between the conventional analysis and CNN model, the gastroenterologists re-evaluated the image to confirm or reject the CNN categorization. RESULTS: In the SB-CE images from the validation set, 4206 abnormalities in 3280 patients were identified after final consensus evaluation. The CNN-based auxiliary model identified abnormalities with 99.88% sensitivity in the per-patient analysis (95% CI, 99.67-99.96) and 99.90% sensitivity in the per-lesion analysis (95% CI, 99.74-99.97). Conventional reading by the gastroenterologists identified abnormalities with 74.57% sensitivity (95% CI, 73.05-76.03) in the per-patient analysis and 76.89% in the per-lesion analysis (95% CI, 75.58-78.15). The mean reading time per patient was 96.6 +/- 22.53 minutes by conventional reading and 5.9 +/- 2.23 minutes by CNN-based auxiliary reading (P < .001). CONCLUSIONS: We validated the ability of a CNN-based algorithm to identify abnormalities in SB-CE images. The CNN-based auxiliary model identified abnormalities with higher levels of sensitivity and significantly shorter reading times than conventional analysis by gastroenterologists. This algorithm provides an important tool to help gastroenterologists analyze SB-CE images more efficiently and more accurately.	Artificial Intelligence; Imaging; Intestine; Lesion	20190625	https://pubmed.ncbi.nlm.nih.gov/31251929
Urban, Gregor; Tripathi, Priyam; Alkayali, Talal; Mittal, Mohit; Jalali, Farid; Karnes, William; Baldi, Pierre	Deep Learning Localizes and Identifies Polyps in Real Time With 96% Accuracy in Screening Colonoscopy.	Gastroenterology	2018	Gastroenterology. 2018 Oct;155(4):1069-1078.e8. doi: 10.1053/j.gastro.2018.06.037. Epub 2018 Jun 18.	BACKGROUND & AIMS: The benefit of colonoscopy for colorectal cancer prevention depends on the adenoma detection rate (ADR). The ADR should reflect the adenoma prevalence rate, which is estimated to be higher than 50% in the screening-age population. However, the ADR by colonoscopists varies from 7% to 53%. It is estimated that every 1% increase in ADR lowers the risk of interval colorectal cancers by 3%-6%. New strategies are needed to increase the ADR during colonoscopy. We tested the ability of computer-assisted image analysis using convolutional neural networks (CNNs; a deep learning model for image analysis) to improve polyp detection, a surrogate of ADR. METHODS: We designed and trained deep CNNs to detect polyps using a diverse and representative set of 8,641 hand-labeled images from screening colonoscopies collected from more than 2000 patients. We tested the models on 20 colonoscopy videos with a total duration of 5 hours. Expert colonoscopists were asked to identify all polyps in 9 de-identified colonoscopy videos, which were selected from archived video studies, with or without benefit of the CNN overlay. Their findings were compared with those of the CNN using CNN-assisted expert review as the reference. RESULTS: When tested on manually labeled images, the CNN identified polyps with an area under the receiver operating characteristic curve of 0.991 and an accuracy of 96.4%. In the analysis of colonoscopy videos in which 28 polyps were removed, 4 expert reviewers identified 8 additional polyps without CNN assistance that had not been removed and identified an additional 17 polyps with CNN assistance (45 in total). All polyps removed and identified by expert review were detected by the CNN. The CNN had a false-positive rate of 7%. CONCLUSION: In a set of 8,641 colonoscopy images containing 4,088 unique polyps, the CNN identified polyps with a cross-validation accuracy of 96.4% and an area under the receiver operating characteristic curve of 0.991. The CNN system detected and localized polyps well within real-time constraints using an ordinary desktop machine with a contemporary graphics processing unit. This system could increase the ADR and decrease interval colorectal cancers but requires validation in large multicenter trials.	Adenoma Detection Rate Improving Technology; Colorectal Cancer Prevention; Convolutional Neural Networks; Machine Learning	20180618	https://pubmed.ncbi.nlm.nih.gov/29928897
Chen, Peng-Jen; Lin, Meng-Chiung; Lai, Mei-Ju; Lin, Jung-Chun; Lu, Henry Horng-Shing; Tseng, Vincent S	Accurate Classification of Diminutive Colorectal Polyps Using Computer-Aided Analysis.	Gastroenterology	2018	Gastroenterology. 2018 Feb;154(3):568-575. doi: 10.1053/j.gastro.2017.10.010. Epub 2017 Oct 16.	BACKGROUND & AIMS: Narrow-band imaging is an image-enhanced form of endoscopy used to observed microstructures and capillaries of the mucosal epithelium which allows for real-time prediction of histologic features of colorectal polyps. However, narrow-band imaging expertise is required to differentiate hyperplastic from neoplastic polyps with high levels of accuracy. We developed and tested a system of computer-aided diagnosis with a deep neural network (DNN-CAD) to analyze narrow-band images of diminutive colorectal polyps. METHODS: We collected 1476 images of neoplastic polyps and 681 images of hyperplastic polyps, obtained from the picture archiving and communications system database in a tertiary hospital in Taiwan. Histologic findings from the polyps were also collected and used as the reference standard. The images and data were used to train the DNN. A test set of images (96 hyperplastic and 188 neoplastic polyps, smaller than 5 mm), obtained from patients who underwent colonoscopies from March 2017 through August 2017, was then used to test the diagnostic ability of the DNN-CAD vs endoscopists (2 expert and 4 novice), who were asked to classify the images of the test set as neoplastic or hyperplastic. Their classifications were compared with findings from histologic analysis. The primary outcome measures were diagnostic accuracy, sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and diagnostic time. The accuracy, sensitivity, specificity, PPV, NPV, and diagnostic time were compared among DNN-CAD, the novice endoscopists, and the expert endoscopists. The study was designed to detect a difference of 10% in accuracy by a 2-sided McNemar test. RESULTS: In the test set, the DNN-CAD identified neoplastic or hyperplastic polyps with 96.3% sensitivity, 78.1% specificity, a PPV of 89.6%, and a NPV of 91.5%. Fewer than half of the novice endoscopists classified polyps with a NPV of 90% (their NPVs ranged from 73.9% to 84.0%). DNN-CAD classified polyps as neoplastic or hyperplastic in 0.45 +/- 0.07 seconds-shorter than the time required by experts (1.54 +/- 1.30 seconds) and nonexperts (1.77 +/- 1.37 seconds) (both P < .001). DNN-CAD classified polyps with perfect intra-observer agreement (kappa score of 1). There was a low level of intra-observer and inter-observer agreement in classification among endoscopists. CONCLUSIONS: We developed a system called DNN-CAD to identify neoplastic or hyperplastic colorectal polyps less than 5 mm. The system classified polyps with a PPV of 89.6%, and a NPV of 91.5%, and in a shorter time than endoscopists. This deep-learning model has potential for not only endoscopic image recognition but for other forms of medical image analysis, including sonography, computed tomography, and magnetic resonance images.	Colon Cancer Detection; Cost-effectiveness; Machine Learning; Magnifying	20171016	https://pubmed.ncbi.nlm.nih.gov/29042219
Saulnier, Delphine M; Riehle, Kevin; Mistretta, Toni-Ann; Diaz, Maria-Alejandra; Mandal, Debasmita; Raza, Sabeen; Weidler, Erica M; Qin, Xiang; Coarfa, Cristian; Milosavljevic, Aleksandar; Petrosino, Joseph F; Highlander, Sarah; Gibbs, Richard; Lynch, Susan V; Shulman, Robert J; Versalovic, James	Gastrointestinal microbiome signatures of pediatric patients with irritable bowel syndrome.	Gastroenterology	2011	Gastroenterology. 2011 Nov;141(5):1782-91. doi: 10.1053/j.gastro.2011.06.072. Epub 2011 Jul 8.	BACKGROUND & AIMS: The intestinal microbiomes of healthy children and pediatric patients with irritable bowel syndrome (IBS) are not well defined. Studies in adults have indicated that the gastrointestinal microbiota could be involved in IBS. METHODS: We analyzed 71 samples from 22 children with IBS (pediatric Rome III criteria) and 22 healthy children, ages 7-12 years, by 16S ribosomal RNA gene sequencing, with an average of 54,287 reads/stool sample (average 454 read length = 503 bases). Data were analyzed using phylogenetic-based clustering (Unifrac), or an operational taxonomic unit (OTU) approach using a supervised machine learning tool (randomForest). Most samples were also hybridized to a microarray that can detect 8741 bacterial taxa (16S rRNA PhyloChip). RESULTS: Microbiomes associated with pediatric IBS were characterized by a significantly greater percentage of the class gamma-proteobacteria (0.07% vs 0.89% of total bacteria, respectively; P < .05); 1 prominent component of this group was Haemophilus parainfluenzae. Differences highlighted by 454 sequencing were confirmed by high-resolution PhyloChip analysis. Using supervised learning techniques, we were able to classify different subtypes of IBS with a success rate of 98.5%, using limited sets of discriminant bacterial species. A novel Ruminococcus-like microbe was associated with IBS, indicating the potential utility of microbe discovery for gastrointestinal disorders. A greater frequency of pain correlated with an increased abundance of several bacterial taxa from the genus Alistipes. CONCLUSIONS: Using 16S metagenomics by PhyloChip DNA hybridization and deep 454 pyrosequencing, we associated specific microbiome signatures with pediatric IBS. These findings indicate the important association between gastrointestinal microbes and IBS in children; these approaches might be used in diagnosis of functional bowel disorders in pediatric patients.		20110708	https://pubmed.ncbi.nlm.nih.gov/21741921
