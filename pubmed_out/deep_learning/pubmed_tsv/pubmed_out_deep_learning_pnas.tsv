Authors	Title	Journal	Year	Publication_citation	Abstract	Keywords	Date_epublished	PMID
Norn, Christoffer; Wicky, Basile I M; Juergens, David; Liu, Sirui; Kim, David; Tischer, Doug; Koepnick, Brian; Anishchenko, Ivan; Baker, David; Ovchinnikov, Sergey	Protein sequence design by conformational landscape optimization.	Proc Natl Acad Sci U S A	2021	Proc Natl Acad Sci U S A. 2021 Mar 16;118(11). pii: 2017228118. doi: 10.1073/pnas.2017228118.	The protein design problem is to identify an amino acid sequence that folds to a desired structure. Given Anfinsen's thermodynamic hypothesis of folding, this can be recast as finding an amino acid sequence for which the desired structure is the lowest energy state. As this calculation involves not only all possible amino acid sequences but also, all possible structures, most current approaches focus instead on the more tractable problem of finding the lowest-energy amino acid sequence for the desired structure, often checking by protein structure prediction in a second step that the desired structure is indeed the lowest-energy conformation for the designed sequence, and typically discarding a large fraction of designed sequences for which this is not the case. Here, we show that by backpropagating gradients through the transform-restrained Rosetta (trRosetta) structure prediction network from the desired structure to the input amino acid sequence, we can directly optimize over all possible amino acid sequences and all possible structures in a single calculation. We find that trRosetta calculations, which consider the full conformational landscape, can be more effective than Rosetta single-point energy estimations in predicting folding and stability of de novo designed proteins. We compare sequence design by conformational landscape optimization with the standard energy-based sequence design methodology in Rosetta and show that the former can result in energy landscapes with fewer alternative energy minima. We show further that more funneled energy landscapes can be designed by combining the strengths of the two approaches: the low-resolution trRosetta model serves to disfavor alternative states, and the high-resolution Rosetta model serves to create a deep energy minimum at the design target structure.	energy landscape; machine learning; protein design; sequence optimization; stability prediction	?	https://pubmed.ncbi.nlm.nih.gov/33712545
Jamali, Vida; Hargus, Cory; Ben-Moshe, Assaf; Aghazadeh, Amirali; Ha, Hyun Dong; Mandadapu, Kranthi K; Alivisatos, A Paul	Anomalous nanoparticle surface diffusion in LCTEM is revealed by deep learning-assisted analysis.	Proc Natl Acad Sci U S A	2021	Proc Natl Acad Sci U S A. 2021 Mar 9;118(10). pii: 2017616118. doi: 10.1073/pnas.2017616118.	The motion of nanoparticles near surfaces is of fundamental importance in physics, biology, and chemistry. Liquid cell transmission electron microscopy (LCTEM) is a promising technique for studying motion of nanoparticles with high spatial resolution. Yet, the lack of understanding of how the electron beam of the microscope affects the particle motion has held back advancement in using LCTEM for in situ single nanoparticle and macromolecule tracking at interfaces. Here, we experimentally studied the motion of a model system of gold nanoparticles dispersed in water and moving adjacent to the silicon nitride membrane of a commercial LC in a broad range of electron beam dose rates. We find that the nanoparticles exhibit anomalous diffusive behavior modulated by the electron beam dose rate. We characterized the anomalous diffusion of nanoparticles in LCTEM using a convolutional deep neural-network model and canonical statistical tests. The results demonstrate that the nanoparticle motion is governed by fractional Brownian motion at low dose rates, resembling diffusion in a viscoelastic medium, and continuous-time random walk at high dose rates, resembling diffusion on an energy landscape with pinning sites. Both behaviors can be explained by the presence of silanol molecular species on the surface of the silicon nitride membrane and the ionic species in solution formed by radiolysis of water in presence of the electron beam.	anomalous diffusion; deep neural network; liquid cell electron microscopy; single-particle tracking	?	https://pubmed.ncbi.nlm.nih.gov/33658362
Colen, Jonathan; Han, Ming; Zhang, Rui; Redford, Steven A; Lemma, Linnea M; Morgan, Link; Ruijgrok, Paul V; Adkins, Raymond; Bryant, Zev; Dogic, Zvonimir; Gardel, Margaret L; de Pablo, Juan J; Vitelli, Vincenzo	Machine learning active-nematic hydrodynamics.	Proc Natl Acad Sci U S A	2021	Proc Natl Acad Sci U S A. 2021 Mar 9;118(10). pii: 2016708118. doi: 10.1073/pnas.2016708118.	Hydrodynamic theories effectively describe many-body systems out of equilibrium in terms of a few macroscopic parameters. However, such parameters are difficult to determine from microscopic information. Seldom is this challenge more apparent than in active matter, where the hydrodynamic parameters are in fact fields that encode the distribution of energy-injecting microscopic components. Here, we use active nematics to demonstrate that neural networks can map out the spatiotemporal variation of multiple hydrodynamic parameters and forecast the chaotic dynamics of these systems. We analyze biofilament/molecular-motor experiments with microtubule/kinesin and actin/myosin complexes as computer vision problems. Our algorithms can determine how activity and elastic moduli change as a function of space and time, as well as adenosine triphosphate (ATP) or motor concentration. The only input needed is the orientation of the biofilaments and not the coupled velocity field which is harder to access in experiments. We can also forecast the evolution of these chaotic many-body systems solely from image sequences of their past using a combination of autoencoders and recurrent neural networks with residual architecture. In realistic experimental setups for which the initial conditions are not perfectly known, our physics-inspired machine-learning algorithms can surpass deterministic simulations. Our study paves the way for artificial-intelligence characterization and control of coupled chaotic fields in diverse physical and biological systems, even in the absence of knowledge of the underlying dynamics.	active turbulence; biomaterials; deep learning; liquid crystals; topological defects	?	https://pubmed.ncbi.nlm.nih.gov/33653956
Feng, Yu; Tu, Yuhai	The inverse variance-flatness relation in stochastic gradient descent is critical for finding flat minima.	Proc Natl Acad Sci U S A	2021	Proc Natl Acad Sci U S A. 2021 Mar 2;118(9). pii: 2015617118. doi: 10.1073/pnas.2015617118.	Despite tremendous success of the stochastic gradient descent (SGD) algorithm in deep learning, little is known about how SGD finds generalizable solutions at flat minima of the loss function in high-dimensional weight space. Here, we investigate the connection between SGD learning dynamics and the loss function landscape. A principal component analysis (PCA) shows that SGD dynamics follow a low-dimensional drift-diffusion motion in the weight space. Around a solution found by SGD, the loss function landscape can be characterized by its flatness in each PCA direction. Remarkably, our study reveals a robust inverse relation between the weight variance and the landscape flatness in all PCA directions, which is the opposite to the fluctuation-response relation (aka Einstein relation) in equilibrium statistical physics. To understand the inverse variance-flatness relation, we develop a phenomenological theory of SGD based on statistical properties of the ensemble of minibatch loss functions. We find that both the anisotropic SGD noise strength (temperature) and its correlation time depend inversely on the landscape flatness in each PCA direction. Our results suggest that SGD serves as a landscape-dependent annealing algorithm. The effective temperature decreases with the landscape flatness so the system seeks out (prefers) flat minima over sharp ones. Based on these insights, an algorithm with landscape-dependent constraints is developed to mitigate catastrophic forgetting efficiently when learning multiple tasks sequentially. In general, our work provides a theoretical framework to understand learning dynamics, which may eventually lead to better algorithms for different learning tasks.	generalization; loss landscape; machine learning; statistical physics; stochastic gradient descent	?	https://pubmed.ncbi.nlm.nih.gov/33619091
Mehrer, Johannes; Spoerer, Courtney J; Jones, Emer C; Kriegeskorte, Nikolaus; Kietzmann, Tim C	An ecologically motivated image dataset for deep learning yields better models of human vision.	Proc Natl Acad Sci U S A	2021	Proc Natl Acad Sci U S A. 2021 Feb 23;118(8). pii: 2011417118. doi: 10.1073/pnas.2011417118.	Deep neural networks provide the current best models of visual information processing in the primate brain. Drawing on work from computer vision, the most commonly used networks are pretrained on data from the ImageNet Large Scale Visual Recognition Challenge. This dataset comprises images from 1,000 categories, selected to provide a challenging testbed for automated visual object recognition systems. Moving beyond this common practice, we here introduce ecoset, a collection of >1.5 million images from 565 basic-level categories selected to better capture the distribution of objects relevant to humans. Ecoset categories were chosen to be both frequent in linguistic usage and concrete, thereby mirroring important physical objects in the world. We test the effects of training on this ecologically more valid dataset using multiple instances of two neural network architectures: AlexNet and vNet, a novel architecture designed to mimic the progressive increase in receptive field sizes along the human ventral stream. We show that training on ecoset leads to significant improvements in predicting representations in human higher-level visual cortex and perceptual judgments, surpassing the previous state of the art. Significant and highly consistent benefits are demonstrated for both architectures on two separate functional magnetic resonance imaging (fMRI) datasets and behavioral data, jointly covering responses to 1,292 visual stimuli from a wide variety of object categories. These results suggest that computational visual neuroscience may take better advantage of the deep learning framework by using image sets that reflect the human perceptual and cognitive experience. Ecoset and trained network models are openly available to the research community.	computational neuroscience; computer vision; deep neural networks; ecological relevance; human visual system	?	https://pubmed.ncbi.nlm.nih.gov/33593900
?	Correction for Kim et al., Prediction of Alzheimer's disease-specific phospholipase c gamma-1 SNV by deep learning-based approach for high-throughput screening.	Proc Natl Acad Sci U S A	2021	Proc Natl Acad Sci U S A. 2021 Mar 2;118(9). pii: 2101727118. doi: 10.1073/pnas.2101727118.	?		?	https://pubmed.ncbi.nlm.nih.gov/33579793
Feng, Peiyuan; Xiao, An; Fang, Meng; Wan, Fangping; Li, Shuya; Lang, Peng; Zhao, Dan; Zeng, Jianyang	A machine learning-based framework for modeling transcription elongation.	Proc Natl Acad Sci U S A	2021	Proc Natl Acad Sci U S A. 2021 Feb 9;118(6). pii: 2007450118. doi: 10.1073/pnas.2007450118.	RNA polymerase II (Pol II) generally pauses at certain positions along gene bodies, thereby interrupting the transcription elongation process, which is often coupled with various important biological functions, such as precursor mRNA splicing and gene expression regulation. Characterizing the transcriptional elongation dynamics can thus help us understand many essential biological processes in eukaryotic cells. However, experimentally measuring Pol II elongation rates is generally time and resource consuming. We developed PEPMAN (polymerase II elongation pausing modeling through attention-based deep neural network), a deep learning-based model that accurately predicts Pol II pausing sites based on the native elongating transcript sequencing (NET-seq) data. Through fully taking advantage of the attention mechanism, PEPMAN is able to decipher important sequence features underlying Pol II pausing. More importantly, we demonstrated that the analyses of the PEPMAN-predicted results around various types of alternative splicing sites can provide useful clues into understanding the cotranscriptional splicing events. In addition, associating the PEPMAN prediction results with different epigenetic features can help reveal important factors related to the transcription elongation process. All these results demonstrated that PEPMAN can provide a useful and effective tool for modeling transcription elongation and understanding the related biological factors from available high-throughput sequencing data.	Pol II pausing; alternative splicing; deep learning	?	https://pubmed.ncbi.nlm.nih.gov/33526657
Amey, Jake L; Keeley, Jake; Choudhury, Tajwar; Kuprov, Ilya	Neural network interpretation using descrambler groups.	Proc Natl Acad Sci U S A	2021	Proc Natl Acad Sci U S A. 2021 Feb 2;118(5). pii: 2016917118. doi: 10.1073/pnas.2016917118.	The lack of interpretability and trust is a much-criticized feature of deep neural networks. In fully connected nets, the signaling between inner layers is scrambled because backpropagation training does not require perceptrons to be arranged in any particular order. The result is a black box; this problem is particularly severe in scientific computing and digital signal processing (DSP), where neural nets perform abstract mathematical transformations that do not reduce to features or concepts. We present here a group-theoretical procedure that attempts to bring inner-layer signaling into a human-readable form, the assumption being that this form exists and has identifiable and quantifiable features-for example, smoothness or locality. We applied the proposed method to DEERNet (a DSP network used in electron spin resonance) and managed to descramble it. We found considerable internal sophistication: the network spontaneously invents a bandpass filter, a notch filter, a frequency axis rescaling transformation, frequency-division multiplexing, group embedding, spectral filtering regularization, and a map from harmonic functions into Chebyshev polynomials-in 10 min of unattended training from a random initial guess.	digital signal processing; electron spin resonance; interpretability; machine learning	?	https://pubmed.ncbi.nlm.nih.gov/33500352
Zhuang, Chengxu; Yan, Siming; Nayebi, Aran; Schrimpf, Martin; Frank, Michael C; DiCarlo, James J; Yamins, Daniel L K	Unsupervised neural network models of the ventral visual stream.	Proc Natl Acad Sci U S A	2021	Proc Natl Acad Sci U S A. 2021 Jan 19;118(3). pii: 2014196118. doi: 10.1073/pnas.2014196118.	Deep neural networks currently provide the best quantitative models of the response patterns of neurons throughout the primate ventral visual stream. However, such networks have remained implausible as a model of the development of the ventral stream, in part because they are trained with supervised methods requiring many more labels than are accessible to infants during development. Here, we report that recent rapid progress in unsupervised learning has largely closed this gap. We find that neural network models learned with deep unsupervised contrastive embedding methods achieve neural prediction accuracy in multiple ventral visual cortical areas that equals or exceeds that of models derived using today's best supervised methods and that the mapping of these neural network models' hidden layers is neuroanatomically consistent across the ventral stream. Strikingly, we find that these methods produce brain-like representations even when trained solely with real human child developmental data collected from head-mounted cameras, despite the fact that these datasets are noisy and limited. We also find that semisupervised deep contrastive embeddings can leverage small numbers of labeled examples to produce representations with substantially improved error-pattern consistency to human behavior. Taken together, these results illustrate a use of unsupervised learning to provide a quantitative model of a multiarea cortical brain system and present a strong candidate for a biologically plausible computational theory of primate sensory learning.	deep neural networks; unsupervised algorithms; ventral visual stream	?	https://pubmed.ncbi.nlm.nih.gov/33431673
Hoye, Toke T; Arje, Johanna; Bjerge, Kim; Hansen, Oskar L P; Iosifidis, Alexandros; Leese, Florian; Mann, Hjalte M R; Meissner, Kristian; Melvad, Claus; Raitoharju, Jenni	Deep learning and computer vision will transform entomology.	Proc Natl Acad Sci U S A	2021	Proc Natl Acad Sci U S A. 2021 Jan 12;118(2). pii: 2002545117. doi: 10.1073/pnas.2002545117.	Most animal species on Earth are insects, and recent reports suggest that their abundance is in drastic decline. Although these reports come from a wide range of insect taxa and regions, the evidence to assess the extent of the phenomenon is sparse. Insect populations are challenging to study, and most monitoring methods are labor intensive and inefficient. Advances in computer vision and deep learning provide potential new solutions to this global challenge. Cameras and other sensors can effectively, continuously, and noninvasively perform entomological observations throughout diurnal and seasonal cycles. The physical appearance of specimens can also be captured by automated imaging in the laboratory. When trained on these data, deep learning models can provide estimates of insect abundance, biomass, and diversity. Further, deep learning models can quantify variation in phenotypic traits, behavior, and interactions. Here, we connect recent developments in deep learning and computer vision to the urgent demand for more cost-efficient monitoring of insects and other invertebrates. We present examples of sensor-based monitoring of insects. We show how deep learning tools can be applied to exceptionally large datasets to derive ecological information and discuss the challenges that lie ahead for the implementation of such solutions in entomology. We identify four focal areas, which will facilitate this transformation: 1) validation of image-based taxonomic identification; 2) generation of sufficient training data; 3) development of public, curated reference databases; and 4) solutions to integrate deep learning and molecular tools.	automated monitoring; ecology; image-based identification; insects; machine learning	?	https://pubmed.ncbi.nlm.nih.gov/33431561
Kim, Sung-Hyun; Yang, Sumin; Lim, Key-Hwan; Ko, Euiseng; Jang, Hyun-Jun; Kang, Mingon; Suh, Pann-Ghill; Joo, Jae-Yeol	Prediction of Alzheimer's disease-specific phospholipase c gamma-1 SNV by deep learning-based approach for high-throughput screening.	Proc Natl Acad Sci U S A	2021	Proc Natl Acad Sci U S A. 2021 Jan 19;118(3). pii: 2011250118. doi: 10.1073/pnas.2011250118.	Exon splicing triggered by unpredicted genetic mutation can cause translational variations in neurodegenerative disorders. In this study, we discover Alzheimer's disease (AD)-specific single-nucleotide variants (SNVs) and abnormal exon splicing of phospholipase c gamma-1 (PLCgamma1) gene, using genome-wide association study (GWAS) and a deep learning-based exon splicing prediction tool. GWAS revealed that the identified single-nucleotide variations were mainly distributed in the H3K27ac-enriched region of PLCgamma1 gene body during brain development in an AD mouse model. A deep learning analysis, trained with human genome sequences, predicted 14 splicing sites in human PLCgamma1 gene, and one of these completely matched with an SNV in exon 27 of PLCgamma1 gene in an AD mouse model. In particular, the SNV in exon 27 of PLCgamma1 gene is associated with abnormal splicing during messenger RNA maturation. Taken together, our findings suggest that this approach, which combines in silico and deep learning-based analyses, has potential for identifying the clinical utility of critical SNVs in AD prediction.	Alzheimer's disease; PLCgamma1; deep learning; single-nucleotide variation	?	https://pubmed.ncbi.nlm.nih.gov/33397809
Ma, Zhuoran; Wang, Feifei; Wang, Weizhi; Zhong, Yeteng; Dai, Hongjie	Deep learning for in vivo near-infrared imaging.	Proc Natl Acad Sci U S A	2021	Proc Natl Acad Sci U S A. 2021 Jan 5;118(1). pii: 2021446118. doi: 10.1073/pnas.2021446118.	Detecting fluorescence in the second near-infrared window (NIR-II) up to approximately 1,700 nm has emerged as a novel in vivo imaging modality with high spatial and temporal resolution through millimeter tissue depths. Imaging in the NIR-IIb window (1,500-1,700 nm) is the most effective one-photon approach to suppressing light scattering and maximizing imaging penetration depth, but relies on nanoparticle probes such as PbS/CdS containing toxic elements. On the other hand, imaging the NIR-I (700-1,000 nm) or NIR-IIa window (1,000-1,300 nm) can be done using biocompatible small-molecule fluorescent probes including US Food and Drug Administration-approved dyes such as indocyanine green (ICG), but has a caveat of suboptimal imaging quality due to light scattering. It is highly desired to achieve the performance of NIR-IIb imaging using molecular probes approved for human use. Here, we trained artificial neural networks to transform a fluorescence image in the shorter-wavelength NIR window of 900-1,300 nm (NIR-I/IIa) to an image resembling an NIR-IIb image. With deep-learning translation, in vivo lymph node imaging with ICG achieved an unprecedented signal-to-background ratio of >100. Using preclinical fluorophores such as IRDye-800, translation of approximately 900-nm NIR molecular imaging of PD-L1 or EGFR greatly enhanced tumor-to-normal tissue ratio up to approximately 20 from approximately 5 and improved tumor margin localization. Further, deep learning greatly improved in vivo noninvasive NIR-II light-sheet microscopy (LSM) in resolution and signal/background. NIR imaging equipped with deep learning could facilitate basic biomedical research and empower clinical diagnostics and imaging-guided surgery in the clinic.	deep learning; near-infrared imaging; second near-infrared window	?	https://pubmed.ncbi.nlm.nih.gov/33372162
Kim, Gi Bae; Gao, Ye; Palsson, Bernhard O; Lee, Sang Yup	DeepTFactor: A deep learning-based tool for the prediction of transcription factors.	Proc Natl Acad Sci U S A	2021	Proc Natl Acad Sci U S A. 2021 Jan 12;118(2). pii: 2021171118. doi: 10.1073/pnas.2021171118.	A transcription factor (TF) is a sequence-specific DNA-binding protein that modulates the transcription of a set of particular genes, and thus regulates gene expression in the cell. TFs have commonly been predicted by analyzing sequence homology with the DNA-binding domains of TFs already characterized. Thus, TFs that do not show homologies with the reported ones are difficult to predict. Here we report the development of a deep learning-based tool, DeepTFactor, that predicts whether a protein in question is a TF. DeepTFactor uses a convolutional neural network to extract features of a protein. It showed high performance in predicting TFs of both eukaryotic and prokaryotic origins, resulting in F1 scores of 0.8154 and 0.8000, respectively. Analysis of the gradients of prediction score with respect to input suggested that DeepTFactor detects DNA-binding domains and other latent features for TF prediction. DeepTFactor predicted 332 candidate TFs in Escherichia coli K-12 MG1655. Among them, 84 candidate TFs belong to the y-ome, which is a collection of genes that lack experimental evidence of function. We experimentally validated the results of DeepTFactor prediction by further characterizing genome-wide binding sites of three predicted TFs, YqhC, YiaU, and YahB. Furthermore, we made available the list of 4,674,808 TFs predicted from 73,873,012 protein sequences in 48,346 genomes. DeepTFactor will serve as a useful tool for predicting TFs, which is necessary for understanding the regulatory systems of organisms of interest. We provide DeepTFactor as a stand-alone program, available at https://bitbucket.org/kaistsystemsbiology/deeptfactor.	ChIP-exo; deep learning; transcription factor; transcription regulation; y-ome	?	https://pubmed.ncbi.nlm.nih.gov/33372147
Pfab, Jonas; Phan, Nhut Minh; Si, Dong	DeepTracer for fast de novo cryo-EM protein structure modeling and special studies on CoV-related complexes.	Proc Natl Acad Sci U S A	2021	Proc Natl Acad Sci U S A. 2021 Jan 12;118(2). pii: 2017525118. doi: 10.1073/pnas.2017525118.	Information about macromolecular structure of protein complexes and related cellular and molecular mechanisms can assist the search for vaccines and drug development processes. To obtain such structural information, we present DeepTracer, a fully automated deep learning-based method for fast de novo multichain protein complex structure determination from high-resolution cryoelectron microscopy (cryo-EM) maps. We applied DeepTracer on a previously published set of 476 raw experimental cryo-EM maps and compared the results with a current state of the art method. The residue coverage increased by over 30% using DeepTracer, and the rmsd value improved from 1.29 A to 1.18 A. Additionally, we applied DeepTracer on a set of 62 coronavirus-related cryo-EM maps, among them 10 with no deposited structure available in EMDataResource. We observed an average residue match of 84% with the deposited structures and an average rmsd of 0.93 A. Additional tests with related methods further exemplify DeepTracer's competitive accuracy and efficiency of structure modeling. DeepTracer allows for exceptionally fast computations, making it possible to trace around 60,000 residues in 350 chains within only 2 h. The web service is globally accessible at https://deeptracer.uw.edu.	complex; cryo-EM; de novo; modeling; structure	?	https://pubmed.ncbi.nlm.nih.gov/33361332
Asner, Gregory P; Vaughn, Nicholas R; Heckler, Joseph; Knapp, David E; Balzotti, Christopher; Shafron, Ethan; Martin, Roberta E; Neilson, Brian J; Gove, Jamison M	Large-scale mapping of live corals to guide reef conservation.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Dec 29;117(52):33711-33718. doi: 10.1073/pnas.2017628117. Epub 2020 Dec 14.	Coral is the life-form that underpins the habitat of most tropical reef ecosystems, thereby supporting biological diversity throughout the marine realm. Coral reefs are undergoing rapid change from ocean warming and nearshore human activities, compromising a myriad of services provided to societies including coastal protection, fishing, and cultural practices. In the face of these challenges, large-scale operational mapping of live coral cover within and across reef ecosystems could provide more opportunities to address reef protection, resilience, and restoration at broad management- and policy-relevant scales. We developed an airborne mapping approach combining laser-guided imaging spectroscopy and deep learning models to quantify, at a large archipelago scale, the geographic distribution of live corals to 16-m water depth throughout the main Hawaiian islands. Airborne estimates of live coral cover were highly correlated with field-based estimates of live coral cover (R (2) = 0.94). Our maps were used to assess the relative condition of reefs based on live coral, and to identify potential coral refugia in the face of human-driven stressors, including marine heat waves. Geospatial modeling revealed that water depth, wave power, and nearshore development accounted for the majority (>60%) of live coral cover variation, but other human-driven factors were also important. Mapped interisland and intraisland variation in live coral location improves our understanding of reef geography and its human impacts, thereby guiding environmental management for reef resiliency.	Hawaiian Islands; coral mapping; coral reef; coral refugia; reef restoration	20201214	https://pubmed.ncbi.nlm.nih.gov/33318215
Jin, Lingbo; Tang, Yubo; Wu, Yicheng; Coole, Jackson B; Tan, Melody T; Zhao, Xuan; Badaoui, Hawraa; Robinson, Jacob T; Williams, Michelle D; Gillenwater, Ann M; Richards-Kortum, Rebecca R; Veeraraghavan, Ashok	Deep learning extended depth-of-field microscope for fast and slide-free histology.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Dec 29;117(52):33051-33060. doi: 10.1073/pnas.2013571117. Epub 2020 Dec 14.	Microscopic evaluation of resected tissue plays a central role in the surgical management of cancer. Because optical microscopes have a limited depth-of-field (DOF), resected tissue is either frozen or preserved with chemical fixatives, sliced into thin sections placed on microscope slides, stained, and imaged to determine whether surgical margins are free of tumor cells-a costly and time- and labor-intensive procedure. Here, we introduce a deep-learning extended DOF (DeepDOF) microscope to quickly image large areas of freshly resected tissue to provide histologic-quality images of surgical margins without physical sectioning. The DeepDOF microscope consists of a conventional fluorescence microscope with the simple addition of an inexpensive (less than $10) phase mask inserted in the pupil plane to encode the light field and enhance the depth-invariance of the point-spread function. When used with a jointly optimized image-reconstruction algorithm, diffraction-limited optical performance to resolve subcellular features can be maintained while significantly extending the DOF (200 microm). Data from resected oral surgical specimens show that the DeepDOF microscope can consistently visualize nuclear morphology and other important diagnostic features across highly irregular resected tissue surfaces without serial refocusing. With the capability to quickly scan intact samples with subcellular detail, the DeepDOF microscope can improve tissue sampling during intraoperative tumor-margin assessment, while offering an affordable tool to provide histological information from resected tissue specimens in resource-limited settings.	deep learning; end-to-end optimization; extended depth-of-field microscopy; pathology; phase mask	20201214	https://pubmed.ncbi.nlm.nih.gov/33318169
Liu, Jing; Zhang, Hui; Yu, Tao; Ni, Duanyu; Ren, Liankun; Yang, Qinhao; Lu, Baoqing; Wang, Di; Heinen, Rebekka; Axmacher, Nikolai; Xue, Gui	Stable maintenance of multiple representational formats in human visual short-term memory.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Dec 22;117(51):32329-32339. doi: 10.1073/pnas.2006752117. Epub 2020 Dec 7.	Visual short-term memory (VSTM) enables humans to form a stable and coherent representation of the external world. However, the nature and temporal dynamics of the neural representations in VSTM that support this stability are barely understood. Here we combined human intracranial electroencephalography (iEEG) recordings with analyses using deep neural networks and semantic models to probe the representational format and temporal dynamics of information in VSTM. We found clear evidence that VSTM maintenance occurred in two distinct representational formats which originated from different encoding periods. The first format derived from an early encoding period (250 to 770 ms) corresponded to higher-order visual representations. The second format originated from a late encoding period (1,000 to 1,980 ms) and contained abstract semantic representations. These representational formats were overall stable during maintenance, with no consistent transformation across time. Nevertheless, maintenance of both representational formats showed substantial arrhythmic fluctuations, i.e., waxing and waning in irregular intervals. The increases of the maintained representational formats were specific to the phases of hippocampal low-frequency activity. Our results demonstrate that human VSTM simultaneously maintains representations at different levels of processing, from higher-order visual information to abstract semantic representations, which are stably maintained via coupling to hippocampal low-frequency activity.	deep neural network; hippocampus; intracranial EEG; representation; visual short-term memory	20201207	https://pubmed.ncbi.nlm.nih.gov/33288707
Peterfreund, Erez; Lindenbaum, Ofir; Dietrich, Felix; Bertalan, Tom; Gavish, Matan; Kevrekidis, Ioannis G; Coifman, Ronald R	Local conformal autoencoder for standardized data coordinates.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Dec 8;117(49):30918-30927. doi: 10.1073/pnas.2014627117. Epub 2020 Nov 23.	We propose a local conformal autoencoder (LOCA) for standardized data coordinates. LOCA is a deep learning-based method for obtaining standardized data coordinates from scientific measurements. Data observations are modeled as samples from an unknown, nonlinear deformation of an underlying Riemannian manifold, which is parametrized by a few normalized, latent variables. We assume a repeated measurement sampling strategy, common in scientific measurements, and present a method for learning an embedding in [Formula: see text] that is isometric to the latent variables of the manifold. The coordinates recovered by our method are invariant to diffeomorphisms of the manifold, making it possible to match between different instrumental observations of the same phenomenon. Our embedding is obtained using LOCA, which is an algorithm that learns to rectify deformations by using a local z-scoring procedure, while preserving relevant geometric information. We demonstrate the isometric embedding properties of LOCA in various model settings and observe that it exhibits promising interpolation and extrapolation capabilities, superior to the current state of the art. Finally, we demonstrate LOCA's efficacy in single-site Wi-Fi localization data and for the reconstruction of three-dimensional curved surfaces from two-dimensional projections.	autoencoder; canonical coordinates; dimensionality reduction; manifold learning	20201123	https://pubmed.ncbi.nlm.nih.gov/33229581
Bastos, Andre M; Lundqvist, Mikael; Waite, Ayan S; Kopell, Nancy; Miller, Earl K	Layer and rhythm specificity for predictive routing.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Dec 8;117(49):31459-31469. doi: 10.1073/pnas.2014868117. Epub 2020 Nov 23.	In predictive coding, experience generates predictions that attenuate the feeding forward of predicted stimuli while passing forward unpredicted "errors." Different models have suggested distinct cortical layers, and rhythms implement predictive coding. We recorded spikes and local field potentials from laminar electrodes in five cortical areas (visual area 4 [V4], lateral intraparietal [LIP], posterior parietal area 7A, frontal eye field [FEF], and prefrontal cortex [PFC]) while monkeys performed a task that modulated visual stimulus predictability. During predictable blocks, there was enhanced alpha (8 to 14 Hz) or beta (15 to 30 Hz) power in all areas during stimulus processing and prestimulus beta (15 to 30 Hz) functional connectivity in deep layers of PFC to the other areas. Unpredictable stimuli were associated with increases in spiking and in gamma-band (40 to 90 Hz) power/connectivity that fed forward up the cortical hierarchy via superficial-layer cortex. Power and spiking modulation by predictability was stimulus specific. Alpha/beta power in LIP, FEF, and PFC inhibited spiking in deep layers of V4. Area 7A uniquely showed increases in high-beta ( approximately 22 to 28 Hz) power/connectivity to unpredictable stimuli. These results motivate a conceptual model, predictive routing. It suggests that predictive coding may be implemented via lower-frequency alpha/beta rhythms that "prepare" pathways processing-predicted inputs by inhibiting feedforward gamma rhythms and associated spiking.	beta oscillations; cortical layers; gamma oscillations; neural synchronization; predictive coding	20201123	https://pubmed.ncbi.nlm.nih.gov/33229572
Baraniuk, Richard; Donoho, David; Gavish, Matan	The science of deep learning.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Dec 1;117(48):30029-30032. doi: 10.1073/pnas.2020596117. Epub 2020 Nov 23.	?	artificial intelligence; deep learning; machine learning; neural networks	20201123	https://pubmed.ncbi.nlm.nih.gov/33229565
Golan, Tal; Raju, Prashant C; Kriegeskorte, Nikolaus	Controversial stimuli: Pitting neural networks against each other as models of human cognition.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Nov 24;117(47):29330-29337. doi: 10.1073/pnas.1912334117.	Distinct scientific theories can make similar predictions. To adjudicate between theories, we must design experiments for which the theories make distinct predictions. Here we consider the problem of comparing deep neural networks as models of human visual recognition. To efficiently compare models' ability to predict human responses, we synthesize controversial stimuli: images for which different models produce distinct responses. We applied this approach to two visual recognition tasks, handwritten digits (MNIST) and objects in small natural images (CIFAR-10). For each task, we synthesized controversial stimuli to maximize the disagreement among models which employed different architectures and recognition algorithms. Human subjects viewed hundreds of these stimuli, as well as natural examples, and judged the probability of presence of each digit/object category in each image. We quantified how accurately each model predicted the human judgments. The best-performing models were a generative analysis-by-synthesis model (based on variational autoencoders) for MNIST and a hybrid discriminative-generative joint energy model for CIFAR-10. These deep neural networks (DNNs), which model the distribution of images, performed better than purely discriminative DNNs, which learn only to map images to labels. None of the candidate models fully explained the human responses. Controversial stimuli generalize the concept of adversarial examples, obviating the need to assume a ground-truth model. Unlike natural images, controversial stimuli are not constrained to the stimulus distribution models are trained on, thus providing severe out-of-distribution tests that reveal the models' inductive biases. Controversial stimuli therefore provide powerful probes of discrepancies between models and human perception.	adversarial examples; deep neural networks; generative modeling; optimal experimental design; visual object recognition	?	https://pubmed.ncbi.nlm.nih.gov/33229549
Allen, Kelsey R; Smith, Kevin A; Tenenbaum, Joshua B	Rapid trial-and-error learning with simulation supports flexible tool use and physical reasoning.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Nov 24;117(47):29302-29310. doi: 10.1073/pnas.1912341117.	Many animals, and an increasing number of artificial agents, display sophisticated capabilities to perceive and manipulate objects. But human beings remain distinctive in their capacity for flexible, creative tool use-using objects in new ways to act on the world, achieve a goal, or solve a problem. To study this type of general physical problem solving, we introduce the Virtual Tools game. In this game, people solve a large range of challenging physical puzzles in just a handful of attempts. We propose that the flexibility of human physical problem solving rests on an ability to imagine the effects of hypothesized actions, while the efficiency of human search arises from rich action priors which are updated via observations of the world. We instantiate these components in the "sample, simulate, update" (SSUP) model and show that it captures human performance across 30 levels of the Virtual Tools game. More broadly, this model provides a mechanism for explaining how people condense general physical knowledge into actionable, task-specific plans to achieve flexible and efficient physical problem solving.	intuitive physics; physical problem solving; tool use	?	https://pubmed.ncbi.nlm.nih.gov/33229515
Wang, Siruo; McCormick, Tyler H; Leek, Jeffrey T	Methods for correcting inference based on outcomes predicted by machine learning.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Dec 1;117(48):30266-30275. doi: 10.1073/pnas.2001238117. Epub 2020 Nov 18.	Many modern problems in medicine and public health leverage machine-learning methods to predict outcomes based on observable covariates. In a wide array of settings, predicted outcomes are used in subsequent statistical analysis, often without accounting for the distinction between observed and predicted outcomes. We call inference with predicted outcomes postprediction inference. In this paper, we develop methods for correcting statistical inference using outcomes predicted with arbitrarily complicated machine-learning models including random forests and deep neural nets. Rather than trying to derive the correction from first principles for each machine-learning algorithm, we observe that there is typically a low-dimensional and easily modeled representation of the relationship between the observed and predicted outcomes. We build an approach for postprediction inference that naturally fits into the standard machine-learning framework where the data are divided into training, testing, and validation sets. We train the prediction model in the training set, estimate the relationship between the observed and predicted outcomes in the testing set, and use that relationship to correct subsequent inference in the validation set. We show our postprediction inference (postpi) approach can correct bias and improve variance estimation and subsequent statistical inference with predicted outcomes. To show the broad range of applicability of our approach, we show postpi can improve inference in two distinct fields: modeling predicted phenotypes in repurposed gene expression data and modeling predicted causes of death in verbal autopsy data. Our method is available through an open-source R package: https://github.com/leekgroup/postpi.	interpretability; machine learning; postprediction inference; statistics	20201118	https://pubmed.ncbi.nlm.nih.gov/33208538
White, Alexander E	Deep learning in deep time.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Nov 24;117(47):29268-29270. doi: 10.1073/pnas.2020870117. Epub 2020 Nov 9.	?		20201109	https://pubmed.ncbi.nlm.nih.gov/33168754
Romero, Ingrid C; Kong, Shu; Fowlkes, Charless C; Jaramillo, Carlos; Urban, Michael A; Oboh-Ikuenobe, Francisca; D'Apolito, Carlos; Punyasena, Surangi W	Improving the taxonomy of fossil pollen using convolutional neural networks and superresolution microscopy.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Nov 10;117(45):28496-28505. doi: 10.1073/pnas.2007324117. Epub 2020 Oct 23.	Taxonomic resolution is a major challenge in palynology, largely limiting the ecological and evolutionary interpretations possible with deep-time fossil pollen data. We present an approach for fossil pollen analysis that uses optical superresolution microscopy and machine learning to create a quantitative and higher throughput workflow for producing palynological identifications and hypotheses of biological affinity. We developed three convolutional neural network (CNN) classification models: maximum projection (MPM), multislice (MSM), and fused (FM). We trained the models on the pollen of 16 genera of the legume tribe Amherstieae, and then used these models to constrain the biological classifications of 48 fossil Striatopollis specimens from the Paleocene, Eocene, and Miocene of western Africa and northern South America. All models achieved average accuracies of 83 to 90% in the classification of the extant genera, and the majority of fossil identifications (86%) showed consensus among at least two of the three models. Our fossil identifications support the paleobiogeographic hypothesis that Amherstieae originated in Paleocene Africa and dispersed to South America during the Paleocene-Eocene Thermal Maximum (56 Ma). They also raise the possibility that at least three Amherstieae genera (Crudia, Berlinia, and Anthonotha) may have diverged earlier in the Cenozoic than predicted by molecular phylogenies.	Airyscan microscopy; Detarioideae; automated classification; machine learning; palynology	20201023	https://pubmed.ncbi.nlm.nih.gov/33097671
Radhakrishnan, Adityanarayanan; Belkin, Mikhail; Uhler, Caroline	Overparameterized neural networks implement associative memory.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Nov 3;117(44):27162-27170. doi: 10.1073/pnas.2005013117. Epub 2020 Oct 16.	Identifying computational mechanisms for memorization and retrieval of data is a long-standing problem at the intersection of machine learning and neuroscience. Our main finding is that standard overparameterized deep neural networks trained using standard optimization methods implement such a mechanism for real-valued data. We provide empirical evidence that 1) overparameterized autoencoders store training samples as attractors and thus iterating the learned map leads to sample recovery, and that 2) the same mechanism allows for encoding sequences of examples and serves as an even more efficient mechanism for memory than autoencoding. Theoretically, we prove that when trained on a single example, autoencoders store the example as an attractor. Lastly, by treating a sequence encoder as a composition of maps, we prove that sequence encoding provides a more efficient mechanism for memory than autoencoding.	associative memory; autoencoders; neural networks; overparameterization; sequence encoders	20201016	https://pubmed.ncbi.nlm.nih.gov/33067397
Firestone, Chaz	Performance vs. competence in human-machine comparisons.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Oct 27;117(43):26562-26571. doi: 10.1073/pnas.1905334117. Epub 2020 Oct 13.	Does the human mind resemble the machines that can behave like it? Biologically inspired machine-learning systems approach "human-level" accuracy in an astounding variety of domains, and even predict human brain activity-raising the exciting possibility that such systems represent the world like we do. However, even seemingly intelligent machines fail in strange and "unhumanlike" ways, threatening their status as models of our minds. How can we know when human-machine behavioral differences reflect deep disparities in their underlying capacities, vs. when such failures are only superficial or peripheral? This article draws on a foundational insight from cognitive science-the distinction between performance and competence-to encourage "species-fair" comparisons between humans and machines. The performance/competence distinction urges us to consider whether the failure of a system to behave as ideally hypothesized, or the failure of one creature to behave like another, arises not because the system lacks the relevant knowledge or internal capacities ("competence"), but instead because of superficial constraints on demonstrating that knowledge ("performance"). I argue that this distinction has been neglected by research comparing human and machine behavior, and that it should be essential to any such comparison. Focusing on the domain of image classification, I identify three factors contributing to the species-fairness of human-machine comparisons, extracted from recent work that equates such constraints. Species-fair comparisons level the playing field between natural and artificial intelligence, so that we can separate more superficial differences from those that may be deep and enduring.	artificial intelligence; cognition; deep learning; development; perception	20201013	https://pubmed.ncbi.nlm.nih.gov/33051296
Gartner, Thomas E 3rd; Zhang, Linfeng; Piaggi, Pablo M; Car, Roberto; Panagiotopoulos, Athanassios Z; Debenedetti, Pablo G	Signatures of a liquid-liquid transition in an ab initio deep neural network model for water.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Oct 20;117(42):26040-26046. doi: 10.1073/pnas.2015440117. Epub 2020 Oct 2.	The possible existence of a metastable liquid-liquid transition (LLT) and a corresponding liquid-liquid critical point (LLCP) in supercooled liquid water remains a topic of much debate. An LLT has been rigorously proved in three empirically parametrized molecular models of water, and evidence consistent with an LLT has been reported for several other such models. In contrast, experimental proof of this phenomenon has been elusive due to rapid ice nucleation under deeply supercooled conditions. In this work, we combined density functional theory (DFT), machine learning, and molecular simulations to shed additional light on the possible existence of an LLT in water. We trained a deep neural network (DNN) model to represent the ab initio potential energy surface of water from DFT calculations using the Strongly Constrained and Appropriately Normed (SCAN) functional. We then used advanced sampling simulations in the multithermal-multibaric ensemble to efficiently explore the thermophysical properties of the DNN model. The simulation results are consistent with the existence of an LLCP, although they do not constitute a rigorous proof thereof. We fit the simulation data to a two-state equation of state to provide an estimate of the LLCP's location. These combined results-obtained from a purely first-principles approach with no empirical parameters-are strongly suggestive of the existence of an LLT, bolstering the hypothesis that water can separate into two distinct liquid forms.	liquid-liquid transition; machine learning; molecular simulations; water	20201002	https://pubmed.ncbi.nlm.nih.gov/33008883
Valeriani, Davide; Simonyan, Kristina	A microstructural neural network biomarker for dystonia diagnosis identified by a DystoniaNet deep learning platform.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Oct 20;117(42):26398-26405. doi: 10.1073/pnas.2009165117. Epub 2020 Oct 1.	Isolated dystonia is a neurological disorder of heterogeneous pathophysiology, which causes involuntary muscle contractions leading to abnormal movements and postures. Its diagnosis is remarkably challenging due to the absence of a biomarker or gold standard diagnostic test. This leads to a low agreement between clinicians, with up to 50% of cases being misdiagnosed and diagnostic delays extending up to 10.1 y. We developed a deep learning algorithmic platform, DystoniaNet, to automatically identify and validate a microstructural neural network biomarker for dystonia diagnosis from raw structural brain MRIs of 612 subjects, including 392 patients with three different forms of isolated focal dystonia and 220 healthy controls. DystoniaNet identified clusters in corpus callosum, anterior and posterior thalamic radiations, inferior fronto-occipital fasciculus, and inferior temporal and superior orbital gyri as the biomarker components. These regions are known to contribute to abnormal interhemispheric information transfer, heteromodal sensorimotor processing, and executive control of motor commands in dystonia pathophysiology. The DystoniaNet-based biomarker showed an overall accuracy of 98.8% in diagnosing dystonia, with a referral of 3.5% of cases due to diagnostic uncertainty. The diagnostic decision by DystoniaNet was computed in 0.36 s per subject. DystoniaNet significantly outperformed shallow machine-learning algorithms in benchmark comparisons, showing nearly a 20% increase in its diagnostic performance. Importantly, the microstructural neural network biomarker and its DystoniaNet platform showed substantial improvement over the current 34% agreement on dystonia diagnosis between clinicians. The translational potential of this biomarker is in its highly accurate, interpretable, and generalizable performance for enhanced clinical decision-making.	biomarker; brain MRI; dystonia; machine learning	20201001	https://pubmed.ncbi.nlm.nih.gov/33004625
Yao, Haicheng; Yang, Weidong; Cheng, Wen; Tan, Yu Jun; See, Hian Hian; Li, Si; Ali, Hashina Parveen Anwar; Lim, Brian Z H; Liu, Zhuangjian; Tee, Benjamin C K	Near-hysteresis-free soft tactile electronic skins for wearables and reliable machine learning.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Oct 13;117(41):25352-25359. doi: 10.1073/pnas.2010989117. Epub 2020 Sep 28.	Electronic skins are essential for real-time health monitoring and tactile perception in robots. Although the use of soft elastomers and microstructures have improved the sensitivity and pressure-sensing range of tactile sensors, the intrinsic viscoelasticity of soft polymeric materials remains a long-standing challenge resulting in cyclic hysteresis. This causes sensor data variations between contact events that negatively impact the accuracy and reliability. Here, we introduce the Tactile Resistive Annularly Cracked E-Skin (TRACE) sensor to address the inherent trade-off between sensitivity and hysteresis in tactile sensors when using soft materials. We discovered that piezoresistive sensors made using an array of three-dimensional (3D) metallic annular cracks on polymeric microstructures possess high sensitivities (> 10(7) Omega kPa(-1)), low hysteresis (2.99 +/- 1.37%) over a wide pressure range (0-20 kPa), and fast response (400 Hz). We demonstrate that TRACE sensors can accurately detect and measure the pulse wave velocity (PWV) when skin mounted. Moreover, we show that these tactile sensors when arrayed enabled fast reliable one-touch surface texture classification with neuromorphic encoding and deep learning algorithms.	electronic skin; machine learning; robotics; sensor; wearable	20200928	https://pubmed.ncbi.nlm.nih.gov/32989151
McClelland, James L; Hill, Felix; Rudolph, Maja; Baldridge, Jason; Schutze, Hinrich	Placing language in an integrated understanding system: Next steps toward human-level performance in neural language models.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Oct 20;117(42):25966-25974. doi: 10.1073/pnas.1910416117. Epub 2020 Sep 28.	Language is crucial for human intelligence, but what exactly is its role? We take language to be a part of a system for understanding and communicating about situations. In humans, these abilities emerge gradually from experience and depend on domain-general principles of biological neural networks: connection-based learning, distributed representation, and context-sensitive, mutual constraint satisfaction-based processing. Current artificial language processing systems rely on the same domain general principles, embodied in artificial neural networks. Indeed, recent progress in this field depends on query-based attention, which extends the ability of these systems to exploit context and has contributed to remarkable breakthroughs. Nevertheless, most current models focus exclusively on language-internal tasks, limiting their ability to perform tasks that depend on understanding situations. These systems also lack memory for the contents of prior situations outside of a fixed contextual span. We describe the organization of the brain's distributed understanding system, which includes a fast learning system that addresses the memory problem. We sketch a framework for future models of understanding drawing equally on cognitive neuroscience and artificial intelligence and exploiting query-based attention. We highlight relevant current directions and consider further developments needed to fully capture human-level language understanding in a computational system.	artificial intelligence; cognitive neuroscience; deep learning; natural language understanding; situation models	20200928	https://pubmed.ncbi.nlm.nih.gov/32989131
Maslova, Alexandra; Ramirez, Ricardo N; Ma, Ke; Schmutz, Hugo; Wang, Chendi; Fox, Curtis; Ng, Bernard; Benoist, Christophe; Mostafavi, Sara	Deep learning of immune cell differentiation.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Oct 13;117(41):25655-25666. doi: 10.1073/pnas.2011795117. Epub 2020 Sep 25.	Although we know many sequence-specific transcription factors (TFs), how the DNA sequence of cis-regulatory elements is decoded and orchestrated on the genome scale to determine immune cell differentiation is beyond our grasp. Leveraging a granular atlas of chromatin accessibility across 81 immune cell types, we asked if a convolutional neural network (CNN) could learn to infer cell type-specific chromatin accessibility solely from regulatory DNA sequences. With a tailored architecture and an ensemble approach to CNN parameter interpretation, we show that our trained network ("AI-TAC") does so by rediscovering ab initio the binding motifs for known regulators and some unknown ones. Motifs whose importance is learned virtually as functionally important overlap strikingly well with positions determined by chromatin immunoprecipitation for several TFs. AI-TAC establishes a hierarchy of TFs and their interactions that drives lineage specification and also identifies stage-specific interactions, like Pax5/Ebf1 vs. Pax5/Prdm1, or the role of different NF-kappaB dimers in different cell types. AI-TAC assigns Spi1/Cebp and Pax5/Ebf1 as the drivers necessary for myeloid and B lineage fates, respectively, but no factors seemed as dominantly required for T cell differentiation, which may represent a fall-back pathway. Mouse-trained AI-TAC can parse human DNA, revealing a strikingly similar ranking of influential TFs and providing additional support that AI-TAC is a generalizable regulatory sequence decoder. Thus, deep learning can reveal the regulatory syntax predictive of the full differentiative complexity of the immune system.	artificial intelligence; gene regulation	20200925	https://pubmed.ncbi.nlm.nih.gov/32978299
Papyan, Vardan; Han, X Y; Donoho, David L	Prevalence of neural collapse during the terminal phase of deep learning training.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Oct 6;117(40):24652-24663. doi: 10.1073/pnas.2015509117. Epub 2020 Sep 21.	Modern practice for training classification deepnets involves a terminal phase of training (TPT), which begins at the epoch where training error first vanishes. During TPT, the training error stays effectively zero, while training loss is pushed toward zero. Direct measurements of TPT, for three prototypical deepnet architectures and across seven canonical classification datasets, expose a pervasive inductive bias we call neural collapse (NC), involving four deeply interconnected phenomena. (NC1) Cross-example within-class variability of last-layer training activations collapses to zero, as the individual activations themselves collapse to their class means. (NC2) The class means collapse to the vertices of a simplex equiangular tight frame (ETF). (NC3) Up to rescaling, the last-layer classifiers collapse to the class means or in other words, to the simplex ETF (i.e., to a self-dual configuration). (NC4) For a given activation, the classifier's decision collapses to simply choosing whichever class has the closest train class mean (i.e., the nearest class center [NCC] decision rule). The symmetric and very simple geometry induced by the TPT confers important benefits, including better generalization performance, better robustness, and better interpretability.	adversarial robustness; deep learning; inductive bias; nearest class center; simplex equiangular tight frame	20200921	https://pubmed.ncbi.nlm.nih.gov/32958680
Maoz, Ori; Tkacik, Gasper; Esteki, Mohamad Saleh; Kiani, Roozbeh; Schneidman, Elad	Learning probabilistic neural representations with randomly connected circuits.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Oct 6;117(40):25066-25073. doi: 10.1073/pnas.1912804117. Epub 2020 Sep 18.	The brain represents and reasons probabilistically about complex stimuli and motor actions using a noisy, spike-based neural code. A key building block for such neural computations, as well as the basis for supervised and unsupervised learning, is the ability to estimate the surprise or likelihood of incoming high-dimensional neural activity patterns. Despite progress in statistical modeling of neural responses and deep learning, current approaches either do not scale to large neural populations or cannot be implemented using biologically realistic mechanisms. Inspired by the sparse and random connectivity of real neuronal circuits, we present a model for neural codes that accurately estimates the likelihood of individual spiking patterns and has a straightforward, scalable, efficient, learnable, and realistic neural implementation. This model's performance on simultaneously recorded spiking activity of >100 neurons in the monkey visual and prefrontal cortices is comparable with or better than that of state-of-the-art models. Importantly, the model can be learned using a small number of samples and using a local learning rule that utilizes noise intrinsic to neural circuits. Slower, structural changes in random connectivity, consistent with rewiring and pruning processes, further improve the efficiency and sparseness of the resulting neural representations. Our results merge insights from neuroanatomy, machine learning, and theoretical neuroscience to suggest random sparse connectivity as a key design principle for neuronal computation.	cortical computation; learning rules; neural circuits; population codes; sparse nonlinear random projections	20200918	https://pubmed.ncbi.nlm.nih.gov/32948691
Bau, David; Zhu, Jun-Yan; Strobelt, Hendrik; Lapedriza, Agata; Zhou, Bolei; Torralba, Antonio	Understanding the role of individual units in a deep neural network.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Dec 1;117(48):30071-30078. doi: 10.1073/pnas.1907375117. Epub 2020 Sep 1.	Deep neural networks excel at finding hierarchical representations that solve complex tasks over large datasets. How can we humans understand these learned representations? In this work, we present network dissection, an analytic framework to systematically identify the semantics of individual hidden units within image classification and image generation networks. First, we analyze a convolutional neural network (CNN) trained on scene classification and discover units that match a diverse set of object concepts. We find evidence that the network has learned many object classes that play crucial roles in classifying scene classes. Second, we use a similar analytic method to analyze a generative adversarial network (GAN) model trained to generate scenes. By analyzing changes made when small sets of units are activated or deactivated, we find that objects can be added and removed from the output scenes while adapting to the context. Finally, we apply our analytic framework to understanding adversarial attacks and to semantic image editing.	computer vision; deep networks; machine learning	20200901	https://pubmed.ncbi.nlm.nih.gov/32873639
Verpoort, Philipp C; Lee, Alpha A; Wales, David J	Archetypal landscapes for deep neural networks.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Sep 8;117(36):21857-21864. doi: 10.1073/pnas.1919995117. Epub 2020 Aug 25.	The predictive capabilities of deep neural networks (DNNs) continue to evolve to increasingly impressive levels. However, it is still unclear how training procedures for DNNs succeed in finding parameters that produce good results for such high-dimensional and nonconvex loss functions. In particular, we wish to understand why simple optimization schemes, such as stochastic gradient descent, do not end up trapped in local minima with high loss values that would not yield useful predictions. We explain the optimizability of DNNs by characterizing the local minima and transition states of the loss-function landscape (LFL) along with their connectivity. We show that the LFL of a DNN in the shallow network or data-abundant limit is funneled, and thus easy to optimize. Crucially, in the opposite low-data/deep limit, although the number of minima increases, the landscape is characterized by many minima with similar loss values separated by low barriers. This organization is different from the hierarchical landscapes of structural glass formers and explains why minimization procedures commonly employed by the machine-learning community can navigate the LFL successfully and reach low-lying solutions.	deep learning; energy landscapes; neural networks; optimization; statistical mechanics	20200825	https://pubmed.ncbi.nlm.nih.gov/32843349
Doan, Minh; Sebastian, Joseph A; Caicedo, Juan C; Siegert, Stefanie; Roch, Aline; Turner, Tracey R; Mykhailova, Olga; Pinto, Ruben N; McQuin, Claire; Goodman, Allen; Parsons, Michael J; Wolkenhauer, Olaf; Hennig, Holger; Singh, Shantanu; Wilson, Anne; Acker, Jason P; Rees, Paul; Kolios, Michael C; Carpenter, Anne E	Objective assessment of stored blood quality by deep learning.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Sep 1;117(35):21381-21390. doi: 10.1073/pnas.2001227117. Epub 2020 Aug 24.	Stored red blood cells (RBCs) are needed for life-saving blood transfusions, but they undergo continuous degradation. RBC storage lesions are often assessed by microscopic examination or biochemical and biophysical assays, which are complex, time-consuming, and destructive to fragile cells. Here we demonstrate the use of label-free imaging flow cytometry and deep learning to characterize RBC lesions. Using brightfield images, a trained neural network achieved 76.7% agreement with experts in classifying seven clinically relevant RBC morphologies associated with storage lesions, comparable to 82.5% agreement between different experts. Given that human observation and classification may not optimally discern RBC quality, we went further and eliminated subjective human annotation in the training step by training a weakly supervised neural network using only storage duration times. The feature space extracted by this network revealed a chronological progression of morphological changes that better predicted blood quality, as measured by physiological hemolytic assay readouts, than the conventional expert-assessed morphology classification system. With further training and clinical testing across multiple sites, protocols, and instruments, deep learning and label-free imaging flow cytometry might be used to routinely and objectively assess RBC storage lesions. This would automate a complex protocol, minimize laboratory sample handling and preparation, and reduce the impact of procedural errors and discrepancies between facilities and blood donors. The chronology-based machine-learning approach may also improve upon humans' assessment of morphological changes in other biomedically important progressions, such as differentiation and metastasis.	cell morphology; deep learning; stored blood quality; weakly supervised learning	20200824	https://pubmed.ncbi.nlm.nih.gov/32839303
Barreto, Andre; Hou, Shaobo; Borsa, Diana; Silver, David; Precup, Doina	Fast reinforcement learning with generalized policy updates.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Dec 1;117(48):30079-30087. doi: 10.1073/pnas.1907370117. Epub 2020 Aug 17.	The combination of reinforcement learning with deep learning is a promising approach to tackle important sequential decision-making problems that are currently intractable. One obstacle to overcome is the amount of data needed by learning systems of this type. In this article, we propose to address this issue through a divide-and-conquer approach. We argue that complex decision problems can be naturally decomposed into multiple tasks that unfold in sequence or in parallel. By associating each task with a reward function, this problem decomposition can be seamlessly accommodated within the standard reinforcement-learning formalism. The specific way we do so is through a generalization of two fundamental operations in reinforcement learning: policy improvement and policy evaluation. The generalized version of these operations allow one to leverage the solution of some tasks to speed up the solution of others. If the reward function of a task can be well approximated as a linear combination of the reward functions of tasks previously solved, we can reduce a reinforcement-learning problem to a simpler linear regression. When this is not the case, the agent can still exploit the task solutions by using them to interact with and learn about the environment. Both strategies considerably reduce the amount of data needed to solve a reinforcement-learning problem.	artificial intelligence; generalized policy evaluation; generalized policy improvement; reinforcement learning; successor features	20200817	https://pubmed.ncbi.nlm.nih.gov/32817541
Hu, Zicheng; Tang, Alice; Singh, Jaiveer; Bhattacharya, Sanchita; Butte, Atul J	A robust and interpretable end-to-end deep learning model for cytometry data.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Sep 1;117(35):21373-21380. doi: 10.1073/pnas.2003026117. Epub 2020 Aug 14.	Cytometry technologies are essential tools for immunology research, providing high-throughput measurements of the immune cells at the single-cell level. Existing approaches in interpreting and using cytometry measurements include manual or automated gating to identify cell subsets from the cytometry data, providing highly intuitive results but may lead to significant information loss, in that additional details in measured or correlated cell signals might be missed. In this study, we propose and test a deep convolutional neural network for analyzing cytometry data in an end-to-end fashion, allowing a direct association between raw cytometry data and the clinical outcome of interest. Using nine large cytometry by time-of-flight mass spectrometry or mass cytometry (CyTOF) studies from the open-access ImmPort database, we demonstrated that the deep convolutional neural network model can accurately diagnose the latent cytomegalovirus (CMV) in healthy individuals, even when using highly heterogeneous data from different studies. In addition, we developed a permutation-based method for interpreting the deep convolutional neural network model. We were able to identify a CD27- CD94+ CD8+ T cell population significantly associated with latent CMV infection, confirming the findings in previous studies. Finally, we provide a tutorial for creating, training, and interpreting the tailored deep learning model for cytometry data using Keras and TensorFlow (https://github.com/hzc363/DeepLearningCyTOF).	CyTOF; cytomegalovirus; deep learning; flow cytometry; model interpretation	20200814	https://pubmed.ncbi.nlm.nih.gov/32801215
Kandel, Mikhail E; Rubessa, Marcello; He, Yuchen R; Schreiber, Sierra; Meyers, Sasha; Matter Naves, Luciana; Sermersheim, Molly K; Sell, G Scott; Szewczyk, Michael J; Sobh, Nahil; Wheeler, Matthew B; Popescu, Gabriel	Reproductive outcomes predicted by phase imaging with computational specificity of spermatozoon ultrastructure.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Aug 4;117(31):18302-18309. doi: 10.1073/pnas.2001754117. Epub 2020 Jul 20.	The ability to evaluate sperm at the microscopic level, at high-throughput, would be useful for assisted reproductive technologies (ARTs), as it can allow specific selection of sperm cells for in vitro fertilization (IVF). The tradeoff between intrinsic imaging and external contrast agents is particularly acute in reproductive medicine. The use of fluorescence labels has enabled new cell-sorting strategies and given new insights into developmental biology. Nevertheless, using extrinsic contrast agents is often too invasive for routine clinical operation. Raising questions about cell viability, especially for single-cell selection, clinicians prefer intrinsic contrast in the form of phase-contrast, differential-interference contrast, or Hoffman modulation contrast. While such instruments are nondestructive, the resulting image suffers from a lack of specificity. In this work, we provide a template to circumvent the tradeoff between cell viability and specificity by combining high-sensitivity phase imaging with deep learning. In order to introduce specificity to label-free images, we trained a deep-convolutional neural network to perform semantic segmentation on quantitative phase maps. This approach, a form of phase imaging with computational specificity (PICS), allowed us to efficiently analyze thousands of sperm cells and identify correlations between dry-mass content and artificial-reproduction outcomes. Specifically, we found that the dry-mass content ratios between the head, midpiece, and tail of the cells can predict the percentages of success for zygote cleavage and embryo blastocyst formation.	assisted reproduction; machine learning; phase imaging with computational specificity; quantitative phase imaging; sperm	20200720	https://pubmed.ncbi.nlm.nih.gov/32690677
Stengel, Karen; Glaws, Andrew; Hettinger, Dylan; King, Ryan N	Adversarial super-resolution of climatological wind and solar data.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Jul 21;117(29):16805-16815. doi: 10.1073/pnas.1918964117. Epub 2020 Jul 6.	Accurate and high-resolution data reflecting different climate scenarios are vital for policy makers when deciding on the development of future energy resources, electrical infrastructure, transportation networks, agriculture, and many other societally important systems. However, state-of-the-art long-term global climate simulations are unable to resolve the spatiotemporal characteristics necessary for resource assessment or operational planning. We introduce an adversarial deep learning approach to super resolve wind velocity and solar irradiance outputs from global climate models to scales sufficient for renewable energy resource assessment. Using adversarial training to improve the physical and perceptual performance of our networks, we demonstrate up to a [Formula: see text] resolution enhancement of wind and solar data. In validation studies, the inferred fields are robust to input noise, possess the correct small-scale properties of atmospheric turbulent flow and solar irradiance, and retain consistency at large scales with coarse data. An additional advantage of our fully convolutional architecture is that it allows for training on small domains and evaluation on arbitrarily-sized inputs, including global scale. We conclude with a super-resolution study of renewable energy resources based on climate scenario data from the Intergovernmental Panel on Climate Change's Fifth Assessment Report.	adversarial training; climate downscaling; deep learning	20200706	https://pubmed.ncbi.nlm.nih.gov/32631993
Poggio, Tomaso; Banburski, Andrzej; Liao, Qianli	Theoretical issues in deep networks.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Dec 1;117(48):30039-30045. doi: 10.1073/pnas.1907369117. Epub 2020 Jun 9.	While deep learning is successful in a number of applications, it is not yet well understood theoretically. A theoretical characterization of deep learning should answer questions about their approximation power, the dynamics of optimization, and good out-of-sample performance, despite overparameterization and the absence of explicit regularization. We review our recent results toward this goal. In approximation theory both shallow and deep networks are known to approximate any continuous functions at an exponential cost. However, we proved that for certain types of compositional functions, deep networks of the convolutional type (even without weight sharing) can avoid the curse of dimensionality. In characterizing minimization of the empirical exponential loss we consider the gradient flow of the weight directions rather than the weights themselves, since the relevant function underlying classification corresponds to normalized networks. The dynamics of normalized weights turn out to be equivalent to those of the constrained problem of minimizing the loss subject to a unit norm constraint. In particular, the dynamics of typical gradient descent have the same critical points as the constrained problem. Thus there is implicit regularization in training deep networks under exponential-type loss functions during gradient flow. As a consequence, the critical points correspond to minimum norm infima of the loss. This result is especially relevant because it has been recently shown that, for overparameterized models, selection of a minimum norm solution optimizes cross-validation leave-one-out stability and thereby the expected error. Thus our results imply that gradient descent in deep networks minimize the expected error.	approximation; deep learning; generalization; machine learning; optimization	20200609	https://pubmed.ncbi.nlm.nih.gov/32518109
Simine, Lena; Allen, Thomas C; Rossky, Peter J	Predicting optical spectra for optoelectronic polymers using coarse-grained models and recurrent neural networks.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Jun 23;117(25):13945-13948. doi: 10.1073/pnas.1918696117. Epub 2020 Jun 8.	Coarse-grained modeling of conjugated polymers has become an increasingly popular route to investigate the physics of organic optoelectronic materials. While ultraviolet (UV)-vis spectroscopy remains one of the key experimental methods for the interrogation of these materials, a rigorous bridge between simulated coarse-grained structures and spectroscopy has not been established. Here, we address this challenge by developing a method that can predict spectra of conjugated polymers directly from coarse-grained representations while avoiding repetitive procedures such as ad hoc back-mapping from coarse-grained to atomistic representations followed by spectral computation using quantum chemistry. Our approach is based on a generative deep-learning model: the long-short-term memory recurrent neural network (LSTM-RNN). The latter is suggested by the apparent similarity between natural languages and the mathematical structure of perturbative expansions of, in our case, excited-state energies perturbed by conformational fluctuations. We also use this model to explore the level of sensitivity of spectra to the coarse-grained representation back-mapping protocol. Our approach presents a tool uniquely suited for improving postsimulation analysis protocols, as well as, potentially, for including spectral data as input in the refinement of coarse-grained potentials.	coarse-grained modeling; conjugated polymers; machine learning; molecular spectroscopy	20200608	https://pubmed.ncbi.nlm.nih.gov/32513725
Manning, Christopher D; Clark, Kevin; Hewitt, John; Khandelwal, Urvashi; Levy, Omer	Emergent linguistic structure in artificial neural networks trained by self-supervision.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Dec 1;117(48):30046-30054. doi: 10.1073/pnas.1907367117. Epub 2020 Jun 3.	This paper explores the knowledge of linguistic structure learned by large artificial neural networks, trained via self-supervision, whereby the model simply tries to predict a masked word in a given context. Human language communication is via sequences of words, but language understanding requires constructing rich hierarchical structures that are never observed explicitly. The mechanisms for this have been a prime mystery of human language acquisition, while engineering work has mainly proceeded by supervised learning on treebanks of sentences hand labeled for this latent structure. However, we demonstrate that modern deep contextual language models learn major aspects of this structure, without any explicit supervision. We develop methods for identifying linguistic hierarchical structure emergent in artificial neural networks and demonstrate that components in these models focus on syntactic grammatical relationships and anaphoric coreference. Indeed, we show that a linear transformation of learned embeddings in these models captures parse tree distances to a surprising degree, allowing approximate reconstruction of the sentence tree structures normally assumed by linguists. These results help explain why these models have brought such large improvements across many language-understanding tasks.	artificial neural netwok; learning; self-supervision; syntax	20200603	https://pubmed.ncbi.nlm.nih.gov/32493748
Larrazabal, Agostina J; Nieto, Nicolas; Peterson, Victoria; Milone, Diego H; Ferrante, Enzo	Gender imbalance in medical imaging datasets produces biased classifiers for computer-aided diagnosis.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Jun 9;117(23):12592-12594. doi: 10.1073/pnas.1919012117. Epub 2020 May 26.	Artificial intelligence (AI) systems for computer-aided diagnosis and image-based screening are being adopted worldwide by medical institutions. In such a context, generating fair and unbiased classifiers becomes of paramount importance. The research community of medical image computing is making great efforts in developing more accurate algorithms to assist medical doctors in the difficult task of disease diagnosis. However, little attention is paid to the way databases are collected and how this may influence the performance of AI systems. Our study sheds light on the importance of gender balance in medical imaging datasets used to train AI systems for computer-assisted diagnosis. We provide empirical evidence supported by a large-scale study, based on three deep neural network architectures and two well-known publicly available X-ray image datasets used to diagnose various thoracic diseases under different gender imbalance conditions. We found a consistent decrease in performance for underrepresented genders when a minimum balance is not fulfilled. This raises the alarm for national agencies in charge of regulating and approving computer-assisted diagnosis systems, which should include explicit gender balance and diversity recommendations. We also establish an open problem for the academic medical image computing community which needs to be addressed by novel algorithms endowed with robustness to gender imbalance.	computer-aided diagnosis; deep learning; gender bias; gendered innovations; medical image analysis	20200526	https://pubmed.ncbi.nlm.nih.gov/32457147
Antun, Vegard; Renna, Francesco; Poon, Clarice; Adcock, Ben; Hansen, Anders C	On instabilities of deep learning in image reconstruction and the potential costs of AI.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Dec 1;117(48):30088-30095. doi: 10.1073/pnas.1907377117. Epub 2020 May 11.	Deep learning, due to its unprecedented success in tasks such as image classification, has emerged as a new tool in image reconstruction with potential to change the field. In this paper, we demonstrate a crucial phenomenon: Deep learning typically yields unstable methods for image reconstruction. The instabilities usually occur in several forms: 1) Certain tiny, almost undetectable perturbations, both in the image and sampling domain, may result in severe artefacts in the reconstruction; 2) a small structural change, for example, a tumor, may not be captured in the reconstructed image; and 3) (a counterintuitive type of instability) more samples may yield poorer performance. Our stability test with algorithms and easy-to-use software detects the instability phenomena. The test is aimed at researchers, to test their networks for instabilities, and for government agencies, such as the Food and Drug Administration (FDA), to secure safe use of deep learning methods.	AI; deep learning; image reconstruction; instability; inverse problems	20200511	https://pubmed.ncbi.nlm.nih.gov/32393633
Yang, Yang; Youyou, Wu; Uzzi, Brian	Estimating the deep replicability of scientific findings using human and artificial intelligence.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 May 19;117(20):10762-10768. doi: 10.1073/pnas.1909046117. Epub 2020 May 4.	Replicability tests of scientific papers show that the majority of papers fail replication. Moreover, failed papers circulate through the literature as quickly as replicating papers. This dynamic weakens the literature, raises research costs, and demonstrates the need for new approaches for estimating a study's replicability. Here, we trained an artificial intelligence model to estimate a paper's replicability using ground truth data on studies that had passed or failed manual replication tests, and then tested the model's generalizability on an extensive set of out-of-sample studies. The model predicts replicability better than the base rate of reviewers and comparably as well as prediction markets, the best present-day method for predicting replicability. In out-of-sample tests on manually replicated papers from diverse disciplines and methods, the model had strong accuracy levels of 0.65 to 0.78. Exploring the reasons behind the model's predictions, we found no evidence for bias based on topics, journals, disciplines, base rates of failure, persuasion words, or novelty words like "remarkable" or "unexpected." We did find that the model's accuracy is higher when trained on a paper's text rather than its reported statistics and that n-grams, higher order word combinations that humans have difficulty processing, correlate with replication. We discuss how combining human and machine intelligence can raise confidence in research, provide research self-assessment techniques, and create methods that are scalable and efficient enough to review the ever-growing numbers of publications-a task that entails extensive human resources to accomplish with prediction markets and manual replication alone.	computational social science; machine learning; replicability	20200504	https://pubmed.ncbi.nlm.nih.gov/32366645
Friedmann, Drew; Pun, Albert; Adams, Eliza L; Lui, Jan H; Kebschull, Justus M; Grutzner, Sophie M; Castagnola, Caitlin; Tessier-Lavigne, Marc; Luo, Liqun	Mapping mesoscale axonal projections in the mouse brain using a 3D convolutional network.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 May 19;117(20):11068-11075. doi: 10.1073/pnas.1918465117. Epub 2020 May 1.	The projection targets of a neuronal population are a key feature of its anatomical characteristics. Historically, tissue sectioning, confocal microscopy, and manual scoring of specific regions of interest have been used to generate coarse summaries of mesoscale projectomes. We present here TrailMap, a three-dimensional (3D) convolutional network for extracting axonal projections from intact cleared mouse brains imaged by light-sheet microscopy. TrailMap allows region-based quantification of total axon content in large and complex 3D structures after registration to a standard reference atlas. The identification of axonal structures as thin as one voxel benefits from data augmentation but also requires a loss function that tolerates errors in annotation. A network trained with volumes of serotonergic axons in all major brain regions can be generalized to map and quantify axons from thalamocortical, deep cerebellar, and cortical projection neurons, validating transfer learning as a tool to adapt the model to novel categories of axonal morphology. Speed of training, ease of use, and accuracy improve over existing tools without a need for specialized computing hardware. Given the recent emphasis on genetically and functionally defining cell types in neural circuit analysis, TrailMap will facilitate automated extraction and quantification of axons from these specific cell types at the scale of the entire mouse brain, an essential component of deciphering their connectivity.	axons; light-sheet microscopy; neural networks; tissue clearing; whole-brain	20200501	https://pubmed.ncbi.nlm.nih.gov/32358193
Bartlett, Peter L; Long, Philip M; Lugosi, Gabor; Tsigler, Alexander	Benign overfitting in linear regression.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Dec 1;117(48):30063-30070. doi: 10.1073/pnas.1907378117. Epub 2020 Apr 24.	The phenomenon of benign overfitting is one of the key mysteries uncovered by deep learning methodology: deep neural networks seem to predict well, even with a perfect fit to noisy training data. Motivated by this phenomenon, we consider when a perfect fit to training data in linear regression is compatible with accurate prediction. We give a characterization of linear regression problems for which the minimum norm interpolating prediction rule has near-optimal prediction accuracy. The characterization is in terms of two notions of the effective rank of the data covariance. It shows that overparameterization is essential for benign overfitting in this setting: the number of directions in parameter space that are unimportant for prediction must significantly exceed the sample size. By studying examples of data covariance properties that this characterization shows are required for benign overfitting, we find an important role for finite-dimensional data: the accuracy of the minimum norm interpolating prediction rule approaches the best possible accuracy for a much narrower range of properties of the data distribution when the data lie in an infinite-dimensional space vs. when the data lie in a finite-dimensional space with dimension that grows faster than the sample size.	interpolation; linear regression; overfitting; statistical learning theory	20200424	https://pubmed.ncbi.nlm.nih.gov/32332161
Nygate, Yoav N; Levi, Mattan; Mirsky, Simcha K; Turko, Nir A; Rubin, Moran; Barnea, Itay; Dardikman-Yoffe, Gili; Haifler, Miki; Shalev, Alon; Shaked, Natan T	Holographic virtual staining of individual biological cells.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Apr 28;117(17):9223-9231. doi: 10.1073/pnas.1919569117. Epub 2020 Apr 13.	Many medical and biological protocols for analyzing individual biological cells involve morphological evaluation based on cell staining, designed to enhance imaging contrast and enable clinicians and biologists to differentiate between various cell organelles. However, cell staining is not always allowed in certain medical procedures. In other cases, staining may be time-consuming or expensive to implement. Staining protocols may be operator-sensitive, and hence may lead to varying analytical results, as well as cause artificial imaging artifacts or false heterogeneity. We present a deep-learning approach, called HoloStain, which converts images of isolated biological cells acquired without staining by holographic microscopy to their virtually stained images. We demonstrate this approach for human sperm cells, as there is a well-established protocol and global standardization for characterizing the morphology of stained human sperm cells for fertility evaluation, but, on the other hand, staining might be cytotoxic and thus is not allowed during human in vitro fertilization (IVF). After a training process, the deep neural network can take images of unseen sperm cells retrieved from holograms acquired without staining and convert them to their stainlike images. We obtained a fivefold recall improvement in the analysis results, demonstrating the advantage of using virtual staining for sperm cell analysis. With the introduction of simple holographic imaging methods in clinical settings, the proposed method has a great potential to become a common practice in human IVF procedures, as well as to significantly simplify and radically change other cell analyses and techniques such as imaging flow cytometry.	biological cell imaging; deep learning; digital holography	20200413	https://pubmed.ncbi.nlm.nih.gov/32284403
Koenecke, Allison; Nam, Andrew; Lake, Emily; Nudell, Joe; Quartey, Minnie; Mengesha, Zion; Toups, Connor; Rickford, John R; Jurafsky, Dan; Goel, Sharad	Racial disparities in automated speech recognition.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Apr 7;117(14):7684-7689. doi: 10.1073/pnas.1915768117. Epub 2020 Mar 23.	Automated speech recognition (ASR) systems, which use sophisticated machine-learning algorithms to convert spoken language to text, have become increasingly widespread, powering popular virtual assistants, facilitating automated closed captioning, and enabling digital dictation platforms for health care. Over the last several years, the quality of these systems has dramatically improved, due both to advances in deep learning and to the collection of large-scale datasets used to train the systems. There is concern, however, that these tools do not work equally well for all subgroups of the population. Here, we examine the ability of five state-of-the-art ASR systems-developed by Amazon, Apple, Google, IBM, and Microsoft-to transcribe structured interviews conducted with 42 white speakers and 73 black speakers. In total, this corpus spans five US cities and consists of 19.8 h of audio matched on the age and gender of the speaker. We found that all five ASR systems exhibited substantial racial disparities, with an average word error rate (WER) of 0.35 for black speakers compared with 0.19 for white speakers. We trace these disparities to the underlying acoustic models used by the ASR systems as the race gap was equally large on a subset of identical phrases spoken by black and white individuals in our corpus. We conclude by proposing strategies-such as using more diverse training datasets that include African American Vernacular English-to reduce these performance differences and ensure speech recognition technology is inclusive.	fair machine learning; natural language processing; speech-to-text	20200323	https://pubmed.ncbi.nlm.nih.gov/32205437
Lu, Lu; Dao, Ming; Kumar, Punit; Ramamurty, Upadrasta; Karniadakis, George Em; Suresh, Subra	Extraction of mechanical properties of materials through deep learning from instrumented indentation.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Mar 31;117(13):7052-7062. doi: 10.1073/pnas.1922210117. Epub 2020 Mar 16.	Instrumented indentation has been developed and widely utilized as one of the most versatile and practical means of extracting mechanical properties of materials. This method is particularly desirable for those applications where it is difficult to experimentally determine the mechanical properties using stress-strain data obtained from coupon specimens. Such applications include material processing and manufacturing of small and large engineering components and structures involving the following: three-dimensional (3D) printing, thin-film and multilayered structures, and integrated manufacturing of materials for coupled mechanical and functional properties. Here, we utilize the latest developments in neural networks, including a multifidelity approach whereby deep-learning algorithms are trained to extract elastoplastic properties of metals and alloys from instrumented indentation results using multiple datasets for desired levels of improved accuracy. We have established algorithms for solving inverse problems by recourse to single, dual, and multiple indentation and demonstrate that these algorithms significantly outperform traditional brute force computations and function-fitting methods. Moreover, we present several multifidelity approaches specifically for solving the inverse indentation problem which 1) significantly reduce the number of high-fidelity datasets required to achieve a given level of accuracy, 2) utilize known physical and scaling laws to improve training efficiency and accuracy, and 3) integrate simulation and experimental data for training disparate datasets to learn and minimize systematic errors. The predictive capabilities and advantages of these multifidelity methods have been assessed by direct comparisons with experimental results for indentation for different commercial alloys, including two wrought aluminum alloys and several 3D printed titanium alloys.	3D printed materials; machine learning; multifidelity modeling; stress-strain behavior; transfer learning	20200316	https://pubmed.ncbi.nlm.nih.gov/32179694
?	Correction for Shi et al., Deep elastic strain engineering of bandgap through machine learning.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Mar 17;117(11):6274. doi: 10.1073/pnas.2002727117. Epub 2020 Mar 9.	?		20200309	https://pubmed.ncbi.nlm.nih.gov/32152115
Carulli, Daniela; Broersen, Robin; de Winter, Fred; Muir, Elizabeth M; Meskovic, Maja; de Waal, Matthijs; de Vries, Sharon; Boele, Henk-Jan; Canto, Cathrin B; De Zeeuw, Chris I; Verhaagen, Joost	Cerebellar plasticity and associative memories are controlled by perineuronal nets.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Mar 24;117(12):6855-6865. doi: 10.1073/pnas.1916163117. Epub 2020 Mar 9.	Perineuronal nets (PNNs) are assemblies of extracellular matrix molecules, which surround the cell body and dendrites of many types of neuron and regulate neural plasticity. PNNs are prominently expressed around neurons of the deep cerebellar nuclei (DCN), but their role in adult cerebellar plasticity and behavior is far from clear. Here we show that PNNs in the mouse DCN are diminished during eyeblink conditioning (EBC), a form of associative motor learning that depends on DCN plasticity. When memories are fully acquired, PNNs are restored. Enzymatic digestion of PNNs in the DCN improves EBC learning, but intact PNNs are necessary for memory retention. At the structural level, PNN removal induces significant synaptic rearrangements in vivo, resulting in increased inhibition of DCN baseline activity in awake behaving mice. Together, these results demonstrate that PNNs are critical players in the regulation of cerebellar circuitry and function.	cerebellum; eyeblink conditioning; learning; perineuronal net; plasticity	20200309	https://pubmed.ncbi.nlm.nih.gov/32152108
Sejnowski, Terrence J	The unreasonable effectiveness of deep learning in artificial intelligence.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Dec 1;117(48):30033-30038. doi: 10.1073/pnas.1907373117. Epub 2020 Jan 28.	Deep learning networks have been trained to recognize speech, caption photographs, and translate text between languages at high levels of performance. Although applications of deep learning networks to real-world problems have become ubiquitous, our understanding of why they are so effective is lacking. These empirical results should not be possible according to sample complexity in statistics and nonconvex optimization theory. However, paradoxes in the training and effectiveness of deep learning networks are being investigated and insights are being found in the geometry of high-dimensional spaces. A mathematical theory of deep learning would illuminate how they function, allow us to assess the strengths and weaknesses of different network architectures, and lead to major improvements. Deep learning has provided natural ways for humans to communicate with digital devices and is foundational for building artificial general intelligence. Deep learning was inspired by the architecture of the cerebral cortex and insights into autonomy and general intelligence may be found in other brain regions that are essential for planning and survival, but major breakthroughs will be needed to achieve these goals.	artificial intelligence; deep learning; neural networks	20200128	https://pubmed.ncbi.nlm.nih.gov/31992643
Graham, Garrett; Csicsery, Nicholas; Stasiowski, Elizabeth; Thouvenin, Gregoire; Mather, William H; Ferry, Michael; Cookson, Scott; Hasty, Jeff	Genome-scale transcriptional dynamics and environmental biosensing.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Feb 11;117(6):3301-3306. doi: 10.1073/pnas.1913003117. Epub 2020 Jan 23.	Genome-scale technologies have enabled mapping of the complex molecular networks that govern cellular behavior. An emerging theme in the analyses of these networks is that cells use many layers of regulatory feedback to constantly assess and precisely react to their environment. The importance of complex feedback in controlling the real-time response to external stimuli has led to a need for the next generation of cell-based technologies that enable both the collection and analysis of high-throughput temporal data. Toward this end, we have developed a microfluidic platform capable of monitoring temporal gene expression from over 2,000 promoters. By coupling the "Dynomics" platform with deep neural network (DNN) and associated explainable artificial intelligence (XAI) algorithms, we show how machine learning can be harnessed to assess patterns in transcriptional data on a genome scale and identify which genes contribute to these patterns. Furthermore, we demonstrate the utility of the Dynomics platform as a field-deployable real-time biosensor through prediction of the presence of heavy metals in urban water and mine spill samples, based on the the dynamic transcription profiles of 1,807 unique Escherichia coli promoters.	E. coli transcriptomics; biosensor; dynamics; explainable AI; high-throughput microfluidics	20200123	https://pubmed.ncbi.nlm.nih.gov/31974311
Yang, Jianyi; Anishchenko, Ivan; Park, Hahnbeom; Peng, Zhenling; Ovchinnikov, Sergey; Baker, David	Improved protein structure prediction using predicted interresidue orientations.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Jan 21;117(3):1496-1503. doi: 10.1073/pnas.1914677117. Epub 2020 Jan 2.	The prediction of interresidue contacts and distances from coevolutionary data using deep learning has considerably advanced protein structure prediction. Here, we build on these advances by developing a deep residual network for predicting interresidue orientations, in addition to distances, and a Rosetta-constrained energy-minimization protocol for rapidly and accurately generating structure models guided by these restraints. In benchmark tests on 13th Community-Wide Experiment on the Critical Assessment of Techniques for Protein Structure Prediction (CASP13)- and Continuous Automated Model Evaluation (CAMEO)-derived sets, the method outperforms all previously described structure-prediction methods. Although trained entirely on native proteins, the network consistently assigns higher probability to de novo-designed proteins, identifying the key fold-determining residues and providing an independent quantitative measure of the "ideality" of a protein structure. The method promises to be useful for a broad range of protein structure prediction and design problems.	deep learning; protein contact prediction; protein structure prediction	20200102	https://pubmed.ncbi.nlm.nih.gov/31896580
Mockl, Leonhard; Roy, Anish R; Petrov, Petar N; Moerner, W E	Accurate and rapid background estimation in single-molecule localization microscopy using the deep neural network BGnet.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Jan 7;117(1):60-67. doi: 10.1073/pnas.1916219117. Epub 2019 Dec 23.	Background fluorescence, especially when it exhibits undesired spatial features, is a primary factor for reduced image quality in optical microscopy. Structured background is particularly detrimental when analyzing single-molecule images for 3-dimensional localization microscopy or single-molecule tracking. Here, we introduce BGnet, a deep neural network with a U-net-type architecture, as a general method to rapidly estimate the background underlying the image of a point source with excellent accuracy, even when point-spread function (PSF) engineering is in use to create complex PSF shapes. We trained BGnet to extract the background from images of various PSFs and show that the identification is accurate for a wide range of different interfering background structures constructed from many spatial frequencies. Furthermore, we demonstrate that the obtained background-corrected PSF images, for both simulated and experimental data, lead to a substantial improvement in localization precision. Finally, we verify that structured background estimation with BGnet results in higher quality of superresolution reconstructions of biological structures.	background estimation; deep learning; localization microscopy; single-molecule methods; superresolution	20191223	https://pubmed.ncbi.nlm.nih.gov/31871202
Baldassi, Carlo; Pittorino, Fabrizio; Zecchina, Riccardo	Shaping the learning landscape in neural networks around wide flat minima.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Jan 7;117(1):161-170. doi: 10.1073/pnas.1908636117. Epub 2019 Dec 23.	Learning in deep neural networks takes place by minimizing a nonconvex high-dimensional loss function, typically by a stochastic gradient descent (SGD) strategy. The learning process is observed to be able to find good minimizers without getting stuck in local critical points and such minimizers are often satisfactory at avoiding overfitting. How these 2 features can be kept under control in nonlinear devices composed of millions of tunable connections is a profound and far-reaching open question. In this paper we study basic nonconvex 1- and 2-layer neural network models that learn random patterns and derive a number of basic geometrical and algorithmic features which suggest some answers. We first show that the error loss function presents few extremely wide flat minima (WFM) which coexist with narrower minima and critical points. We then show that the minimizers of the cross-entropy loss function overlap with the WFM of the error loss. We also show examples of learning devices for which WFM do not exist. From the algorithmic perspective we derive entropy-driven greedy and message-passing algorithms that focus their search on wide flat regions of minimizers. In the case of SGD and cross-entropy loss, we show that a slow reduction of the norm of the weights along the learning process also leads to WFM. We corroborate the results by a numerical study of the correlations between the volumes of the minimizers, their Hessian, and their generalization performance on real data.	machine learning; neural networks; statistical physics	20191223	https://pubmed.ncbi.nlm.nih.gov/31871189
Qi, Di; Majda, Andrew J	Using machine learning to predict extreme events in complex systems.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Jan 7;117(1):52-59. doi: 10.1073/pnas.1917285117. Epub 2019 Dec 23.	Extreme events and the related anomalous statistics are ubiquitously observed in many natural systems, and the development of efficient methods to understand and accurately predict such representative features remains a grand challenge. Here, we investigate the skill of deep learning strategies in the prediction of extreme events in complex turbulent dynamical systems. Deep neural networks have been successfully applied to many imaging processing problems involving big data, and have recently shown potential for the study of dynamical systems. We propose to use a densely connected mixed-scale network model to capture the extreme events appearing in a truncated Korteweg-de Vries (tKdV) statistical framework, which creates anomalous skewed distributions consistent with recent laboratory experiments for shallow water waves across an abrupt depth change, where a remarkable statistical phase transition is generated by varying the inverse temperature parameter in the corresponding Gibbs invariant measures. The neural network is trained using data without knowing the explicit model dynamics, and the training data are only drawn from the near-Gaussian regime of the tKdV model solutions without the occurrence of large extreme values. A relative entropy loss function, together with empirical partition functions, is proposed for measuring the accuracy of the network output where the dominant structures in the turbulent field are emphasized. The optimized network is shown to gain uniformly high skill in accurately predicting the solutions in a wide variety of statistical regimes, including highly skewed extreme events. The technique is promising to be further applied to other complicated high-dimensional systems.	anomalous extreme events; convolutional neural networks; turbulent dynamical systems	20191223	https://pubmed.ncbi.nlm.nih.gov/31871152
Mozaffar, M; Bostanabad, R; Chen, W; Ehmann, K; Cao, J; Bessa, M A	Deep learning predicts path-dependent plasticity.	Proc Natl Acad Sci U S A	2019	Proc Natl Acad Sci U S A. 2019 Dec 16. pii: 1911815116. doi: 10.1073/pnas.1911815116.	Plasticity theory aims at describing the yield loci and work hardening of a material under general deformation states. Most of its complexity arises from the nontrivial dependence of the yield loci on the complete strain history of a material and its microstructure. This motivated 3 ingenious simplifications that underpinned a century of developments in this field: 1) yield criteria describing yield loci location; 2) associative or nonassociative flow rules defining the direction of plastic flow; and 3) effective stress-strain laws consistent with the plastic work equivalence principle. However, 2 key complications arise from these simplifications. First, finding equations that describe these 3 assumptions for materials with complex microstructures is not trivial. Second, yield surface evolution needs to be traced iteratively, i.e., through a return mapping algorithm. Here, we show that these assumptions are not needed in the context of sequence learning when using recurrent neural networks, diverting the above-mentioned complications. This work offers an alternative to currently established plasticity formulations by providing the foundations for finding history- and microstructure-dependent constitutive models through deep learning.	data-driven modeling; deep learning; plasticity; recurrent neural network	20191216	https://pubmed.ncbi.nlm.nih.gov/31843918
Yuan, Ye; Bar-Joseph, Ziv	Deep learning for inferring gene relationships from single-cell expression data.	Proc Natl Acad Sci U S A	2019	Proc Natl Acad Sci U S A. 2019 Dec 10. pii: 1911536116. doi: 10.1073/pnas.1911536116.	Several methods were developed to mine gene-gene relationships from expression data. Examples include correlation and mutual information methods for coexpression analysis, clustering and undirected graphical models for functional assignments, and directed graphical models for pathway reconstruction. Using an encoding for gene expression data, followed by deep neural networks analysis, we present a framework that can successfully address all of these diverse tasks. We show that our method, convolutional neural network for coexpression (CNNC), improves upon prior methods in tasks ranging from predicting transcription factor targets to identifying disease-related genes to causality inference. CNNC's encoding provides insights about some of the decisions it makes and their biological basis. CNNC is flexible and can easily be extended to integrate additional types of genomics data, leading to further improvements in its performance.	causality inference; deep learning; gene interactions	20191210	https://pubmed.ncbi.nlm.nih.gov/31822622
Smith, Jason T; Yao, Ruoyang; Sinsuebphon, Nattawut; Rudkouskaya, Alena; Un, Nathan; Mazurkiewicz, Joseph; Barroso, Margarida; Yan, Pingkun; Intes, Xavier	Fast fit-free analysis of fluorescence lifetime imaging via deep learning.	Proc Natl Acad Sci U S A	2019	Proc Natl Acad Sci U S A. 2019 Nov 26;116(48):24019-24030. doi: 10.1073/pnas.1912707116. Epub 2019 Nov 12.	Fluorescence lifetime imaging (FLI) provides unique quantitative information in biomedical and molecular biology studies but relies on complex data-fitting techniques to derive the quantities of interest. Herein, we propose a fit-free approach in FLI image formation that is based on deep learning (DL) to quantify fluorescence decays simultaneously over a whole image and at fast speeds. We report on a deep neural network (DNN) architecture, named fluorescence lifetime imaging network (FLI-Net) that is designed and trained for different classes of experiments, including visible FLI and near-infrared (NIR) FLI microscopy (FLIM) and NIR gated macroscopy FLI (MFLI). FLI-Net outputs quantitatively the spatially resolved lifetime-based parameters that are typically employed in the field. We validate the utility of the FLI-Net framework by performing quantitative microscopic and preclinical lifetime-based studies across the visible and NIR spectra, as well as across the 2 main data acquisition technologies. These results demonstrate that FLI-Net is well suited to accurately quantify complex fluorescence lifetimes in cells and, in real time, in intact animals without any parameter settings. Hence, FLI-Net paves the way to reproducible and quantitative lifetime studies at unprecedented speeds, for improved dissemination and impact of FLI in many important biomedical applications ranging from fundamental discoveries in molecular and cellular biology to clinical translation.	analytic optimization; deep learning; fluorescence lifetime; pharmacokinetics; simulation	20191112	https://pubmed.ncbi.nlm.nih.gov/31719196
Champion, Kathleen; Lusch, Bethany; Kutz, J Nathan; Brunton, Steven L	Data-driven discovery of coordinates and governing equations.	Proc Natl Acad Sci U S A	2019	Proc Natl Acad Sci U S A. 2019 Nov 5;116(45):22445-22451. doi: 10.1073/pnas.1906995116. Epub 2019 Oct 21.	The discovery of governing equations from scientific data has the potential to transform data-rich fields that lack well-characterized quantitative descriptions. Advances in sparse regression are currently enabling the tractable identification of both the structure and parameters of a nonlinear dynamical system from data. The resulting models have the fewest terms necessary to describe the dynamics, balancing model complexity with descriptive ability, and thus promoting interpretability and generalizability. This provides an algorithmic approach to Occam's razor for model discovery. However, this approach fundamentally relies on an effective coordinate system in which the dynamics have a simple representation. In this work, we design a custom deep autoencoder network to discover a coordinate transformation into a reduced space where the dynamics may be sparsely represented. Thus, we simultaneously learn the governing equations and the associated coordinate system. We demonstrate this approach on several example high-dimensional systems with low-dimensional behavior. The resulting modeling framework combines the strengths of deep neural networks for flexible representation and sparse identification of nonlinear dynamics (SINDy) for parsimonious models. This method places the discovery of coordinates and models on an equal footing.	deep learning; dynamical systems; machine learning; model discovery	20191021	https://pubmed.ncbi.nlm.nih.gov/31636218
Ebina, Teppei; Obara, Keitaro; Watakabe, Akiya; Masamizu, Yoshito; Terada, Shin-Ichiro; Matoba, Ryota; Takaji, Masafumi; Hatanaka, Nobuhiko; Nambu, Atsushi; Mizukami, Hiroaki; Yamamori, Tetsuo; Matsuzaki, Masanori	Arm movements induced by noninvasive optogenetic stimulation of the motor cortex in the common marmoset.	Proc Natl Acad Sci U S A	2019	Proc Natl Acad Sci U S A. 2019 Nov 5;116(45):22844-22850. doi: 10.1073/pnas.1903445116. Epub 2019 Oct 21.	Optogenetics is now a fundamental tool for investigating the relationship between neuronal activity and behavior. However, its application to the investigation of motor control systems in nonhuman primates is rather limited, because optogenetic stimulation of cortical neurons in nonhuman primates has failed to induce or modulate any hand/arm movements. Here, we used a tetracycline-inducible gene expression system carrying CaMKII promoter and the gene encoding a Channelrhodopsin-2 variant with fast kinetics in the common marmoset, a small New World monkey. In an awake state, forelimb movements could be induced when Channelrhodopsin-2-expressing neurons in the motor cortex were illuminated by blue laser light with a spot diameter of 1 mm or 2 mm through a cranial window without cortical invasion. Forelimb muscles responded 10 ms to 50 ms after photostimulation onset. Long-duration (500 ms) photostimulation induced discrete forelimb movements that could be markerlessly tracked with charge-coupled device cameras and a deep learning algorithm. Long-duration photostimulation mapping revealed that the primary motor cortex is divided into multiple domains that can induce hand and elbow movements in different directions. During performance of a forelimb movement task, movement trajectories were modulated by weak photostimulation, which did not induce visible forelimb movements at rest, around the onset of task-relevant movement. The modulation was biased toward the movement direction induced by the strong photostimulation. Combined with calcium imaging, all-optical interrogation of motor circuits should be possible in behaving marmosets.	Channelrhodopsin-2; common marmosets; forelimb; motor cortex; optogenetics	20191021	https://pubmed.ncbi.nlm.nih.gov/31636197
Kuo, Weicheng; Hne, Christian; Mukherjee, Pratik; Malik, Jitendra; Yuh, Esther L	Expert-level detection of acute intracranial hemorrhage on head computed tomography using deep learning.	Proc Natl Acad Sci U S A	2019	Proc Natl Acad Sci U S A. 2019 Nov 5;116(45):22737-22745. doi: 10.1073/pnas.1908021116. Epub 2019 Oct 21.	Computed tomography (CT) of the head is used worldwide to diagnose neurologic emergencies. However, expertise is required to interpret these scans, and even highly trained experts may miss subtle life-threatening findings. For head CT, a unique challenge is to identify, with perfect or near-perfect sensitivity and very high specificity, often small subtle abnormalities on a multislice cross-sectional (three-dimensional [3D]) imaging modality that is characterized by poor soft tissue contrast, low signal-to-noise using current low radiation-dose protocols, and a high incidence of artifacts. We trained a fully convolutional neural network with 4,396 head CT scans performed at the University of California at San Francisco and affiliated hospitals and compared the algorithm's performance to that of 4 American Board of Radiology (ABR) certified radiologists on an independent test set of 200 randomly selected head CT scans. Our algorithm demonstrated the highest accuracy to date for this clinical application, with a receiver operating characteristic (ROC) area under the curve (AUC) of 0.991 +/- 0.006 for identification of examinations positive for acute intracranial hemorrhage, and also exceeded the performance of 2 of 4 radiologists. We demonstrate an end-to-end network that performs joint classification and segmentation with examination-level classification comparable to experts, in addition to robust localization of abnormalities, including some that are missed by radiologists, both of which are critically important elements for this application.	deep learning; head computed tomography; intracranial hemorrhage; radiology	20191021	https://pubmed.ncbi.nlm.nih.gov/31636195
Kietzmann, Tim C; Spoerer, Courtney J; Sorensen, Lynn K A; Cichy, Radoslaw M; Hauk, Olaf; Kriegeskorte, Nikolaus	Recurrence is required to capture the representational dynamics of the human visual system.	Proc Natl Acad Sci U S A	2019	Proc Natl Acad Sci U S A. 2019 Oct 22;116(43):21854-21863. doi: 10.1073/pnas.1905544116. Epub 2019 Oct 7.	The human visual system is an intricate network of brain regions that enables us to recognize the world around us. Despite its abundant lateral and feedback connections, object processing is commonly viewed and studied as a feedforward process. Here, we measure and model the rapid representational dynamics across multiple stages of the human ventral stream using time-resolved brain imaging and deep learning. We observe substantial representational transformations during the first 300 ms of processing within and across ventral-stream regions. Categorical divisions emerge in sequence, cascading forward and in reverse across regions, and Granger causality analysis suggests bidirectional information flow between regions. Finally, recurrent deep neural network models clearly outperform parameter-matched feedforward models in terms of their ability to capture the multiregion cortical dynamics. Targeted virtual cooling experiments on the recurrent deep network models further substantiate the importance of their lateral and top-down connections. These results establish that recurrent models are required to understand information processing in the human ventral stream.	deep recurrent neural networks; magnetoencephalography; object recognition; representational dynamics; virtual cooling	20191007	https://pubmed.ncbi.nlm.nih.gov/31591217
Wang, Johnny; Knol, Maria J; Tiulpin, Aleksei; Dubost, Florian; de Bruijne, Marleen; Vernooij, Meike W; Adams, Hieab H H; Ikram, M Arfan; Niessen, Wiro J; Roshchupkin, Gennady V	Gray Matter Age Prediction as a Biomarker for Risk of Dementia.	Proc Natl Acad Sci U S A	2019	Proc Natl Acad Sci U S A. 2019 Oct 15;116(42):21213-21218. doi: 10.1073/pnas.1902376116. Epub 2019 Oct 1.	The gap between predicted brain age using magnetic resonance imaging (MRI) and chronological age may serve as a biomarker for early-stage neurodegeneration. However, owing to the lack of large longitudinal studies, it has been challenging to validate this link. We aimed to investigate the utility of such a gap as a risk biomarker for incident dementia using a deep learning approach for predicting brain age based on MRI-derived gray matter (GM). We built a convolutional neural network (CNN) model to predict brain age trained on 3,688 dementia-free participants of the Rotterdam Study (mean age 66 +/- 11 y, 55% women). Logistic regressions and Cox proportional hazards were used to assess the association of the age gap with incident dementia, adjusted for age, sex, intracranial volume, GM volume, hippocampal volume, white matter hyperintensities, years of education, and APOE epsilon4 allele carriership. Additionally, we computed the attention maps, which shows which regions are important for age prediction. Logistic regression and Cox proportional hazard models showed that the age gap was significantly related to incident dementia (odds ratio [OR] = 1.11 and 95% confidence intervals [CI] = 1.05-1.16; hazard ratio [HR] = 1.11, and 95% CI = 1.06-1.15, respectively). Attention maps indicated that GM density around the amygdala and hippocampi primarily drove the age estimation. We showed that the gap between predicted and chronological brain age is a biomarker, complimentary to those that are known, associated with risk of dementia, and could possibly be used for early-stage dementia risk screening.	age prediction; deep learning; dementia; magnetic resonance imaging; voxel-based morphometry	20191001	https://pubmed.ncbi.nlm.nih.gov/31575746
Goy, Alexandre; Rughoobur, Girish; Li, Shuai; Arthur, Kwabena; Akinwande, Akintunde I; Barbastathis, George	High-resolution limited-angle phase tomography of dense layered objects using deep neural networks.	Proc Natl Acad Sci U S A	2019	Proc Natl Acad Sci U S A. 2019 Oct 1;116(40):19848-19856. doi: 10.1073/pnas.1821378116. Epub 2019 Sep 16.	We present a machine learning-based method for tomographic reconstruction of dense layered objects, with range of projection angles limited to [Formula: see text] Whereas previous approaches to phase tomography generally require 2 steps, first to retrieve phase projections from intensity projections and then to perform tomographic reconstruction on the retrieved phase projections, in our work a physics-informed preprocessor followed by a deep neural network (DNN) conduct the 3-dimensional reconstruction directly from the intensity projections. We demonstrate this single-step method experimentally in the visible optical domain on a scaled-up integrated circuit phantom. We show that even under conditions of highly attenuated photon fluxes a DNN trained only on synthetic data can be used to successfully reconstruct physical samples disjoint from the synthetic training set. Thus, the need for producing a large number of physical examples for training is ameliorated. The method is generally applicable to tomography with electromagnetic or other types of radiation at all bands.	deep learning; imaging through scattering media; tomography	20190916	https://pubmed.ncbi.nlm.nih.gov/31527279
Bonati, Luigi; Zhang, Yue-Yu; Parrinello, Michele	Neural networks-based variationally enhanced sampling.	Proc Natl Acad Sci U S A	2019	Proc Natl Acad Sci U S A. 2019 Sep 3;116(36):17641-17647. doi: 10.1073/pnas.1907975116. Epub 2019 Aug 15.	Sampling complex free-energy surfaces is one of the main challenges of modern atomistic simulation methods. The presence of kinetic bottlenecks in such surfaces often renders a direct approach useless. A popular strategy is to identify a small number of key collective variables and to introduce a bias potential that is able to favor their fluctuations in order to accelerate sampling. Here, we propose to use machine-learning techniques in conjunction with the recent variationally enhanced sampling method [O. Valsson, M. Parrinello, Phys. Rev. Lett. 113, 090601 (2014)] in order to determine such potential. This is achieved by expressing the bias as a neural network. The parameters are determined in a variational learning scheme aimed at minimizing an appropriate functional. This required the development of a more efficient minimization technique. The expressivity of neural networks allows representing rapidly varying free-energy surfaces, removes boundary effects artifacts, and allows several collective variables to be handled.	deep learning; enhanced sampling; molecular dynamics	20190815	https://pubmed.ncbi.nlm.nih.gov/31416918
Xu, Jinbo	Distance-based protein folding powered by deep learning.	Proc Natl Acad Sci U S A	2019	Proc Natl Acad Sci U S A. 2019 Aug 20;116(34):16856-16865. doi: 10.1073/pnas.1821309116. Epub 2019 Aug 9.	Direct coupling analysis (DCA) for protein folding has made very good progress, but it is not effective for proteins that lack many sequence homologs, even coupled with time-consuming conformation sampling with fragments. We show that we can accurately predict interresidue distance distribution of a protein by deep learning, even for proteins with approximately 60 sequence homologs. Using only the geometric constraints given by the resulting distance matrix we may construct 3D models without involving extensive conformation sampling. Our method successfully folded 21 of the 37 CASP12 hard targets with a median family size of 58 effective sequence homologs within 4 h on a Linux computer of 20 central processing units. In contrast, DCA-predicted contacts cannot be used to fold any of these hard targets in the absence of extensive conformation sampling, and the best CASP12 group folded only 11 of them by integrating DCA-predicted contacts into fragment-based conformation sampling. Rigorous experimental validation in CASP13 shows that our distance-based folding server successfully folded 17 of 32 hard targets (with a median family size of 36 sequence homologs) and obtained 70% precision on the top L/5 long-range predicted contacts. The latest experimental validation in CAMEO shows that our server predicted correct folds for 2 membrane proteins while all of the other servers failed. These results demonstrate that it is now feasible to predict correct fold for many more proteins lack of similar structures in the Protein Data Bank even on a personal computer.	deep learning; direct coupling analysis; protein contact prediction; protein distance prediction; protein folding	20190809	https://pubmed.ncbi.nlm.nih.gov/31399549
Artoni, Pietro; Piffer, Arianna; Vinci, Viviana; LeBlanc, Jocelyn; Nelson, Charles A; Hensch, Takao K; Fagiolini, Michela	Deep learning of spontaneous arousal fluctuations detects early cholinergic defects across neurodevelopmental mouse models and patients.	Proc Natl Acad Sci U S A	2020	Proc Natl Acad Sci U S A. 2020 Sep 22;117(38):23298-23303. doi: 10.1073/pnas.1820847116. Epub 2019 Jul 22.	Neurodevelopmental spectrum disorders like autism (ASD) are diagnosed, on average, beyond age 4 y, after multiple critical periods of brain development close and behavioral intervention becomes less effective. This raises the urgent need for quantitative, noninvasive, and translational biomarkers for their early detection and tracking. We found that both idiopathic (BTBR) and genetic (CDKL5- and MeCP2-deficient) mouse models of ASD display an early, impaired cholinergic neuromodulation as reflected in altered spontaneous pupil fluctuations. Abnormalities were already present before the onset of symptoms and were rescued by the selective expression of MeCP2 in cholinergic circuits. Hence, we trained a neural network (ConvNetACh) to recognize, with 97% accuracy, patterns of these arousal fluctuations in mice with enhanced cholinergic sensitivity (LYNX1-deficient). ConvNetACh then successfully detected impairments in all ASD mouse models tested except in MeCP2-rescued mice. By retraining only the last layers of ConvNetACh with heart rate variation data (a similar proxy of arousal) directly from Rett syndrome patients, we generated ConvNetPatients, a neural network capable of distinguishing them from typically developing subjects. Even with small cohorts of rare patients, our approach exhibited significant accuracy before (80% in the first and second year of life) and into regression (88% in stage III patients). Thus, transfer learning across species and modalities establishes spontaneous arousal fluctuations combined with deep learning as a robust noninvasive, quantitative, and sensitive translational biomarker for the rapid and early detection of neurodevelopmental disorders before major symptom onset.	CDKL5 disorder; LYNX1; MECP2; Rett syndrome; transfer learning	20190722	https://pubmed.ncbi.nlm.nih.gov/31332003
Suzuki, Yuta; Kobayashi, Koya; Wakisaka, Yoshifumi; Deng, Dinghuan; Tanaka, Shunji; Huang, Chun-Jung; Lei, Cheng; Sun, Chia-Wei; Liu, Hanqin; Fujiwaki, Yasuhiro; Lee, Sangwook; Isozaki, Akihiro; Kasai, Yusuke; Hayakawa, Takeshi; Sakuma, Shinya; Arai, Fumihito; Koizumi, Kenichi; Tezuka, Hiroshi; Inaba, Mary; Hiraki, Kei; Ito, Takuro; Hase, Misa; Matsusaka, Satoshi; Shiba, Kiyotaka; Suga, Kanako; Nishikawa, Masako; Jona, Masahiro; Yatomi, Yutaka; Yalikun, Yaxiaer; Tanaka, Yo; Sugimura, Takeaki; Nitta, Nao; Goda, Keisuke; Ozeki, Yasuyuki	Label-free chemical imaging flow cytometry by high-speed multicolor stimulated Raman scattering.	Proc Natl Acad Sci U S A	2019	Proc Natl Acad Sci U S A. 2019 Aug 6;116(32):15842-15848. doi: 10.1073/pnas.1902322116. Epub 2019 Jul 19.	Combining the strength of flow cytometry with fluorescence imaging and digital image analysis, imaging flow cytometry is a powerful tool in diverse fields including cancer biology, immunology, drug discovery, microbiology, and metabolic engineering. It enables measurements and statistical analyses of chemical, structural, and morphological phenotypes of numerous living cells to provide systematic insights into biological processes. However, its utility is constrained by its requirement of fluorescent labeling for phenotyping. Here we present label-free chemical imaging flow cytometry to overcome the issue. It builds on a pulse pair-resolved wavelength-switchable Stokes laser for the fastest-to-date multicolor stimulated Raman scattering (SRS) microscopy of fast-flowing cells on a 3D acoustic focusing microfluidic chip, enabling an unprecedented throughput of up to approximately 140 cells/s. To show its broad utility, we use the SRS imaging flow cytometry with the aid of deep learning to study the metabolic heterogeneity of microalgal cells and perform marker-free cancer detection in blood.	cancer cells; imaging flow cytometry; metabolite imaging; microalgae; stimulated Raman scattering	20190719	https://pubmed.ncbi.nlm.nih.gov/31324741
Kingston, Benjamin R; Syed, Abdullah Muhammad; Ngai, Jessica; Sindhwani, Shrey; Chan, Warren C W	Assessing micrometastases as a target for nanoparticles using 3D microscopy and machine learning.	Proc Natl Acad Sci U S A	2019	Proc Natl Acad Sci U S A. 2019 Jul 23;116(30):14937-14946. doi: 10.1073/pnas.1907646116. Epub 2019 Jul 8.	Metastasis of solid tumors is a key determinant of cancer patient survival. Targeting micrometastases using nanoparticles could offer a way to stop metastatic tumor growth before it causes excessive patient morbidity. However, nanoparticle delivery to micrometastases is difficult to investigate because micrometastases are small in size and lie deep within tissues. Here, we developed an imaging and image analysis workflow to analyze nanoparticle-cell interactions in metastatic tumors. This technique combines tissue clearing and 3D microscopy with machine learning-based image analysis to assess the physiology of micrometastases with single-cell resolution and quantify the delivery of nanoparticles within them. We show that nanoparticles access a higher proportion of cells in micrometastases (50% nanoparticle-positive cells) compared with primary tumors (17% nanoparticle-positive cells) because they reside close to blood vessels and require a small diffusion distance to reach all tumor cells. Furthermore, the high-throughput nature of our image analysis workflow allowed us to profile the physiology and nanoparticle delivery of 1,301 micrometastases. This enabled us to use machine learning-based modeling to predict nanoparticle delivery to individual micrometastases based on their physiology. Our imaging method allows researchers to measure nanoparticle delivery to micrometastases and highlights an opportunity to target micrometastases with nanoparticles. The development of models to predict nanoparticle delivery based on micrometastasis physiology could enable personalized treatments based on the specific physiology of a patient's micrometastases.	3D microscopy; image analysis; machine learning; metastasis; nanoparticles	20190708	https://pubmed.ncbi.nlm.nih.gov/31285340
He, Siyu; Li, Yin; Feng, Yu; Ho, Shirley; Ravanbakhsh, Siamak; Chen, Wei; Poczos, Barnabas	Learning to predict the cosmological structure formation.	Proc Natl Acad Sci U S A	2019	Proc Natl Acad Sci U S A. 2019 Jul 9;116(28):13825-13832. doi: 10.1073/pnas.1821458116. Epub 2019 Jun 24.	Matter evolved under the influence of gravity from minuscule density fluctuations. Nonperturbative structure formed hierarchically over all scales and developed non-Gaussian features in the Universe, known as the cosmic web. To fully understand the structure formation of the Universe is one of the holy grails of modern astrophysics. Astrophysicists survey large volumes of the Universe and use a large ensemble of computer simulations to compare with the observed data to extract the full information of our own Universe. However, to evolve billions of particles over billions of years, even with the simplest physics, is a daunting task. We build a deep neural network, the Deep Density Displacement Model ([Formula: see text]), which learns from a set of prerun numerical simulations, to predict the nonlinear large-scale structure of the Universe with the Zel'dovich Approximation (ZA), an analytical approximation based on perturbation theory, as the input. Our extensive analysis demonstrates that [Formula: see text] outperforms the second-order perturbation theory (2LPT), the commonly used fast-approximate simulation method, in predicting cosmic structure in the nonlinear regime. We also show that [Formula: see text] is able to accurately extrapolate far beyond its training data and predict structure formation for significantly different cosmological parameters. Our study proves that deep learning is a practical and accurate alternative to approximate 3D simulations of the gravitational structure formation of the Universe.	cosmology; deep learning; simulation	20190624	https://pubmed.ncbi.nlm.nih.gov/31235606
Ryu, Jae Yong; Kim, Hyun Uk; Lee, Sang Yup	Deep learning enables high-quality and high-throughput prediction of enzyme commission numbers.	Proc Natl Acad Sci U S A	2019	Proc Natl Acad Sci U S A. 2019 Jul 9;116(28):13996-14001. doi: 10.1073/pnas.1821905116. Epub 2019 Jun 20.	High-quality and high-throughput prediction of enzyme commission (EC) numbers is essential for accurate understanding of enzyme functions, which have many implications in pathologies and industrial biotechnology. Several EC number prediction tools are currently available, but their prediction performance needs to be further improved to precisely and efficiently process an ever-increasing volume of protein sequence data. Here, we report DeepEC, a deep learning-based computational framework that predicts EC numbers for protein sequences with high precision and in a high-throughput manner. DeepEC takes a protein sequence as input and predicts EC numbers as output. DeepEC uses 3 convolutional neural networks (CNNs) as a major engine for the prediction of EC numbers, and also implements homology analysis for EC numbers that cannot be classified by the CNNs. Comparative analyses against 5 representative EC number prediction tools show that DeepEC allows the most precise prediction of EC numbers, and is the fastest and the lightest in terms of the disk space required. Furthermore, DeepEC is the most sensitive in detecting the effects of mutated domains/binding site residues of protein sequences. DeepEC can be used as an independent tool, and also as a third-party software component in combination with other computational platforms that examine metabolic reactions.	DeepEC; EC number prediction; deep learning; enzyme commission number; metabolism	20190620	https://pubmed.ncbi.nlm.nih.gov/31221760
Romero, Raquel; Yuen, Tony; New, Maria I; Zaidi, Mone; Haider, Shozeb	Reply to Graham et al.: In silico atomistic coordinates and molecular dynamics simulation trajectories of the glucocerebrosidase-saposin C complex.	Proc Natl Acad Sci U S A	2019	Proc Natl Acad Sci U S A. 2019 Jun 4;116(23):11101-11102. doi: 10.1073/pnas.1905744116.	?		?	https://pubmed.ncbi.nlm.nih.gov/31164477
Graham, Stephen C; Nagar, Bhushan; Prive, Gilbert G; Deane, Janet E	Molecular models should not be published without the corresponding atomic coordinates.	Proc Natl Acad Sci U S A	2019	Proc Natl Acad Sci U S A. 2019 Jun 4;116(23):11099-11100. doi: 10.1073/pnas.1904409116.	?		?	https://pubmed.ncbi.nlm.nih.gov/31164476
Gleitman, Lila; Senghas, Ann; Flaherty, Molly; Coppola, Marie; Goldin-Meadow, Susan	The emergence of the formal category "symmetry" in a new sign language.	Proc Natl Acad Sci U S A	2019	Proc Natl Acad Sci U S A. 2019 Jun 11;116(24):11705-11711. doi: 10.1073/pnas.1819872116. Epub 2019 May 28.	Logical properties such as negation, implication, and symmetry, despite the fact that they are foundational and threaded through the vocabulary and syntax of known natural languages, pose a special problem for language learning. Their meanings are much harder to identify and isolate in the child's everyday interaction with referents in the world than concrete things (like spoons and horses) and happenings and acts (like running and jumping) that are much more easily identified, and thus more easily linked to their linguistic labels (spoon, horse, run, jump). Here we concentrate attention on the category of symmetry [a relation R is symmetrical if and only if (iff) for all x, y: if R(x,y), then R(y,x)], expressed in English by such terms as similar, marry, cousin, and near After a brief introduction to how symmetry is expressed in English and other well-studied languages, we discuss the appearance and maturation of this category in Nicaraguan Sign Language (NSL). NSL is an emerging language used as the primary, daily means of communication among a population of deaf individuals who could not acquire the surrounding spoken language because they could not hear it, and who were not exposed to a preexisting sign language because there was none available in their community. Remarkably, these individuals treat symmetry, in both semantic and syntactic regards, much as do learners exposed to a previously established language. These findings point to deep human biases in the structures underpinning and constituting human language.	homesign; language emergence; logical structure of language; sign language; symmetry	20190528	https://pubmed.ncbi.nlm.nih.gov/31138681
McCloskey, Kevin; Taly, Ankur; Monti, Federico; Brenner, Michael P; Colwell, Lucy J	Using attribution to decode binding mechanism in neural network models for chemistry.	Proc Natl Acad Sci U S A	2019	Proc Natl Acad Sci U S A. 2019 Jun 11;116(24):11624-11629. doi: 10.1073/pnas.1820657116. Epub 2019 May 24.	Deep neural networks have achieved state-of-the-art accuracy at classifying molecules with respect to whether they bind to specific protein targets. A key breakthrough would occur if these models could reveal the fragment pharmacophores that are causally involved in binding. Extracting chemical details of binding from the networks could enable scientific discoveries about the mechanisms of drug actions. However, doing so requires shining light into the black box that is the trained neural network model, a task that has proved difficult across many domains. Here we show how the binding mechanism learned by deep neural network models can be interrogated, using a recently described attribution method. We first work with carefully constructed synthetic datasets, in which the molecular features responsible for "binding" are fully known. We find that networks that achieve perfect accuracy on held-out test datasets still learn spurious correlations, and we are able to exploit this nonrobustness to construct adversarial examples that fool the model. This makes these models unreliable for accurately revealing information about the mechanisms of protein-ligand binding. In light of our findings, we prescribe a test that checks whether a hypothesized mechanism can be learned. If the test fails, it indicates that the model must be simplified or regularized and/or that the training dataset requires augmentation.	attribution for molecules; deep learning; overfitting; virtual screening	20190524	https://pubmed.ncbi.nlm.nih.gov/31127041
Saxe, Andrew M; McClelland, James L; Ganguli, Surya	A mathematical theory of semantic development in deep neural networks.	Proc Natl Acad Sci U S A	2019	Proc Natl Acad Sci U S A. 2019 Jun 4;116(23):11537-11546. doi: 10.1073/pnas.1820226116. Epub 2019 May 17.	An extensive body of empirical research has revealed remarkable regularities in the acquisition, organization, deployment, and neural representation of human semantic knowledge, thereby raising a fundamental conceptual question: What are the theoretical principles governing the ability of neural networks to acquire, organize, and deploy abstract knowledge by integrating across many individual experiences? We address this question by mathematically analyzing the nonlinear dynamics of learning in deep linear networks. We find exact solutions to this learning dynamics that yield a conceptual explanation for the prevalence of many disparate phenomena in semantic cognition, including the hierarchical differentiation of concepts through rapid developmental transitions, the ubiquity of semantic illusions between such transitions, the emergence of item typicality and category coherence as factors controlling the speed of semantic processing, changing patterns of inductive projection over development, and the conservation of semantic similarity in neural representations across species. Thus, surprisingly, our simple neural model qualitatively recapitulates many diverse regularities underlying semantic development, while providing analytic insight into how the statistical structure of an environment can interact with nonlinear deep-learning dynamics to give rise to these regularities.	deep learning; generative models; neural networks; semantic cognition	20190517	https://pubmed.ncbi.nlm.nih.gov/31101713
Fonda, Enrico; Pandey, Ambrish; Schumacher, Jorg; Sreenivasan, Katepalli R	Deep learning in turbulent convection networks.	Proc Natl Acad Sci U S A	2019	Proc Natl Acad Sci U S A. 2019 Apr 30;116(18):8667-8672. doi: 10.1073/pnas.1900358116. Epub 2019 Apr 15.	We explore heat transport properties of turbulent Rayleigh-Benard convection in horizontally extended systems by using deep-learning algorithms that greatly reduce the number of degrees of freedom. Particular attention is paid to the slowly evolving turbulent superstructures-so called because they are larger in extent than the height of the convection layer-which appear as temporal patterns of ridges of hot upwelling and cold downwelling fluid, including defects where the ridges merge or end. The machine-learning algorithm trains a deep convolutional neural network (CNN) with U-shaped architecture, consisting of a contraction and a subsequent expansion branch, to reduce the complex 3D turbulent superstructure to a temporal planar network in the midplane of the layer. This results in a data compression by more than five orders of magnitude at the highest Rayleigh number, and its application yields a discrete transport network with dynamically varying defect points, including points of locally enhanced heat flux or "hot spots." One conclusion is that the fraction of heat transport by the superstructure decreases as the Rayleigh number increases (although they might remain individually strong), correspondingly implying the increased importance of small-scale background turbulence.	machine learning; temporal networks; turbulent convection	20190415	https://pubmed.ncbi.nlm.nih.gov/30988195
Soltanian-Zadeh, Somayyeh; Sahingur, Kaan; Blau, Sarah; Gong, Yiyang; Farsiu, Sina	Fast and robust active neuron segmentation in two-photon calcium imaging using spatiotemporal deep learning.	Proc Natl Acad Sci U S A	2019	Proc Natl Acad Sci U S A. 2019 Apr 23;116(17):8554-8563. doi: 10.1073/pnas.1812995116. Epub 2019 Apr 11.	Calcium imaging records large-scale neuronal activity with cellular resolution in vivo. Automated, fast, and reliable active neuron segmentation is a critical step in the analysis workflow of utilizing neuronal signals in real-time behavioral studies for discovery of neuronal coding properties. Here, to exploit the full spatiotemporal information in two-photon calcium imaging movies, we propose a 3D convolutional neural network to identify and segment active neurons. By utilizing a variety of two-photon microscopy datasets, we show that our method outperforms state-of-the-art techniques and is on a par with manual segmentation. Furthermore, we demonstrate that the network trained on data recorded at a specific cortical layer can be used to accurately segment active neurons from another layer with different neuron density. Finally, our work documents significant tabulation flaws in one of the most cited and active online scientific challenges in neuron segmentation. As our computationally fast method is an invaluable tool for a large spectrum of real-time optogenetic experiments, we have made our open-source software and carefully annotated dataset freely available online.	calcium imaging; deep learning; neuron segmentation; open source; two-photon microscopy	20190411	https://pubmed.ncbi.nlm.nih.gov/30975747
Krotov, Dmitry; Hopfield, John J	Unsupervised learning by competing hidden units.	Proc Natl Acad Sci U S A	2019	Proc Natl Acad Sci U S A. 2019 Apr 16;116(16):7723-7731. doi: 10.1073/pnas.1820458116. Epub 2019 Mar 29.	It is widely believed that end-to-end training with the backpropagation algorithm is essential for learning good feature detectors in early layers of artificial neural networks, so that these detectors are useful for the task performed by the higher layers of that neural network. At the same time, the traditional form of backpropagation is biologically implausible. In the present paper we propose an unusual learning rule, which has a degree of biological plausibility and which is motivated by Hebb's idea that change of the synapse strength should be local-i.e., should depend only on the activities of the pre- and postsynaptic neurons. We design a learning algorithm that utilizes global inhibition in the hidden layer and is capable of learning early feature detectors in a completely unsupervised way. These learned lower-layer feature detectors can be used to train higher-layer weights in a usual supervised way so that the performance of the full network is comparable to the performance of standard feedforward networks trained end-to-end with a backpropagation algorithm on simple tasks.	Hebbian-like plasticity; backpropagation; biological deep learning	20190329	https://pubmed.ncbi.nlm.nih.gov/30926658
Washburn, Jacob D; Mejia-Guerra, Maria Katherine; Ramstein, Guillaume; Kremling, Karl A; Valluru, Ravi; Buckler, Edward S; Wang, Hai	Evolutionarily informed deep learning methods for predicting relative transcript abundance from DNA sequence.	Proc Natl Acad Sci U S A	2019	Proc Natl Acad Sci U S A. 2019 Mar 19;116(12):5542-5549. doi: 10.1073/pnas.1814551116. Epub 2019 Mar 6.	Deep learning methodologies have revolutionized prediction in many fields and show potential to do the same in molecular biology and genetics. However, applying these methods in their current forms ignores evolutionary dependencies within biological systems and can result in false positives and spurious conclusions. We developed two approaches that account for evolutionary relatedness in machine learning models: (i) gene-family-guided splitting and (ii) ortholog contrasts. The first approach accounts for evolution by constraining model training and testing sets to include different gene families. The second approach uses evolutionarily informed comparisons between orthologous genes to both control for and leverage evolutionary divergence during the training process. The two approaches were explored and validated within the context of mRNA expression level prediction and have the area under the ROC curve (auROC) values ranging from 0.75 to 0.94. Model weight inspections showed biologically interpretable patterns, resulting in the hypothesis that the 3' UTR is more important for fine-tuning mRNA abundance levels while the 5' UTR is more important for large-scale changes.	RNA; convolutional neural networks; machine learning; regulation	20190306	https://pubmed.ncbi.nlm.nih.gov/30842277
Romero, Raquel; Ramanathan, Arvind; Yuen, Tony; Bhowmik, Debsindhu; Mathew, Mehr; Munshi, Lubna Bashir; Javaid, Seher; Bloch, Madison; Lizneva, Daria; Rahimova, Alina; Khan, Ayesha; Taneja, Charit; Kim, Se-Min; Sun, Li; New, Maria I; Haider, Shozeb; Zaidi, Mone	Mechanism of glucocerebrosidase activation and dysfunction in Gaucher disease unraveled by molecular dynamics and deep learning.	Proc Natl Acad Sci U S A	2019	Proc Natl Acad Sci U S A. 2019 Mar 12;116(11):5086-5095. doi: 10.1073/pnas.1818411116. Epub 2019 Feb 26.	The lysosomal enzyme glucocerebrosidase-1 (GCase) catalyzes the cleavage of a major glycolipid glucosylceramide into glucose and ceramide. The absence of fully functional GCase leads to the accumulation of its lipid substrates in lysosomes, causing Gaucher disease, an autosomal recessive disorder that displays profound genotype-phenotype nonconcordance. More than 250 disease-causing mutations in GBA1, the gene encoding GCase, have been discovered, although only one of these, N370S, causes 70% of disease. Here, we have used a knowledge-based docking protocol that considers experimental data of protein-protein binding to generate a complex between GCase and its known facilitator protein saposin C (SAPC). Multiscale molecular-dynamics simulations were used to study lipid self-assembly, membrane insertion, and the dynamics of the interactions between different components of the complex. Deep learning was applied to propose a model that explains the mechanism of GCase activation, which requires SAPC. Notably, we find that conformational changes in the loops at the entrance of the substrate-binding site are stabilized by direct interactions with SAPC and that the loss of such interactions induced by N370S and another common mutation, L444P, result in destabilization of the complex and reduced GCase activation. Our findings provide an atomistic-level explanation for GCase activation and the precise mechanism through which N370S and L444P cause Gaucher disease.	gene mutations; lysosomal storage disease; multiscale simulations; rare disease	20190226	https://pubmed.ncbi.nlm.nih.gov/30808805
Shi, Zhe; Tsymbalov, Evgenii; Dao, Ming; Suresh, Subra; Shapeev, Alexander; Li, Ju	Deep elastic strain engineering of bandgap through machine learning.	Proc Natl Acad Sci U S A	2019	Proc Natl Acad Sci U S A. 2019 Mar 5;116(10):4117-4122. doi: 10.1073/pnas.1818555116. Epub 2019 Feb 15.	Nanoscale specimens of semiconductor materials as diverse as silicon and diamond are now known to be deformable to large elastic strains without inelastic relaxation. These discoveries harbinger a new age of deep elastic strain engineering of the band structure and device performance of electronic materials. Many possibilities remain to be investigated as to what pure silicon can do as the most versatile electronic material and what an ultrawide bandgap material such as diamond, with many appealing functional figures of merit, can offer after overcoming its present commercial immaturity. Deep elastic strain engineering explores full six-dimensional space of admissible nonlinear elastic strain and its effects on physical properties. Here we present a general method that combines machine learning and ab initio calculations to guide strain engineering whereby material properties and performance could be designed. This method invokes recent advances in the field of artificial intelligence by utilizing a limited amount of ab initio data for the training of a surrogate model, predicting electronic bandgap within an accuracy of 8 meV. Our model is capable of discovering the indirect-to-direct bandgap transition and semiconductor-to-metal transition in silicon by scanning the entire strain space. It is also able to identify the most energy-efficient strain pathways that would transform diamond from an ultrawide-bandgap material to a smaller-bandgap semiconductor. A broad framework is presented to tailor any target figure of merit by recourse to deep elastic strain engineering and machine learning for a variety of applications in microelectronics, optoelectronics, photonics, and energy technologies.	bandgap engineering; electronic band structure; first-principles calculation; neural network; semiconductor materials	20190215	https://pubmed.ncbi.nlm.nih.gov/30770444
Lu, Hongjing; Wu, Ying Nian; Holyoak, Keith J	Emergence of analogy from relation learning.	Proc Natl Acad Sci U S A	2019	Proc Natl Acad Sci U S A. 2019 Mar 5;116(10):4176-4181. doi: 10.1073/pnas.1814779116. Epub 2019 Feb 15.	By middle childhood, humans are able to learn abstract semantic relations (e.g., antonym, synonym, category membership) and use them to reason by analogy. A deep theoretical challenge is to show how such abstract relations can arise from nonrelational inputs, thereby providing key elements of a protosymbolic representation system. We have developed a computational model that exploits the potential synergy between deep learning from "big data" (to create semantic features for individual words) and supervised learning from "small data" (to create representations of semantic relations between words). Given as inputs labeled pairs of lexical representations extracted by deep learning, the model creates augmented representations by remapping features according to the rank of differences between values for the two words in each pair. These augmented representations aid in coping with the feature alignment problem (e.g., matching those features that make "love-hate" an antonym with the different features that make "rich-poor" an antonym). The model extracts weight distributions that are used to estimate the probabilities that new word pairs instantiate each relation, capturing the pattern of human typicality judgments for a broad range of abstract semantic relations. A measure of relational similarity can be derived and used to solve simple verbal analogies with human-level accuracy. Because each acquired relation has a modular representation, basic symbolic operations are enabled (notably, the converse of any learned relation can be formed without additional training). Abstract semantic relations can be induced by bootstrapping from nonrelational inputs, thereby enabling relational generalization and analogical reasoning.	analogy; generalization; learning; semantic relations; word embeddings	20190215	https://pubmed.ncbi.nlm.nih.gov/30770443
Kittur, Aniket; Yu, Lixiu; Hope, Tom; Chan, Joel; Lifshitz-Assaf, Hila; Gilon, Karni; Ng, Felicia; Kraut, Robert E; Shahaf, Dafna	Scaling up analogical innovation with crowds and AI.	Proc Natl Acad Sci U S A	2019	Proc Natl Acad Sci U S A. 2019 Feb 5;116(6):1870-1877. doi: 10.1073/pnas.1807185116.	Analogy-the ability to find and apply deep structural patterns across domains-has been fundamental to human innovation in science and technology. Today there is a growing opportunity to accelerate innovation by moving analogy out of a single person's mind and distributing it across many information processors, both human and machine. Doing so has the potential to overcome cognitive fixation, scale to large idea repositories, and support complex problems with multiple constraints. Here we lay out a perspective on the future of scalable analogical innovation and first steps using crowds and artificial intelligence (AI) to augment creativity that quantitatively demonstrate the promise of the approach, as well as core challenges critical to realizing this vision.	AI; analogy; crowdsourcing; innovation; machine learning	?	https://pubmed.ncbi.nlm.nih.gov/30718420
Waldrop, M Mitchell	News Feature: What are the limits of deep learning?	Proc Natl Acad Sci U S A	2019	Proc Natl Acad Sci U S A. 2019 Jan 22;116(4):1074-1077. doi: 10.1073/pnas.1821594116.	?		?	https://pubmed.ncbi.nlm.nih.gov/30670601
Pethe, Manasi A; Rubenstein, Aliza B; Khare, Sagar D	Data-driven supervised learning of a viral protease specificity landscape from deep sequencing and molecular simulations.	Proc Natl Acad Sci U S A	2019	Proc Natl Acad Sci U S A. 2019 Jan 2;116(1):168-176. doi: 10.1073/pnas.1805256116. Epub 2018 Dec 26.	Biophysical interactions between proteins and peptides are key determinants of molecular recognition specificity landscapes. However, an understanding of how molecular structure and residue-level energetics at protein-peptide interfaces shape these landscapes remains elusive. We combine information from yeast-based library screening, next-generation sequencing, and structure-based modeling in a supervised machine learning approach to report the comprehensive sequence-energetics-function mapping of the specificity landscape of the hepatitis C virus (HCV) NS3/4A protease, whose function-site-specific cleavages of the viral polyprotein-is a key determinant of viral fitness. We screened a library of substrates in which five residue positions were randomized and measured cleavability of approximately 30,000 substrates ( approximately 1% of the library) using yeast display and fluorescence-activated cell sorting followed by deep sequencing. Structure-based models of a subset of experimentally derived sequences were used in a supervised learning procedure to train a support vector machine to predict the cleavability of 3.2 million substrate variants by the HCV protease. The resulting landscape allows identification of previously unidentified HCV protease substrates, and graph-theoretic analyses reveal extensive clustering of cleavable and uncleavable motifs in sequence space. Specificity landscapes of known drug-resistant variants are similarly clustered. The described approach should enable the elucidation and redesign of specificity landscapes of a wide variety of proteases, including human-origin enzymes. Our results also suggest a possible role for residue-level energetics in shaping plateau-like functional landscapes predicted from viral quasispecies theory.	machine learning; molecular modeling; protease; sequence-function mapping; substrate specificity	20181226	https://pubmed.ncbi.nlm.nih.gov/30587591
Lindsey, Robert; Daluiski, Aaron; Chopra, Sumit; Lachapelle, Alexander; Mozer, Michael; Sicular, Serge; Hanel, Douglas; Gardner, Michael; Gupta, Anurag; Hotchkiss, Robert; Potter, Hollis	Deep neural network improves fracture detection by clinicians.	Proc Natl Acad Sci U S A	2018	Proc Natl Acad Sci U S A. 2018 Nov 6;115(45):11591-11596. doi: 10.1073/pnas.1806905115. Epub 2018 Oct 22.	Suspected fractures are among the most common reasons for patients to visit emergency departments (EDs), and X-ray imaging is the primary diagnostic tool used by clinicians to assess patients for fractures. Missing a fracture in a radiograph often has severe consequences for patients, resulting in delayed treatment and poor recovery of function. Nevertheless, radiographs in emergency settings are often read out of necessity by emergency medicine clinicians who lack subspecialized expertise in orthopedics, and misdiagnosed fractures account for upward of four of every five reported diagnostic errors in certain EDs. In this work, we developed a deep neural network to detect and localize fractures in radiographs. We trained it to accurately emulate the expertise of 18 senior subspecialized orthopedic surgeons by having them annotate 135,409 radiographs. We then ran a controlled experiment with emergency medicine clinicians to evaluate their ability to detect fractures in wrist radiographs with and without the assistance of the deep learning model. The average clinician's sensitivity was 80.8% (95% CI, 76.7-84.1%) unaided and 91.5% (95% CI, 89.3-92.9%) aided, and specificity was 87.5% (95 CI, 85.3-89.5%) unaided and 93.9% (95% CI, 92.9-94.9%) aided. The average clinician experienced a relative reduction in misinterpretation rate of 47.0% (95% CI, 37.4-53.9%). The significant improvements in diagnostic accuracy that we observed in this study show that deep learning methods are a mechanism by which senior medical specialists can deliver their expertise to generalists on the front lines of medicine, thereby providing substantial improvements to patient care.	CAD; X-ray; deep learning; fractures; radiology	20181022	https://pubmed.ncbi.nlm.nih.gov/30348771
Flesch, Timo; Balaguer, Jan; Dekker, Ronald; Nili, Hamed; Summerfield, Christopher	Comparing continual task learning in minds and machines.	Proc Natl Acad Sci U S A	2018	Proc Natl Acad Sci U S A. 2018 Oct 30;115(44):E10313-E10322. doi: 10.1073/pnas.1800755115. Epub 2018 Oct 15.	Humans can learn to perform multiple tasks in succession over the lifespan ("continual" learning), whereas current machine learning systems fail. Here, we investigated the cognitive mechanisms that permit successful continual learning in humans and harnessed our behavioral findings for neural network design. Humans categorized naturalistic images of trees according to one of two orthogonal task rules that were learned by trial and error. Training regimes that focused on individual rules for prolonged periods (blocked training) improved human performance on a later test involving randomly interleaved rules, compared with control regimes that trained in an interleaved fashion. Analysis of human error patterns suggested that blocked training encouraged humans to form "factorized" representation that optimally segregated the tasks, especially for those individuals with a strong prior bias to represent the stimulus space in a well-structured way. By contrast, standard supervised deep neural networks trained on the same tasks suffered catastrophic forgetting under blocked training, due to representational interference in the deeper layers. However, augmenting deep networks with an unsupervised generative model that allowed it to first learn a good embedding of the stimulus space (similar to that observed in humans) reduced catastrophic forgetting under blocked training. Building artificial agents that first learn a model of the world may be one promising route to solving continual task performance in artificial intelligence research.	catastrophic forgetting; categorization; continual learning; representational similarity analysis; task factorization	20181015	https://pubmed.ncbi.nlm.nih.gov/30322916
Rasp, Stephan; Pritchard, Michael S; Gentine, Pierre	Deep learning to represent subgrid processes in climate models.	Proc Natl Acad Sci U S A	2018	Proc Natl Acad Sci U S A. 2018 Sep 25;115(39):9684-9689. doi: 10.1073/pnas.1810286115. Epub 2018 Sep 6.	The representation of nonlinear subgrid processes, especially clouds, has been a major source of uncertainty in climate models for decades. Cloud-resolving models better represent many of these processes and can now be run globally but only for short-term simulations of at most a few years because of computational limitations. Here we demonstrate that deep learning can be used to capture many advantages of cloud-resolving modeling at a fraction of the computational cost. We train a deep neural network to represent all atmospheric subgrid processes in a climate model by learning from a multiscale model in which convection is treated explicitly. The trained neural network then replaces the traditional subgrid parameterizations in a global general circulation model in which it freely interacts with the resolved dynamics and the surface-flux scheme. The prognostic multiyear simulations are stable and closely reproduce not only the mean climate of the cloud-resolving simulation but also key aspects of variability, including precipitation extremes and the equatorial wave spectrum. Furthermore, the neural network approximately conserves energy despite not being explicitly instructed to. Finally, we show that the neural network parameterization generalizes to new surface forcing patterns but struggles to cope with temperatures far outside its training manifold. Our results show the feasibility of using deep learning for climate model parameterization. In a broader context, we anticipate that data-driven Earth system model development could play a key role in reducing climate prediction uncertainty in the coming decade.	climate modeling; convection; deep learning; subgrid parameterization	20180906	https://pubmed.ncbi.nlm.nih.gov/30190437
Wang, Desheng; Smith-Bell, Carrie A; Burhans, Lauren B; O'Dell, Deidre E; Bell, Roger W; Schreurs, Bernard G	Changes in membrane properties of rat deep cerebellar nuclear projection neurons during acquisition of eyeblink conditioning.	Proc Natl Acad Sci U S A	2018	Proc Natl Acad Sci U S A. 2018 Oct 2;115(40):E9419-E9428. doi: 10.1073/pnas.1808539115. Epub 2018 Aug 28.	Previous studies have shown changes in membrane properties of neurons in rat deep cerebellar nuclei (DCN) as a function of development, but due to technical difficulties in obtaining viable DCN slices from adult animals, it remains unclear whether there are learning-related alterations in the membrane properties of DCN neurons in adult rats. This study was designed to record from identified DCN cells in cerebellar slices from postnatal day 25-26 (P25-26) rats that had a relatively mature sensory nervous system and were able to acquire learning as a result of tone-shock eyeblink conditioning (EBC) and to document resulting changes in electrophysiological properties. After electromyographic electrode implantation at P21 and inoculation with a fluorescent pseudorabies virus (PRV-152) at P22-23, rats received either four sessions of paired delay EBC or unpaired stimulus presentations with a tone conditioned stimulus and a shock unconditioned stimulus or sat in the training chamber without stimulus presentations. Compared with rats given unpaired stimuli or no stimulus presentations, rats given paired EBC showed an increase in conditioned responses across sessions. Whole-cell recordings of both fluorescent and nonfluorescent DCN projection neurons showed that delay EBC induced significant changes in membrane properties of evoked DCN action potentials including a reduced after-hyperpolarization amplitude and shortened latency. Similar findings were obtained in hyperpolarization-induced rebound spikes of DCN neurons. In sum, delay EBC produced significant changes in the membrane properties of juvenile rat DCN projection neurons. These learning-specific changes in DCN excitability have not previously been reported in any species or task.	after-hyperpolarization; deep cerebellar nuclei; eyeblink conditioning; intrinsic membrane properties; whole-cell recording	20180828	https://pubmed.ncbi.nlm.nih.gov/30154170
Han, Jiequn; Jentzen, Arnulf; E, Weinan	Solving high-dimensional partial differential equations using deep learning.	Proc Natl Acad Sci U S A	2018	Proc Natl Acad Sci U S A. 2018 Aug 21;115(34):8505-8510. doi: 10.1073/pnas.1718942115. Epub 2018 Aug 6.	Developing algorithms for solving high-dimensional partial differential equations (PDEs) has been an exceedingly difficult task for a long time, due to the notoriously difficult problem known as the "curse of dimensionality." This paper introduces a deep learning-based approach that can handle general high-dimensional parabolic PDEs. To this end, the PDEs are reformulated using backward stochastic differential equations and the gradient of the unknown solution is approximated by neural networks, very much in the spirit of deep reinforcement learning with the gradient acting as the policy function. Numerical results on examples including the nonlinear Black-Scholes equation, the Hamilton-Jacobi-Bellman equation, and the Allen-Cahn equation suggest that the proposed algorithm is quite effective in high dimensions, in terms of both accuracy and cost. This opens up possibilities in economics, finance, operational research, and physics, by considering all participating agents, assets, resources, or particles together at the same time, instead of making ad hoc assumptions on their interrelationships.	Feynman-Kac; backward stochastic differential equations; deep learning; high dimension; partial differential equations	20180806	https://pubmed.ncbi.nlm.nih.gov/30082389
Zhou, Quan; Tang, Peizhe; Liu, Shenxiu; Pan, Jinbo; Yan, Qimin; Zhang, Shou-Cheng	Learning atoms for materials discovery.	Proc Natl Acad Sci U S A	2018	Proc Natl Acad Sci U S A. 2018 Jul 10;115(28):E6411-E6417. doi: 10.1073/pnas.1801181115. Epub 2018 Jun 26.	Exciting advances have been made in artificial intelligence (AI) during recent decades. Among them, applications of machine learning (ML) and deep learning techniques brought human-competitive performances in various tasks of fields, including image recognition, speech recognition, and natural language understanding. Even in Go, the ancient game of profound complexity, the AI player has already beat human world champions convincingly with and without learning from the human. In this work, we show that our unsupervised machines (Atom2Vec) can learn the basic properties of atoms by themselves from the extensive database of known compounds and materials. These learned properties are represented in terms of high-dimensional vectors, and clustering of atoms in vector space classifies them into meaningful groups consistent with human knowledge. We use the atom vectors as basic input units for neural networks and other ML models designed and trained to predict materials properties, which demonstrate significant accuracy.	atomism; machine learning; materials discovery	20180626	https://pubmed.ncbi.nlm.nih.gov/29946023
Piscopo, Denise M; Weible, Aldis P; Rothbart, Mary K; Posner, Michael I; Niell, Cristopher M	Changes in white matter in mice resulting from low-frequency brain stimulation.	Proc Natl Acad Sci U S A	2018	Proc Natl Acad Sci U S A. 2018 Jul 3;115(27):E6339-E6346. doi: 10.1073/pnas.1802160115. Epub 2018 Jun 18.	Recent reports have begun to elucidate mechanisms by which learning and experience produce white matter changes in the brain. We previously reported changes in white matter surrounding the anterior cingulate cortex in humans after 2-4 weeks of meditation training. We further found that low-frequency optogenetic stimulation of the anterior cingulate in mice increased time spent in the light in a light/dark box paradigm, suggesting decreased anxiety similar to what is observed following meditation training. Here, we investigated the impact of this stimulation at the cellular level. We found that laser stimulation in the range of 1-8 Hz results in changes to subcortical white matter projection fibers in the corpus callosum. Specifically, stimulation resulted in increased oligodendrocyte proliferation, accompanied by a decrease in the g-ratio within the corpus callosum underlying the anterior cingulate cortex. These results suggest that low-frequency stimulation can result in activity-dependent remodeling of myelin, giving rise to enhanced connectivity and altered behavior.	anterior cingulate cortex; electron microscopy; meditation; mouse; myelination	20180618	https://pubmed.ncbi.nlm.nih.gov/29915074
Norouzzadeh, Mohammad Sadegh; Nguyen, Anh; Kosmala, Margaret; Swanson, Alexandra; Palmer, Meredith S; Packer, Craig; Clune, Jeff	Automatically identifying, counting, and describing wild animals in camera-trap images with deep learning.	Proc Natl Acad Sci U S A	2018	Proc Natl Acad Sci U S A. 2018 Jun 19;115(25):E5716-E5725. doi: 10.1073/pnas.1719367115. Epub 2018 Jun 5.	Having accurate, detailed, and up-to-date information about the location and behavior of animals in the wild would improve our ability to study and conserve ecosystems. We investigate the ability to automatically, accurately, and inexpensively collect such data, which could help catalyze the transformation of many fields of ecology, wildlife biology, zoology, conservation biology, and animal behavior into "big data" sciences. Motion-sensor "camera traps" enable collecting wildlife pictures inexpensively, unobtrusively, and frequently. However, extracting information from these pictures remains an expensive, time-consuming, manual task. We demonstrate that such information can be automatically extracted by deep learning, a cutting-edge type of artificial intelligence. We train deep convolutional neural networks to identify, count, and describe the behaviors of 48 species in the 3.2 million-image Snapshot Serengeti dataset. Our deep neural networks automatically identify animals with >93.8% accuracy, and we expect that number to improve rapidly in years to come. More importantly, if our system classifies only images it is confident about, our system can automate animal identification for 99.3% of the data while still performing at the same 96.6% accuracy as that of crowdsourced teams of human volunteers, saving >8.4 y (i.e., >17,000 h at 40 h/wk) of human labeling effort on this 3.2 million-image dataset. Those efficiency gains highlight the importance of using deep neural networks to automate data extraction from camera-trap images, reducing a roadblock for this widely used technology. Our results suggest that deep learning could enable the inexpensive, unobtrusive, high-volume, and even real-time collection of a wealth of information about vast numbers of animals in the wild.	artificial intelligence; camera-trap images; deep learning; deep neural networks; wildlife ecology	20180605	https://pubmed.ncbi.nlm.nih.gov/29871948
Phillips, P Jonathon; Yates, Amy N; Hu, Ying; Hahn, Carina A; Noyes, Eilidh; Jackson, Kelsey; Cavazos, Jacqueline G; Jeckeln, Geraldine; Ranjan, Rajeev; Sankaranarayanan, Swami; Chen, Jun-Cheng; Castillo, Carlos D; Chellappa, Rama; White, David; O'Toole, Alice J	Face recognition accuracy of forensic examiners, superrecognizers, and face recognition algorithms.	Proc Natl Acad Sci U S A	2018	Proc Natl Acad Sci U S A. 2018 Jun 12;115(24):6171-6176. doi: 10.1073/pnas.1721355115. Epub 2018 May 29.	Achieving the upper limits of face identification accuracy in forensic applications can minimize errors that have profound social and personal consequences. Although forensic examiners identify faces in these applications, systematic tests of their accuracy are rare. How can we achieve the most accurate face identification: using people and/or machines working alone or in collaboration? In a comprehensive comparison of face identification by humans and computers, we found that forensic facial examiners, facial reviewers, and superrecognizers were more accurate than fingerprint examiners and students on a challenging face identification test. Individual performance on the test varied widely. On the same test, four deep convolutional neural networks (DCNNs), developed between 2015 and 2017, identified faces within the range of human accuracy. Accuracy of the algorithms increased steadily over time, with the most recent DCNN scoring above the median of the forensic facial examiners. Using crowd-sourcing methods, we fused the judgments of multiple forensic facial examiners by averaging their rating-based identity judgments. Accuracy was substantially better for fused judgments than for individuals working alone. Fusion also served to stabilize performance, boosting the scores of lower-performing individuals and decreasing variability. Single forensic facial examiners fused with the best algorithm were more accurate than the combination of two examiners. Therefore, collaboration among humans and between humans and machines offers tangible benefits to face identification accuracy in important applications. These results offer an evidence-based roadmap for achieving the most accurate face identification possible.	face identification; face recognition algorithm; forensic science; machine learning technology; wisdom-of-crowds	20180529	https://pubmed.ncbi.nlm.nih.gov/29844174
Verma, Siddhartha; Novati, Guido; Koumoutsakos, Petros	Efficient collective swimming by harnessing vortices through deep reinforcement learning.	Proc Natl Acad Sci U S A	2018	Proc Natl Acad Sci U S A. 2018 Jun 5;115(23):5849-5854. doi: 10.1073/pnas.1800923115. Epub 2018 May 21.	Fish in schooling formations navigate complex flow fields replete with mechanical energy in the vortex wakes of their companions. Their schooling behavior has been associated with evolutionary advantages including energy savings, yet the underlying physical mechanisms remain unknown. We show that fish can improve their sustained propulsive efficiency by placing themselves in appropriate locations in the wake of other swimmers and intercepting judiciously their shed vortices. This swimming strategy leads to collective energy savings and is revealed through a combination of high-fidelity flow simulations with a deep reinforcement learning (RL) algorithm. The RL algorithm relies on a policy defined by deep, recurrent neural nets, with long-short-term memory cells, that are essential for capturing the unsteadiness of the two-way interactions between the fish and the vortical flow field. Surprisingly, we find that swimming in-line with a leader is not associated with energetic benefits for the follower. Instead, "smart swimmer(s)" place themselves at off-center positions, with respect to the axis of the leader(s) and deform their body to synchronize with the momentum of the oncoming vortices, thus enhancing their swimming efficiency at no cost to the leader(s). The results confirm that fish may harvest energy deposited in vortices and support the conjecture that swimming in formation is energetically advantageous. Moreover, this study demonstrates that deep RL can produce navigation algorithms for complex unsteady and vortical flow fields, with promising implications for energy savings in autonomous robotic swarms.	autonomous navigation; deep reinforcement learning; energy harvesting; fish schooling; recurrent neural networks	20180521	https://pubmed.ncbi.nlm.nih.gov/29784820
Ghosal, Sambuddha; Blystone, David; Singh, Asheesh K; Ganapathysubramanian, Baskar; Singh, Arti; Sarkar, Soumik	An explainable deep machine vision framework for plant stress phenotyping.	Proc Natl Acad Sci U S A	2018	Proc Natl Acad Sci U S A. 2018 May 1;115(18):4613-4618. doi: 10.1073/pnas.1716999115. Epub 2018 Apr 16.	Current approaches for accurate identification, classification, and quantification of biotic and abiotic stresses in crop research and production are predominantly visual and require specialized training. However, such techniques are hindered by subjectivity resulting from inter- and intrarater cognitive variability. This translates to erroneous decisions and a significant waste of resources. Here, we demonstrate a machine learning framework's ability to identify and classify a diverse set of foliar stresses in soybean [Glycine max (L.) Merr.] with remarkable accuracy. We also present an explanation mechanism, using the top-K high-resolution feature maps that isolate the visual symptoms used to make predictions. This unsupervised identification of visual symptoms provides a quantitative measure of stress severity, allowing for identification (type of foliar stress), classification (low, medium, or high stress), and quantification (stress severity) in a single framework without detailed symptom annotation by experts. We reliably identified and classified several biotic (bacterial and fungal diseases) and abiotic (chemical injury and nutrient deficiency) stresses by learning from over 25,000 images. The learned model is robust to input image perturbations, demonstrating viability for high-throughput deployment. We also noticed that the learned model appears to be agnostic to species, seemingly demonstrating an ability of transfer learning. The availability of an explainable model that can consistently, rapidly, and accurately identify and quantify foliar stresses would have significant implications in scientific research, plant breeding, and crop production. The trained model could be deployed in mobile platforms (e.g., unmanned air vehicles and automated ground scouts) for rapid, large-scale scouting or as a mobile application for real-time detection of stress by farmers and researchers.	explainable deep learning; machine learning; plant stress phenotyping; precision agriculture; resolving rater variabilities	20180416	https://pubmed.ncbi.nlm.nih.gov/29666265
Ryu, Jae Yong; Kim, Hyun Uk; Lee, Sang Yup	Deep learning improves prediction of drug-drug and drug-food interactions.	Proc Natl Acad Sci U S A	2018	Proc Natl Acad Sci U S A. 2018 May 1;115(18):E4304-E4311. doi: 10.1073/pnas.1803294115. Epub 2018 Apr 16.	Drug interactions, including drug-drug interactions (DDIs) and drug-food constituent interactions (DFIs), can trigger unexpected pharmacological effects, including adverse drug events (ADEs), with causal mechanisms often unknown. Several computational methods have been developed to better understand drug interactions, especially for DDIs. However, these methods do not provide sufficient details beyond the chance of DDI occurrence, or require detailed drug information often unavailable for DDI prediction. Here, we report development of a computational framework DeepDDI that uses names of drug-drug or drug-food constituent pairs and their structural information as inputs to accurately generate 86 important DDI types as outputs of human-readable sentences. DeepDDI uses deep neural network with its optimized prediction performance and predicts 86 DDI types with a mean accuracy of 92.4% using the DrugBank gold standard DDI dataset covering 192,284 DDIs contributed by 191,878 drug pairs. DeepDDI is used to suggest potential causal mechanisms for the reported ADEs of 9,284 drug pairs, and also predict alternative drug candidates for 62,707 drug pairs having negative health effects. Furthermore, DeepDDI is applied to 3,288,157 drug-food constituent pairs (2,159 approved drugs and 1,523 well-characterized food constituents) to predict DFIs. The effects of 256 food constituents on pharmacological effects of interacting drugs and bioactivities of 149 food constituents are predicted. These results suggest that DeepDDI can provide important information on drug prescription and even dietary suggestions while taking certain drugs and also guidelines during drug development.	DeepDDI; deep learning; drug-drug interactions; drug-food interactions; structural similarity profile	20180416	https://pubmed.ncbi.nlm.nih.gov/29666228
Egeland, Charles P; Dominguez-Rodrigo, Manuel; Pickering, Travis Rayne; Menter, Colin G; Heaton, Jason L	Hominin skeletal part abundances and claims of deliberate disposal of corpses in the Middle Pleistocene.	Proc Natl Acad Sci U S A	2018	Proc Natl Acad Sci U S A. 2018 May 1;115(18):4601-4606. doi: 10.1073/pnas.1718678115. Epub 2018 Apr 2.	Humans are set apart from other organisms by the realization of their own mortality. Thus, determining the prehistoric emergence of this capacity is of significant interest to understanding the uniqueness of the human animal. Tracing that capacity chronologically is possible through archaeological investigations that focus on physical markers that reflect "mortality salience." Among these markers is the deliberate and culturally mediated disposal of corpses. Some Neandertal bone assemblages are among the earliest reasonable claims for the deliberate disposal of hominins, but even these are vigorously debated. More dramatic assertions center on the Middle Pleistocene sites of Sima de los Huesos (SH, Spain) and the Dinaledi Chamber (DC, South Africa), where the remains of multiple hominin individuals were found in deep caves, and under reported taphonomic circumstances that seem to discount the possibility that nonhominin actors and processes contributed to their formation. These claims, with significant implications for charting the evolution of the "human condition," deserve scrutiny. We test these assertions through machine-learning analyses of hominin skeletal part representation in the SH and DC assemblages. Our results indicate that nonanthropogenic agents and abiotic processes cannot yet be ruled out as significant contributors to the ultimate condition of both collections. This finding does not falsify hypotheses of deliberate disposal for the SH and DC corpses, but does indicate that the data also support partially or completely nonanthropogenic formational histories.	machine learning; mortality salience; mortuary behavior; skeletal part frequencies; taphonomy	20180402	https://pubmed.ncbi.nlm.nih.gov/29610322
Mobadersany, Pooya; Yousefi, Safoora; Amgad, Mohamed; Gutman, David A; Barnholtz-Sloan, Jill S; Velazquez Vega, Jose E; Brat, Daniel J; Cooper, Lee A D	Predicting cancer outcomes from histology and genomics using convolutional networks.	Proc Natl Acad Sci U S A	2018	Proc Natl Acad Sci U S A. 2018 Mar 27;115(13):E2970-E2979. doi: 10.1073/pnas.1717139115. Epub 2018 Mar 12.	Cancer histology reflects underlying molecular processes and disease progression and contains rich phenotypic information that is predictive of patient outcomes. In this study, we show a computational approach for learning patient outcomes from digital pathology images using deep learning to combine the power of adaptive machine learning algorithms with traditional survival models. We illustrate how these survival convolutional neural networks (SCNNs) can integrate information from both histology images and genomic biomarkers into a single unified framework to predict time-to-event outcomes and show prediction accuracy that surpasses the current clinical paradigm for predicting the overall survival of patients diagnosed with glioma. We use statistical sampling techniques to address challenges in learning survival from histology images, including tumor heterogeneity and the need for large training cohorts. We also provide insights into the prediction mechanisms of SCNNs, using heat map visualization to show that SCNNs recognize important structures, like microvascular proliferation, that are related to prognosis and that are used by pathologists in grading. These results highlight the emerging role of deep learning in precision medicine and suggest an expanding utility for computational analysis of histology in the future practice of pathology.	artificial intelligence; cancer; deep learning; digital pathology; machine learning	20180312	https://pubmed.ncbi.nlm.nih.gov/29531073
Haam, Juhee; Zhou, Jingheng; Cui, Guohong; Yakel, Jerrel L	Septal cholinergic neurons gate hippocampal output to entorhinal cortex via oriens lacunosum moleculare interneurons.	Proc Natl Acad Sci U S A	2018	Proc Natl Acad Sci U S A. 2018 Feb 20;115(8):E1886-E1895. doi: 10.1073/pnas.1712538115. Epub 2018 Feb 7.	Neuromodulation of neural networks, whereby a selected circuit is regulated by a particular modulator, plays a critical role in learning and memory. Among neuromodulators, acetylcholine (ACh) plays a critical role in hippocampus-dependent memory and has been shown to modulate neuronal circuits in the hippocampus. However, it has remained unknown how ACh modulates hippocampal output. Here, using in vitro and in vivo approaches, we show that ACh, by activating oriens lacunosum moleculare (OLM) interneurons and therefore augmenting the negative-feedback regulation to the CA1 pyramidal neurons, suppresses the circuit from the hippocampal area CA1 to the deep-layer entorhinal cortex (EC). We also demonstrate, using mouse behavior studies, that the ablation of OLM interneurons specifically impairs hippocampus-dependent but not hippocampus-independent learning. These data suggest that ACh plays an important role in regulating hippocampal output to the EC by activating OLM interneurons, which is critical for the formation of hippocampus-dependent memory.	acetylcholine; hippocampus; memory; oriens lacunosum moleculare interneurons; photometry	20180207	https://pubmed.ncbi.nlm.nih.gov/29437952
Bastos, Andre M; Loonis, Roman; Kornblith, Simon; Lundqvist, Mikael; Miller, Earl K	Laminar recordings in frontal cortex suggest distinct layers for maintenance and control of working memory.	Proc Natl Acad Sci U S A	2018	Proc Natl Acad Sci U S A. 2018 Jan 30;115(5):1117-1122. doi: 10.1073/pnas.1710323115. Epub 2018 Jan 16.	All of the cerebral cortex has some degree of laminar organization. These different layers are composed of neurons with distinct connectivity patterns, embryonic origins, and molecular profiles. There are little data on the laminar specificity of cognitive functions in the frontal cortex, however. We recorded neuronal spiking/local field potentials (LFPs) using laminar probes in the frontal cortex (PMd, 8A, 8B, SMA/ACC, DLPFC, and VLPFC) of monkeys performing working memory (WM) tasks. LFP power in the gamma band (50-250 Hz) was strongest in superficial layers, and LFP power in the alpha/beta band (4-22 Hz) was strongest in deep layers. Memory delay activity, including spiking and stimulus-specific gamma bursting, was predominately in superficial layers. LFPs from superficial and deep layers were synchronized in the alpha/beta bands. This was primarily unidirectional, with alpha/beta bands in deep layers driving superficial layer activity. The phase of deep layer alpha/beta modulated superficial gamma bursting associated with WM encoding. Thus, alpha/beta rhythms in deep layers may regulate the superficial layer gamma bands and hence maintenance of the contents of WM.	cortical layers; frontal cortex; oscillations; working memory	20180116	https://pubmed.ncbi.nlm.nih.gov/29339471
Pelt, Daniel M; Sethian, James A	A mixed-scale dense convolutional neural network for image analysis.	Proc Natl Acad Sci U S A	2018	Proc Natl Acad Sci U S A. 2018 Jan 9;115(2):254-259. doi: 10.1073/pnas.1715832114. Epub 2017 Dec 26.	Deep convolutional neural networks have been successfully applied to many image-processing problems in recent works. Popular network architectures often add additional operations and connections to the standard architecture to enable training deeper networks. To achieve accurate results in practice, a large number of trainable parameters are often required. Here, we introduce a network architecture based on using dilated convolutions to capture features at different image scales and densely connecting all feature maps with each other. The resulting architecture is able to achieve accurate results with relatively few parameters and consists of a single set of operations, making it easier to implement, train, and apply in practice, and automatically adapts to different problems. We compare results of the proposed network architecture with popular existing architectures for several segmentation problems, showing that the proposed architecture is able to achieve accurate results with fewer parameters, with a reduced risk of overfitting the training data.	convolution neural networks; image segmentation; machine learning	20171226	https://pubmed.ncbi.nlm.nih.gov/29279403
Gebru, Timnit; Krause, Jonathan; Wang, Yilun; Chen, Duyun; Deng, Jia; Aiden, Erez Lieberman; Fei-Fei, Li	Using deep learning and Google Street View to estimate the demographic makeup of neighborhoods across the United States.	Proc Natl Acad Sci U S A	2017	Proc Natl Acad Sci U S A. 2017 Dec 12;114(50):13108-13113. doi: 10.1073/pnas.1700035114. Epub 2017 Nov 28.	The United States spends more than $250 million each year on the American Community Survey (ACS), a labor-intensive door-to-door study that measures statistics relating to race, gender, education, occupation, unemployment, and other demographic factors. Although a comprehensive source of data, the lag between demographic changes and their appearance in the ACS can exceed several years. As digital imagery becomes ubiquitous and machine vision techniques improve, automated data analysis may become an increasingly practical supplement to the ACS. Here, we present a method that estimates socioeconomic characteristics of regions spanning 200 US cities by using 50 million images of street scenes gathered with Google Street View cars. Using deep learning-based computer vision techniques, we determined the make, model, and year of all motor vehicles encountered in particular neighborhoods. Data from this census of motor vehicles, which enumerated 22 million automobiles in total (8% of all automobiles in the United States), were used to accurately estimate income, race, education, and voting patterns at the zip code and precinct level. (The average US precinct contains approximately 1,000 people.) The resulting associations are surprisingly simple and powerful. For instance, if the number of sedans encountered during a drive through a city is higher than the number of pickup trucks, the city is likely to vote for a Democrat during the next presidential election (88% chance); otherwise, it is likely to vote Republican (82%). Our results suggest that automated systems for monitoring demographics may effectively complement labor-intensive approaches, with the potential to measure demographics with fine spatial resolution, in close to real time.	computer vision; deep learning; demography; social analysis	20171128	https://pubmed.ncbi.nlm.nih.gov/29183967
Fredericksen, Maridel A; Zhang, Yizhe; Hazen, Missy L; Loreto, Raquel G; Mangold, Colleen A; Chen, Danny Z; Hughes, David P	Three-dimensional visualization and a deep-learning model reveal complex fungal parasite networks in behaviorally manipulated ants.	Proc Natl Acad Sci U S A	2017	Proc Natl Acad Sci U S A. 2017 Nov 21;114(47):12590-12595. doi: 10.1073/pnas.1711673114. Epub 2017 Nov 7.	Some microbes possess the ability to adaptively manipulate host behavior. To better understand how such microbial parasites control animal behavior, we examine the cell-level interactions between the species-specific fungal parasite Ophiocordyceps unilateralis sensu lato and its carpenter ant host (Camponotus castaneus) at a crucial moment in the parasite's lifecycle: when the manipulated host fixes itself permanently to a substrate by its mandibles. The fungus is known to secrete tissue-specific metabolites and cause changes in host gene expression as well as atrophy in the mandible muscles of its ant host, but it is unknown how the fungus coordinates these effects to manipulate its host's behavior. In this study, we combine techniques in serial block-face scanning-electron microscopy and deep-learning-based image segmentation algorithms to visualize the distribution, abundance, and interactions of this fungus inside the body of its manipulated host. Fungal cells were found throughout the host body but not in the brain, implying that behavioral control of the animal body by this microbe occurs peripherally. Additionally, fungal cells invaded host muscle fibers and joined together to form networks that encircled the muscles. These networks may represent a collective foraging behavior of this parasite, which may in turn facilitate host manipulation.	ants; behavioral manipulation; deep learning; extended phenotype; fungal networks	20171107	https://pubmed.ncbi.nlm.nih.gov/29114054
Reinhart, Robert M G	Disruption and rescue of interareal theta phase coupling and adaptive behavior.	Proc Natl Acad Sci U S A	2017	Proc Natl Acad Sci U S A. 2017 Oct 24;114(43):11542-11547. doi: 10.1073/pnas.1710257114. Epub 2017 Oct 9.	Rescuing executive functions in people with neurological and neuropsychiatric disorders has been a major goal of psychology and neuroscience for decades. Innovative computer-training regimes for executive functions have made tremendous inroads, yet the positive effects of training have not always translated into improved cognitive functioning and often take many days to emerge. In the present study, we asked whether it was possible to immediately change components of executive function by directly manipulating neural activity using a stimulation technology called high-definition transcranial alternating current stimulation (HD-tACS). Twenty minutes of inphase stimulation over medial frontal cortex (MFC) and right lateral prefrontal cortex (lPFC) synchronized theta ( approximately 6 Hz) rhythms between these regions in a frequency and spatially specific manner and rapidly improved adaptive behavior with effects lasting longer than 40 min. In contrast, antiphase stimulation in the same individuals desynchronized MFC-lPFC theta phase coupling and impaired adaptive behavior. Surprisingly, the exogenously driven impairments in performance could be instantly rescued by reversing the phase angle of alternating current. The results suggest executive functions can be rapidly up- or down-regulated by modulating theta phase coupling of distant frontal cortical areas and can contribute to the development of tools for potentially normalizing executive dysfunction in patient populations.	adaptive control; high-definition transcranial alternating current stimulation; lateral prefrontal cortex; medial frontal cortex; phase synchronization	20171009	https://pubmed.ncbi.nlm.nih.gov/29073084
Flores, Francisco J; Hartnack, Katharine E; Fath, Amanda B; Kim, Seong-Eun; Wilson, Matthew A; Brown, Emery N; Purdon, Patrick L	Thalamocortical synchronization during induction and emergence from propofol-induced unconsciousness.	Proc Natl Acad Sci U S A	2017	Proc Natl Acad Sci U S A. 2017 Aug 8;114(32):E6660-E6668. doi: 10.1073/pnas.1700148114. Epub 2017 Jul 25.	General anesthesia (GA) is a reversible drug-induced state of altered arousal required for more than 60,000 surgical procedures each day in the United States alone. Sedation and unconsciousness under GA are associated with stereotyped electrophysiological oscillations that are thought to reflect profound disruptions of activity in neuronal circuits that mediate awareness and cognition. Computational models make specific predictions about the role of the cortex and thalamus in these oscillations. In this paper, we provide in vivo evidence in rats that alpha oscillations (10-15 Hz) induced by the commonly used anesthetic drug propofol are synchronized between the thalamus and the medial prefrontal cortex. We also show that at deep levels of unconsciousness where movement ceases, coherent thalamocortical delta oscillations (1-5 Hz) develop, distinct from concurrent slow oscillations (0.1-1 Hz). The structure of these oscillations in both cortex and thalamus closely parallel those observed in the human electroencephalogram during propofol-induced unconsciousness. During emergence from GA, this synchronized activity dissipates in a sequence different from that observed during loss of consciousness. A possible explanation is that recovery from anesthesia-induced unconsciousness follows a "boot-up" sequence actively driven by ascending arousal centers. The involvement of medial prefrontal cortex suggests that when these oscillations (alpha, delta, slow) are observed in humans, self-awareness and internal consciousness would be impaired if not abolished. These studies advance our understanding of anesthesia-induced unconsciousness and altered arousal and further establish principled neurophysiological markers of these states.	anesthesia; coherence; prefrontal cortex; propofol; thalamus	20170725	https://pubmed.ncbi.nlm.nih.gov/28743752
Tran, Ngoc Hieu; Zhang, Xianglilan; Xin, Lei; Shan, Baozhen; Li, Ming	De novo peptide sequencing by deep learning.	Proc Natl Acad Sci U S A	2017	Proc Natl Acad Sci U S A. 2017 Aug 1;114(31):8247-8252. doi: 10.1073/pnas.1705691114. Epub 2017 Jul 18.	De novo peptide sequencing from tandem MS data is the key technology in proteomics for the characterization of proteins, especially for new sequences, such as mAbs. In this study, we propose a deep neural network model, DeepNovo, for de novo peptide sequencing. DeepNovo architecture combines recent advances in convolutional neural networks and recurrent neural networks to learn features of tandem mass spectra, fragment ions, and sequence patterns of peptides. The networks are further integrated with local dynamic programming to solve the complex optimization task of de novo sequencing. We evaluated the method on a wide variety of species and found that DeepNovo considerably outperformed state of the art methods, achieving 7.7-22.9% higher accuracy at the amino acid level and 38.1-64.0% higher accuracy at the peptide level. We further used DeepNovo to automatically reconstruct the complete sequences of antibody light and heavy chains of mouse, achieving 97.5-100% coverage and 97.2-99.5% accuracy, without assisting databases. Moreover, DeepNovo is retrainable to adapt to any sources of data and provides a complete end-to-end training and prediction solution to the de novo sequencing problem. Not only does our study extend the deep learning revolution to a new field, but it also shows an innovative approach in solving optimization problems by using deep learning and dynamic programming.	MS; de novo sequencing; deep learning	20170718	https://pubmed.ncbi.nlm.nih.gov/28720701
Kirkpatrick, James; Pascanu, Razvan; Rabinowitz, Neil; Veness, Joel; Desjardins, Guillaume; Rusu, Andrei A; Milan, Kieran; Quan, John; Ramalho, Tiago; Grabska-Barwinska, Agnieszka; Hassabis, Demis; Clopath, Claudia; Kumaran, Dharshan; Hadsell, Raia	Overcoming catastrophic forgetting in neural networks.	Proc Natl Acad Sci U S A	2017	Proc Natl Acad Sci U S A. 2017 Mar 28;114(13):3521-3526. doi: 10.1073/pnas.1611835114. Epub 2017 Mar 14.	The ability to learn tasks in a sequential fashion is crucial to the development of artificial intelligence. Until now neural networks have not been capable of this and it has been widely thought that catastrophic forgetting is an inevitable feature of connectionist models. We show that it is possible to overcome this limitation and train networks that can maintain expertise on tasks that they have not experienced for a long time. Our approach remembers old tasks by selectively slowing down learning on the weights important for those tasks. We demonstrate our approach is scalable and effective by solving a set of classification tasks based on a hand-written digit dataset and by learning several Atari 2600 games sequentially.	artificial intelligence; continual learning; deep learning; stability plasticity; synaptic consolidation	20170314	https://pubmed.ncbi.nlm.nih.gov/28292907
Cuffey, Kurt M; Clow, Gary D; Steig, Eric J; Buizert, Christo; Fudge, T J; Koutnik, Michelle; Waddington, Edwin D; Alley, Richard B; Severinghaus, Jeffrey P	Deglacial temperature history of West Antarctica.	Proc Natl Acad Sci U S A	2016	Proc Natl Acad Sci U S A. 2016 Dec 13;113(50):14249-14254. doi: 10.1073/pnas.1609132113. Epub 2016 Nov 28.	The most recent glacial to interglacial transition constitutes a remarkable natural experiment for learning how Earth's climate responds to various forcings, including a rise in atmospheric CO2 This transition has left a direct thermal remnant in the polar ice sheets, where the exceptional purity and continual accumulation of ice permit analyses not possible in other settings. For Antarctica, the deglacial warming has previously been constrained only by the water isotopic composition in ice cores, without an absolute thermometric assessment of the isotopes' sensitivity to temperature. To overcome this limitation, we measured temperatures in a deep borehole and analyzed them together with ice-core data to reconstruct the surface temperature history of West Antarctica. The deglacial warming was [Formula: see text]C, approximately two to three times the global average, in agreement with theoretical expectations for Antarctic amplification of planetary temperature changes. Consistent with evidence from glacier retreat in Southern Hemisphere mountain ranges, the Antarctic warming was mostly completed by 15 kyBP, several millennia earlier than in the Northern Hemisphere. These results constrain the role of variable oceanic heat transport between hemispheres during deglaciation and quantitatively bound the direct influence of global climate forcings on Antarctic temperature. Although climate models perform well on average in this context, some recent syntheses of deglacial climate history have underestimated Antarctic warming and the models with lowest sensitivity can be discounted.	Antarctica; climate; glaciology; paleoclimate; temperature	20161128	https://pubmed.ncbi.nlm.nih.gov/27911783
Chen, Mo; Li, Bing; Guang, Jing; Wei, Linyu; Wu, Si; Liu, Yu; Zhang, Mingsha	Two subdivisions of macaque LIP process visual-oculomotor information differently.	Proc Natl Acad Sci U S A	2016	Proc Natl Acad Sci U S A. 2016 Oct 11;113(41):E6263-E6270. doi: 10.1073/pnas.1605879113. Epub 2016 Sep 28.	Although the cerebral cortex is thought to be composed of functionally distinct areas, the actual parcellation of area and assignment of function are still highly controversial. An example is the much-studied lateral intraparietal cortex (LIP). Despite the general agreement that LIP plays an important role in visual-oculomotor transformation, it remains unclear whether the area is primary sensory- or motor-related (the attention-intention debate). Although LIP has been considered as a functionally unitary area, its dorsal (LIPd) and ventral (LIPv) parts differ in local morphology and long-distance connectivity. In particular, LIPv has much stronger connections with two oculomotor centers, the frontal eye field and the deep layers of the superior colliculus, than does LIPd. Such anatomical distinctions imply that compared with LIPd, LIPv might be more involved in oculomotor processing. We tested this hypothesis physiologically with a memory saccade task and a gap saccade task. We found that LIP neurons with persistent memory activities in memory saccade are primarily provoked either by visual stimulation (vision-related) or by both visual and saccadic events (vision-saccade-related) in gap saccade. The distribution changes from predominantly vision-related to predominantly vision-saccade-related as the recording depth increases along the dorsal-ventral dimension. Consistently, the simultaneously recorded local field potential also changes from visual evoked to saccade evoked. Finally, local injection of muscimol (GABA agonist) in LIPv, but not in LIPd, dramatically decreases the proportion of express saccades. With these results, we conclude that LIPd and LIPv are more involved in visual and visual-saccadic processing, respectively.	electrophysiology; gap saccade task; inactivation; microinjection; visuomotor control	20160928	https://pubmed.ncbi.nlm.nih.gov/27681616
Esser, Steven K; Merolla, Paul A; Arthur, John V; Cassidy, Andrew S; Appuswamy, Rathinakumar; Andreopoulos, Alexander; Berg, David J; McKinstry, Jeffrey L; Melano, Timothy; Barch, Davis R; di Nolfo, Carmelo; Datta, Pallab; Amir, Arnon; Taba, Brian; Flickner, Myron D; Modha, Dharmendra S	Convolutional networks for fast, energy-efficient neuromorphic computing.	Proc Natl Acad Sci U S A	2016	Proc Natl Acad Sci U S A. 2016 Oct 11;113(41):11441-11446. doi: 10.1073/pnas.1604850113. Epub 2016 Sep 20.	Deep networks are now able to achieve human-level performance on a broad spectrum of recognition tasks. Independently, neuromorphic computing has now demonstrated unprecedented energy-efficiency through a new chip architecture based on spiking neurons, low precision synapses, and a scalable communication network. Here, we demonstrate that neuromorphic computing, despite its novel architectural primitives, can implement deep convolution networks that (i) approach state-of-the-art classification accuracy across eight standard datasets encompassing vision and speech, (ii) perform inference while preserving the hardware's underlying energy-efficiency and high throughput, running on the aforementioned datasets at between 1,200 and 2,600 frames/s and using between 25 and 275 mW (effectively >6,000 frames/s per Watt), and (iii) can be specified and trained using backpropagation with the same ease-of-use as contemporary deep learning. This approach allows the algorithmic power of deep learning to be merged with the efficiency of neuromorphic processors, bringing the promise of embedded, intelligent, brain-inspired computing one step closer.	TrueNorth; convolutional network; neural network; neuromorphic	20160920	https://pubmed.ncbi.nlm.nih.gov/27651489
Hirshorn, Elizabeth A; Li, Yuanning; Ward, Michael J; Richardson, R Mark; Fiez, Julie A; Ghuman, Avniel Singh	Decoding and disrupting left midfusiform gyrus activity during word reading.	Proc Natl Acad Sci U S A	2016	Proc Natl Acad Sci U S A. 2016 Jul 19;113(29):8162-7. doi: 10.1073/pnas.1604126113. Epub 2016 Jun 20.	The nature of the visual representation for words has been fiercely debated for over 150 y. We used direct brain stimulation, pre- and postsurgical behavioral measures, and intracranial electroencephalography to provide support for, and elaborate upon, the visual word form hypothesis. This hypothesis states that activity in the left midfusiform gyrus (lmFG) reflects visually organized information about words and word parts. In patients with electrodes placed directly in their lmFG, we found that disrupting lmFG activity through stimulation, and later surgical resection in one of the patients, led to impaired perception of whole words and letters. Furthermore, using machine-learning methods to analyze the electrophysiological data from these electrodes, we found that information contained in early lmFG activity was consistent with an orthographic similarity space. Finally, the lmFG contributed to at least two distinguishable stages of word processing, an early stage that reflects gist-level visual representation sensitive to orthographic statistics, and a later stage that reflects more precise representation sufficient for the individuation of orthographic word forms. These results provide strong support for the visual word form hypothesis and demonstrate that across time the lmFG is involved in multiple stages of orthographic representation.	electrical stimulation; fusiform gyrus; intracranial EEG; temporal dynamics; word reading	20160620	https://pubmed.ncbi.nlm.nih.gov/27325763
Ullman, Shimon; Assif, Liav; Fetaya, Ethan; Harari, Daniel	Atoms of recognition in human and computer vision.	Proc Natl Acad Sci U S A	2016	Proc Natl Acad Sci U S A. 2016 Mar 8;113(10):2744-9. doi: 10.1073/pnas.1513198113. Epub 2016 Feb 16.	Discovering the visual features and representations used by the brain to recognize objects is a central problem in the study of vision. Recently, neural network models of visual object recognition, including biological and deep network models, have shown remarkable progress and have begun to rival human performance in some challenging tasks. These models are trained on image examples and learn to extract features and representations and to use them for categorization. It remains unclear, however, whether the representations and learning processes discovered by current models are similar to those used by the human visual system. Here we show, by introducing and using minimal recognizable images, that the human visual system uses features and processes that are not used by current models and that are critical for recognition. We found by psychophysical studies that at the level of minimal recognizable images a minute change in the image can have a drastic effect on recognition, thus identifying features that are critical for the task. Simulations then showed that current models cannot explain this sensitivity to precise feature configurations and, more generally, do not learn to recognize minimal images at a human level. The role of the features shown here is revealed uniquely at the minimal level, where the contribution of each feature is essential. A full understanding of the learning and use of such features will extend our understanding of visual recognition and its cortical mechanisms and will enhance the capacity of computational models to learn from visual experience and to deal with recognition and detailed image interpretation.	computer vision; minimal images; object recognition; visual perception; visual representations	20160216	https://pubmed.ncbi.nlm.nih.gov/26884200
Shimizu, Katsuhiko; Amano, Taro; Bari, Md Rezaul; Weaver, James C; Arima, Jiro; Mori, Nobuhiro	Glassin, a histidine-rich protein from the siliceous skeletal system of the marine sponge Euplectella, directs silica polycondensation.	Proc Natl Acad Sci U S A	2015	Proc Natl Acad Sci U S A. 2015 Sep 15;112(37):11449-54. doi: 10.1073/pnas.1506968112. Epub 2015 Aug 10.	The hexactinellids are a diverse group of predominantly deep sea sponges that synthesize elaborate fibrous skeletal systems of amorphous hydrated silica. As a representative example, members of the genus Euplectella have proved to be useful model systems for investigating structure-function relationships in these hierarchically ordered siliceous network-like composites. Despite recent advances in understanding the mechanistic origins of damage tolerance in these complex skeletal systems, the details of their synthesis have remained largely unexplored. Here, we describe a previously unidentified protein, named "glassin," the main constituent in the water-soluble fraction of the demineralized skeletal elements of Euplectella. When combined with silicic acid solutions, glassin rapidly accelerates silica polycondensation over a pH range of 6-8. Glassin is characterized by high histidine content, and cDNA sequence analysis reveals that glassin shares no significant similarity with any other known proteins. The deduced amino acid sequence reveals that glassin consists of two similar histidine-rich domains and a connecting domain. Each of the histidine-rich domains is composed of three segments: an amino-terminal histidine and aspartic acid-rich sequence, a proline-rich sequence in the middle, and a histidine and threonine-rich sequence at the carboxyl terminus. Histidine always forms HX or HHX repeats, in which most of X positions are occupied by glycine, aspartic acid, or threonine. Recombinant glassin reproduces the silica precipitation activity observed in the native proteins. The highly modular composition of glassin, composed of imidazole, acidic, and hydroxyl residues, favors silica polycondensation and provides insights into the molecular mechanisms of skeletal formation in hexactinellid sponges.	Porifera; biomineral; fusion materials; organic-inorganic composite; silicon dioxide	20150810	https://pubmed.ncbi.nlm.nih.gov/26261346
Zhou, Tianyin; Shen, Ning; Yang, Lin; Abe, Namiko; Horton, John; Mann, Richard S; Bussemaker, Harmen J; Gordan, Raluca; Rohs, Remo	Quantitative modeling of transcription factor binding specificities using DNA shape.	Proc Natl Acad Sci U S A	2015	Proc Natl Acad Sci U S A. 2015 Apr 14;112(15):4654-9. doi: 10.1073/pnas.1422023112. Epub 2015 Mar 9.	DNA binding specificities of transcription factors (TFs) are a key component of gene regulatory processes. Underlying mechanisms that explain the highly specific binding of TFs to their genomic target sites are poorly understood. A better understanding of TF-DNA binding requires the ability to quantitatively model TF binding to accessible DNA as its basic step, before additional in vivo components can be considered. Traditionally, these models were built based on nucleotide sequence. Here, we integrated 3D DNA shape information derived with a high-throughput approach into the modeling of TF binding specificities. Using support vector regression, we trained quantitative models of TF binding specificity based on protein binding microarray (PBM) data for 68 mammalian TFs. The evaluation of our models included cross-validation on specific PBM array designs, testing across different PBM array designs, and using PBM-trained models to predict relative binding affinities derived from in vitro selection combined with deep sequencing (SELEX-seq). Our results showed that shape-augmented models compared favorably to sequence-based models. Although both k-mer and DNA shape features can encode interdependencies between nucleotide positions of the binding site, using DNA shape features reduced the dimensionality of the feature space. In addition, analyzing the feature weights of DNA shape-augmented models uncovered TF family-specific structural readout mechanisms that were not revealed by the DNA sequence. As such, this work combines knowledge from structural biology and genomics, and suggests a new path toward understanding TF binding and genome function.	DNA structure; protein binding microarray; protein-DNA recognition; statistical machine learning; support vector regression	20150309	https://pubmed.ncbi.nlm.nih.gov/25775564
Huys, Quentin J M; Lally, Niall; Faulkner, Paul; Eshel, Neir; Seifritz, Erich; Gershman, Samuel J; Dayan, Peter; Roiser, Jonathan P	Interplay of approximate planning strategies.	Proc Natl Acad Sci U S A	2015	Proc Natl Acad Sci U S A. 2015 Mar 10;112(10):3098-103. doi: 10.1073/pnas.1414219112. Epub 2015 Feb 9.	Humans routinely formulate plans in domains so complex that even the most powerful computers are taxed. To do so, they seem to avail themselves of many strategies and heuristics that efficiently simplify, approximate, and hierarchically decompose hard tasks into simpler subtasks. Theoretical and cognitive research has revealed several such strategies; however, little is known about their establishment, interaction, and efficiency. Here, we use model-based behavioral analysis to provide a detailed examination of the performance of human subjects in a moderately deep planning task. We find that subjects exploit the structure of the domain to establish subgoals in a way that achieves a nearly maximal reduction in the cost of computing values of choices, but then combine partial searches with greedy local steps to solve subtasks, and maladaptively prune the decision trees of subtasks in a reflexive manner upon encountering salient losses. Subjects come idiosyncratically to favor particular sequences of actions to achieve subgoals, creating novel complex actions or "options."	hierarchical reinforcement learning; memoization; planning; pruning	20150209	https://pubmed.ncbi.nlm.nih.gov/25675480
Shema, Reut; Kulicke, Ruth; Cowley, Glenn S; Stein, Rachael; Root, David E; Heiman, Myriam	Synthetic lethal screening in the mammalian central nervous system identifies Gpx6 as a modulator of Huntington's disease.	Proc Natl Acad Sci U S A	2015	Proc Natl Acad Sci U S A. 2015 Jan 6;112(1):268-72. doi: 10.1073/pnas.1417231112. Epub 2014 Dec 22.	Huntington's disease, the most common inherited neurodegenerative disease, is characterized by a dramatic loss of deep-layer cortical and striatal neurons, as well as morbidity in midlife. Human genetic studies led to the identification of the causative gene, huntingtin. Recent genomic advances have also led to the identification of hundreds of potential interacting partners for huntingtin protein and many hypotheses as to the molecular mechanisms whereby mutant huntingtin leads to cellular dysfunction and death. However, the multitude of possible interacting partners and cellular pathways affected by mutant huntingtin has complicated efforts to understand the etiology of this disease, and to date no curative therapeutic exists. To address the general problem of identifying the disease-phenotype contributing genes from a large number of correlative studies, here we develop a synthetic lethal screening methodology for the mammalian central nervous system, called SLIC, for synthetic lethal in the central nervous system. Applying SLIC to the study of Huntington's disease, we identify the age-regulated glutathione peroxidase 6 (Gpx6) gene as a modulator of mutant huntingtin toxicity and show that overexpression of Gpx6 can dramatically alleviate both behavioral and molecular phenotypes associated with a mouse model of Huntington's disease. SLIC can, in principle, be used in the study of any neurodegenerative disease for which a mouse model exists, promising to reveal modulators of neurodegenerative disease in an unbiased fashion, akin to screens in simpler model organisms.	Huntington's disease; glutathione peroxidase; pooled screening; striatum; synthetic lethality	20141222	https://pubmed.ncbi.nlm.nih.gov/25535386
Lepousez, Gabriel; Nissant, Antoine; Bryant, Alex K; Gheusi, Gilles; Greer, Charles A; Lledo, Pierre-Marie	Olfactory learning promotes input-specific synaptic plasticity in adult-born neurons.	Proc Natl Acad Sci U S A	2014	Proc Natl Acad Sci U S A. 2014 Sep 23;111(38):13984-9. doi: 10.1073/pnas.1404991111. Epub 2014 Sep 4.	The production of new neurons in the olfactory bulb (OB) through adulthood is a major mechanism of structural and functional plasticity underlying learning-induced circuit remodeling. The recruitment of adult-born OB neurons depends not only on sensory input but also on the context in which the olfactory stimulus is received. Among the multiple steps of adult neurogenesis, the integration and survival of adult-born neurons are both strongly influenced by olfactory learning. Conversely, optogenetic stimulation of adult-born neurons has been shown to specifically improve olfactory learning and long-term memory. However, the nature of the circuit and the synaptic mechanisms underlying this reciprocal influence are not yet known. Here, we showed that olfactory learning increases the spine density in a region-restricted manner along the dendritic tree of adult-born granule cells (GCs). Anatomical and electrophysiological analysis of adult-born GCs showed that olfactory learning promotes a remodeling of both excitatory and inhibitory inputs selectively in the deep dendritic domain. Circuit mapping revealed that the malleable dendritic portion of adult-born neurons receives excitatory inputs mostly from the regions of the olfactory cortex that project back to the OB. Finally, selective optogenetic stimulation of olfactory cortical projections to the OB showed that learning strengthens these inputs onto adult-born GCs. We conclude that learning promotes input-specific synaptic plasticity in adult-born neurons, which reinforces the top-down influence from the olfactory cortex to early stages of olfactory information processing.	cortico-bulbar projections; glutamate; inhibitory circuits; piriform cortex; sensory systems	20140904	https://pubmed.ncbi.nlm.nih.gov/25189772
Schweizer, Nadine; Pupe, Stefano; Arvidsson, Emma; Nordenankar, Karin; Smith-Anttila, Casey J A; Mahmoudi, Souha; Andren, Anna; Dumas, Sylvie; Rajagopalan, Aparna; Levesque, Daniel; Leao, Richardson N; Wallen-Mackenzie, Asa	Limiting glutamate transmission in a Vglut2-expressing subpopulation of the subthalamic nucleus is sufficient to cause hyperlocomotion.	Proc Natl Acad Sci U S A	2014	Proc Natl Acad Sci U S A. 2014 May 27;111(21):7837-42. doi: 10.1073/pnas.1323499111. Epub 2014 May 12.	The subthalamic nucleus (STN) is a key area of the basal ganglia circuitry regulating movement. We identified a subpopulation of neurons within this structure that coexpresses Vglut2 and Pitx2, and by conditional targeting of this subpopulation we reduced Vglut2 expression levels in the STN by 40%, leaving Pitx2 expression intact. This reduction diminished, yet did not eliminate, glutamatergic transmission in the substantia nigra pars reticulata and entopeduncular nucleus, two major targets of the STN. The knockout mice displayed hyperlocomotion and decreased latency in the initiation of movement while preserving normal gait and balance. Spatial cognition, social function, and level of impulsive choice also remained undisturbed. Furthermore, these mice showed reduced dopamine transporter binding and slower dopamine clearance in vivo, suggesting that Vglut2-expressing cells in the STN regulate dopaminergic transmission. Our results demonstrate that altering the contribution of a limited population within the STN is sufficient to achieve results similar to STN lesions and high-frequency stimulation, but with fewer side effects.	Parkinson disease; deep brain stimulation; optogenetics; striatum; vesicular transporter	20140512	https://pubmed.ncbi.nlm.nih.gov/24821804
Culbertson, Jennifer; Adger, David	Language learners privilege structured meaning over surface frequency.	Proc Natl Acad Sci U S A	2014	Proc Natl Acad Sci U S A. 2014 Apr 22;111(16):5842-7. doi: 10.1073/pnas.1320525111. Epub 2014 Mar 31.	Although it is widely agreed that learning the syntax of natural languages involves acquiring structure-dependent rules, recent work on acquisition has nevertheless attempted to characterize the outcome of learning primarily in terms of statistical generalizations about surface distributional information. In this paper we investigate whether surface statistical knowledge or structural knowledge of English is used to infer properties of a novel language under conditions of impoverished input. We expose learners to artificial-language patterns that are equally consistent with two possible underlying grammars--one more similar to English in terms of the linear ordering of words, the other more similar on abstract structural grounds. We show that learners' grammatical inferences overwhelmingly favor structural similarity over preservation of superficial order. Importantly, the relevant shared structure can be characterized in terms of a universal preference for isomorphism in the mapping from meanings to utterances. Whereas previous empirical support for this universal has been based entirely on data from cross-linguistic language samples, our results suggest it may reflect a deep property of the human cognitive system--a property that, together with other structure-sensitive principles, constrains the acquisition of linguistic knowledge.	artificial grammar learning; learning biases; semantic scope; transitional probabilities; typology	20140331	https://pubmed.ncbi.nlm.nih.gov/24706789
Chen, Xixi; Yan, Jiusheng; Aldrich, Richard W	BK channel opening involves side-chain reorientation of multiple deep-pore residues.	Proc Natl Acad Sci U S A	2014	Proc Natl Acad Sci U S A. 2014 Jan 7;111(1):E79-88. doi: 10.1073/pnas.1321697111. Epub 2013 Dec 23.	Three deep-pore locations, L312, A313, and A316, were identified in a scanning mutagenesis study of the BK (Ca(2+)-activated, large-conductance K(+)) channel S6 pore, where single aspartate substitutions led to constitutively open mutant channels (L312D, A313D, and A316D). To understand the mechanisms of the constitutive openness of these mutant channels, we individually mutated these three sites into the other 18 amino acids. We found that charged or polar side-chain substitutions at each of the sites resulted in constitutively open mutant BK channels, with high open probability at negative voltages, as well as a loss of voltage and Ca(2+) dependence. Given the fact that multiple pore residues in BK displayed side-chain hydrophilicity-dependent constitutive openness, we propose that BK channel opening involves structural rearrangement of the deep-pore region, where multiple residues undergo conformational changes that may increase the exposure of their side chains to the polar environment of the pore.	gating; ion channel pore; structure-function	20131223	https://pubmed.ncbi.nlm.nih.gov/24367115
Chaumont, Joseph; Guyon, Nicolas; Valera, Antoine M; Dugue, Guillaume P; Popa, Daniela; Marcaggi, Paikan; Gautheron, Vanessa; Reibel-Foisset, Sophie; Dieudonne, Stephane; Stephan, Aline; Barrot, Michel; Cassel, Jean-Christophe; Dupont, Jean-Luc; Doussau, Frederic; Poulain, Bernard; Selimi, Fekrije; Lena, Clement; Isope, Philippe	Clusters of cerebellar Purkinje cells control their afferent climbing fiber discharge.	Proc Natl Acad Sci U S A	2013	Proc Natl Acad Sci U S A. 2013 Oct 1;110(40):16223-8. doi: 10.1073/pnas.1302310110. Epub 2013 Sep 17.	Climbing fibers, the projections from the inferior olive to the cerebellar cortex, carry sensorimotor error and clock signals that trigger motor learning by controlling cerebellar Purkinje cell synaptic plasticity and discharge. Purkinje cells target the deep cerebellar nuclei, which are the output of the cerebellum and include an inhibitory GABAergic projection to the inferior olive. This pathway identifies a potential closed loop in the olivo-cortico-nuclear network. Therefore, sets of Purkinje cells may phasically control their own climbing fiber afferents. Here, using in vitro and in vivo recordings, we describe a genetically modified mouse model that allows the specific optogenetic control of Purkinje cell discharge. Tetrode recordings in the cerebellar nuclei demonstrate that focal stimulations of Purkinje cells strongly inhibit spatially restricted sets of cerebellar nuclear neurons. Strikingly, such stimulations trigger delayed climbing-fiber input signals in the stimulated Purkinje cells. Therefore, our results demonstrate that Purkinje cells phasically control the discharge of their own olivary afferents and thus might participate in the regulation of cerebellar motor learning.	complex spikes; motor control; olivo-cerebellar loop	20130917	https://pubmed.ncbi.nlm.nih.gov/24046366
Oller, D Kimbrough; Buder, Eugene H; Ramsdell, Heather L; Warlaumont, Anne S; Chorna, Lesya; Bakeman, Roger	Functional flexibility of infant vocalization and the emergence of language.	Proc Natl Acad Sci U S A	2013	Proc Natl Acad Sci U S A. 2013 Apr 16;110(16):6318-23. doi: 10.1073/pnas.1300337110. Epub 2013 Apr 2.	We report on the emergence of functional flexibility in vocalizations of human infants. This vastly underappreciated capability becomes apparent when prelinguistic vocalizations express a full range of emotional content--positive, neutral, and negative. The data show that at least three types of infant vocalizations (squeals, vowel-like sounds, and growls) occur with this full range of expression by 3-4 mo of age. In contrast, infant cry and laughter, which are species-specific signals apparently homologous to vocal calls in other primates, show functional stability, with cry overwhelmingly expressing negative and laughter positive emotional states. Functional flexibility is a sine qua non in spoken language, because all words or sentences can be produced as expressions of varying emotional states and because learning conventional "meanings" requires the ability to produce sounds that are free of any predetermined function. Functional flexibility is a defining characteristic of language, and empirically it appears before syntax, word learning, and even earlier-developing features presumed to be critical to language (e.g., joint attention, syllable imitation, and canonical babbling). The appearance of functional flexibility early in the first year of human life is a critical step in the development of vocal language and may have been a critical step in the evolution of human language, preceding protosyntax and even primitive single words. Such flexible affect expression of vocalizations has not yet been reported for any nonhuman primate but if found to occur would suggest deep roots for functional flexibility of vocalization in our primate heritage.		20130402	https://pubmed.ncbi.nlm.nih.gov/23550164
Gourley, Shannon L; Swanson, Andrew M; Jacobs, Andrea M; Howell, Jessica L; Mo, Michelle; Dileone, Ralph J; Koleske, Anthony J; Taylor, Jane R	Action control is mediated by prefrontal BDNF and glucocorticoid receptor binding.	Proc Natl Acad Sci U S A	2012	Proc Natl Acad Sci U S A. 2012 Dec 11;109(50):20714-9. doi: 10.1073/pnas.1208342109. Epub 2012 Nov 26.	Stressor exposure biases decision-making strategies from those based on the relationship between actions and their consequences to others restricted by stimulus-response associations. Chronic stressor exposure also desensitizes glucocorticoid receptors (GR) and diminishes motivation to acquire food reinforcement, although causal relationships are largely not established. We show that a history of chronic exposure to the GR ligand corticosterone or acute posttraining GR blockade with RU38486 makes rodents less able to perform actions based on their consequences. Thus, optimal GR binding is necessary for the consolidation of new response-outcome learning. In contrast, medial prefrontal (but not striatal) BDNF can account for stress-related amotivation, in that selective medial prefrontal cortical Bdnf knockdown decreases break-point ratios in a progressive-ratio task. Knockdown also increases vulnerability to RU38486. Despite the role of BDNF in dendritic spine reorganization, deep-layer spine remodeling does not obviously parallel progressive-ratio response patterns, but treatment with the Na(+)-channel inhibitor riluzole reverses corticosteroid-induced motivational deficits and restores prefrontal BDNF expression after corticosterone. We argue that when prefrontal neurotrophin systems are compromised, and GR-mediated hypothalamic-pituitary-adrenal axis feedback is desensitized (as in the case of chronic stress hormone exposure), amotivation and inflexible maladaptive response strategies that contribute to stress-related mood disorders result.		20121126	https://pubmed.ncbi.nlm.nih.gov/23185000
Hertzman, Clyde	Putting the concept of biological embedding in historical perspective.	Proc Natl Acad Sci U S A	2012	Proc Natl Acad Sci U S A. 2012 Oct 16;109 Suppl 2:17160-7. doi: 10.1073/pnas.1202203109. Epub 2012 Oct 8.	This paper describes evidence that led to the concept of biological embedding and research approaches designed to elucidates its mechanisms. Biological embedding occurs when experience gets under the skin and alters human biological and developmental processes; when systematic differences in experience in different social environments in society lead to systematically different biological and developmental states; when these differences are stable and long term; and, finally, when they have the capacity to influence health, well-being, learning, or behavior over the life course. Biological embedding emerged from insights in population health on the unique characteristics of socioeconomic gradients: Ubiquity in poor and postscarcity societies alike; gradient seen regardless of whether socioeconomic status is measured by income, education, or occupation; cutting widely across health, well-being, learning, and behavior outcomes; replicating itself on new conditions entering society; and, often, showing that flatter gradients mean better overall societal outcomes. Most important, the gradient begins the life course as a gradient in developmental health, suggesting that the emergence of a multifaceted resilience/vulnerability early in life is the best place to look for evidence of biological embedding. To understand its character, the metaphor of the "archeology of biological embedding" has been used, wherein the surficial stratum of the "dig" is experience and behavior, the shallow stratum is organ system and cellular function, and the deep stratum is gene function. We are now ready to address the fundamental question of biological embedding: How do early childhood environments work together with genetic variation and epigenetic regulation to generate gradients in health and human development across the life course?		20121008	https://pubmed.ncbi.nlm.nih.gov/23045673
Maiz, Jaione; Karakossian, Movses H; Pakaprot, Narawut; Robleto, Karla; Thompson, Richard F; Otis, Thomas S	Prolonging the postcomplex spike pause speeds eyeblink conditioning.	Proc Natl Acad Sci U S A	2012	Proc Natl Acad Sci U S A. 2012 Oct 9;109(41):16726-30. doi: 10.1073/pnas.1214274109. Epub 2012 Sep 17.	Climbing fiber input to the cerebellum is believed to serve as a teaching signal during associative, cerebellum-dependent forms of motor learning. However, it is not understood how this neural pathway coordinates changes in cerebellar circuitry during learning. Here, we use pharmacological manipulations to prolong the postcomplex spike pause, a component of the climbing fiber signal in Purkinje neurons, and show that these manipulations enhance the rate of learning in classical eyelid conditioning. Our findings elucidate an unappreciated aspect of the climbing fiber teaching signal, and are consistent with a model in which convergent postcomplex spike pauses drive learning-related plasticity in the deep cerebellar nucleus. They also suggest a physiological mechanism that could modulate motor learning rates.		20120917	https://pubmed.ncbi.nlm.nih.gov/22988089
Glimcher, Paul W	Understanding dopamine and reinforcement learning: the dopamine reward prediction error hypothesis.	Proc Natl Acad Sci U S A	2011	Proc Natl Acad Sci U S A. 2011 Sep 13;108 Suppl 3:15647-54. doi: 10.1073/pnas.1014269108. Epub 2011 Mar 9.	A number of recent advances have been achieved in the study of midbrain dopaminergic neurons. Understanding these advances and how they relate to one another requires a deep understanding of the computational models that serve as an explanatory framework and guide ongoing experimental inquiry. This intertwining of theory and experiment now suggests very clearly that the phasic activity of the midbrain dopamine neurons provides a global mechanism for synaptic modification. These synaptic modifications, in turn, provide the mechanistic underpinning for a specific class of reinforcement learning mechanisms that now seem to underlie much of human and animal behavior. This review describes both the critical empirical findings that are at the root of this conclusion and the fantastic theoretical advances from which this conclusion is drawn.		20110309	https://pubmed.ncbi.nlm.nih.gov/21389268
Mitsuhashi, Takayuki; Yonemoto, Junzo; Sone, Hideko; Kosuge, Yasuhiro; Kosaki, Kenjiro; Takahashi, Takao	In utero exposure to dioxin causes neocortical dysgenesis through the actions of p27Kip1.	Proc Natl Acad Sci U S A	2010	Proc Natl Acad Sci U S A. 2010 Sep 14;107(37):16331-5. doi: 10.1073/pnas.1002960107. Epub 2010 Aug 30.	Dioxins have been reported to exert various adverse effects, including cell-cycle dysregulation in vitro and impairment of spatial learning and memory after in utero exposure in rodents. Furthermore, children born to mothers who are exposed to dioxin analogs polychlorinated dibenzofurans or polychlorinated biphenyls have developmental impairments in cognitive functions. Here, we show that in utero exposure to dioxins in mice alters differentiation patterns of neural progenitors and leads to decreased numbers of non-GABAergic neurons and thinner deep neocortical layers. This reduction in number of non-GABAergic neurons is assumed to be caused by accumulation of cyclin-dependent kinase inhibitor p27(Kip1) in nuclei of neural progenitors. Lending support to this presumption, mice lacking p27(Kip1) are not susceptible to in utero dioxin exposure. These results show that environmental pollutants may affect neocortical histogenesis through alterations of functions of specific gene(s)/protein(s) (in our case, dioxins), exerting adverse effects by altering functions of p27(Kip1).		20100830	https://pubmed.ncbi.nlm.nih.gov/20805476
Walter, Joy T; Khodakhah, Kamran	The advantages of linear information processing for cerebellar computation.	Proc Natl Acad Sci U S A	2009	Proc Natl Acad Sci U S A. 2009 Mar 17;106(11):4471-6. doi: 10.1073/pnas.0812348106. Epub 2009 Feb 20.	Purkinje cells can encode the strength of parallel fiber inputs in their firing by using 2 fundamentally different mechanisms, either as pauses or as linear increases in firing rate. It is not clear which of these 2 encoding mechanisms is used by the cerebellum. We used the pattern-recognition capacity of Purkinje cells based on the Marr-Albus-Ito theory of cerebellar learning to evaluate the suitability of the linear algorithm for cerebellar information processing. Here, we demonstrate the simplicity and versatility of pattern recognition in Purkinje cells linearly encoding the strength of parallel fiber inputs in their firing rate. In contrast to encoding patterns with pauses, Purkinje cells using the linear algorithm could recognize a large number of both synchronous and asynchronous input patterns in the presence or absence of inhibitory synaptic transmission. Under all conditions, the number of patterns recognized by Purkinje cells using the linear algorithm was greater than that achieved by encoding information in pauses. Linear encoding of information also allows neurons of deep cerebellar nuclei to use a simple averaging mechanism to significantly increase the computational capacity of the cerebellum. We propose that the virtues of the linear encoding mechanism make it well suited for cerebellar computation.		20090220	https://pubmed.ncbi.nlm.nih.gov/19234116
Wada, Norio; Kishimoto, Yasushi; Watanabe, Dai; Kano, Masanobu; Hirano, Tomoo; Funabiki, Kazuo; Nakanishi, Shigetada	Conditioned eyeblink learning is formed and stored without cerebellar granule cell transmission.	Proc Natl Acad Sci U S A	2007	Proc Natl Acad Sci U S A. 2007 Oct 16;104(42):16690-5. doi: 10.1073/pnas.0708165104. Epub 2007 Oct 8.	Classical conditioning of the eyeblink reflex is elicited by paired presentation of a conditioned stimulus and an unconditioned stimulus and represents a basic form of cerebellum-dependent motor learning. Purkinje cells and the deep nuclei receive convergent information of conditioned stimulus and unconditioned stimulus through the mossy fiber and climbing fiber projections, respectively. To explore the relative importance of these neural circuits and the underlying mechanism in associative eyeblink learning, we adopted a novel gene-manipulating technique, termed reversible neurotransmission blocking (RNB). In this technology, cerebellar granule cells specifically expressed neurotransmission-blocking tetanus toxin in a doxycycline (DOX)-dependent manner. Extracellular recording of Purkinje cells in awake RNB mice revealed that DOX treatment and withdrawal reversibly turned off and on simple spikes elicited by granule cell inputs, respectively, without interference with complex spikes evoked by climbing fiber inputs. Blockade of granule cell inputs to Purkinje cells abolished eyeblink conditioned responses (CRs) in a DOX-dependent manner. Importantly, when granule cell inputs recovered by removal of DOX, normal CRs were immediately produced in the DOX-treated, CR-negative RNB mice from the beginning of reconditioning. This learning process in RNB mice during DOX treatment was completely abolished by bilateral lesion of the interpositus nucleus before eyeblink conditioning. These results indicate that the convergent information at the interpositus nucleus is critical for acquisition and storage of learning in intimate association with the Purkinje cell circuit for expression of CRs in eyeblink conditioning.		20071008	https://pubmed.ncbi.nlm.nih.gov/17923666
Wilson, Brian M; Cox, Charles L	Absence of metabotropic glutamate receptor-mediated plasticity in the neocortex of fragile X mice.	Proc Natl Acad Sci U S A	2007	Proc Natl Acad Sci U S A. 2007 Feb 13;104(7):2454-9. doi: 10.1073/pnas.0610875104. Epub 2007 Feb 7.	Fragile X syndrome is a common heritable form of mental retardation in humans. Recent neuroanatomical studies indicate an apparent immature appearance of neurons in fragile X syndrome patients and fragile X mental retardation protein (FMRP)-knockout mice, an animal model of this condition. In this work, we investigated possible alterations in synaptic plasticity in the neocortex of FMRP-knockout mice. Extracellular field potentials were recorded from the deep-layer visual neocortex. Long-term potentiation (LTP) was severely attenuated in brain slices from knockout mice relative to that observed in slices from wild-type mice. Considering that neocortical LTP can involve both NMDA receptor-dependent and -independent mechanisms, we attempted to distinguish the nature of LTP attenuated in the knockout condition. In slices from wild-type mice, LTP was partially attenuated by the NMDA receptor antagonist 3-[(+/-)-2-carboxypiperazin-4-yl]-propyl-1-phosphate (CPP); however, the general metabotropic glutamate receptor (mGluR) antagonist alpha-methyl-4-carboxyphenylglycine (MCPG) strongly attenuated LTP, resulting in a response indistinguishable from that observed in slices from knockout mice. The selective mGluR5 antagonist 2-methyl-6-(phenylethynyl)-pyridine (MPEP) attenuated LTP to a similar degree as did MCPG in wild-type slices, but MPEP did not alter the reduced potentiation in knockout slices. Our results suggest that LTP in layer V visual neocortex depends primarily on mGluR5 activation. Our data also indicate that mGluR5-mediated synaptic plasticity is absent in the neocortex of FMRP-knockout mice. Such an alteration may contribute to the cognitive and learning deficits exhibited in these mice as well as in fragile X syndrome.		20070207	https://pubmed.ncbi.nlm.nih.gov/17287348
McKinstry, Jeffrey L; Edelman, Gerald M; Krichmar, Jeffrey L	A cerebellar model for predictive motor control tested in a brain-based device.	Proc Natl Acad Sci U S A	2006	Proc Natl Acad Sci U S A. 2006 Feb 28;103(9):3387-92. doi: 10.1073/pnas.0511281103. Epub 2006 Feb 17.	The cerebellum is known to be critical for accurate adaptive control and motor learning. We propose here a mechanism by which the cerebellum may replace reflex control with predictive control. This mechanism is embedded in a learning rule (the delayed eligibility trace rule) in which synapses onto a Purkinje cell or onto a cell in the deep cerebellar nuclei become eligible for plasticity only after a fixed delay from the onset of suprathreshold presynaptic activity. To investigate the proposal that the cerebellum is a general-purpose predictive controller guided by a delayed eligibility trace rule, a computer model based on the anatomy and dynamics of the cerebellum was constructed. It contained components simulating cerebellar cortex and deep cerebellar nuclei, and it received input from a middle temporal visual area and the inferior olive. The model was incorporated in a real-world brain-based device (BBD) built on a Segway robotic platform that learned to traverse curved paths. The BBD learned which visual motion cues predicted impending collisions and used this experience to avoid path boundaries. During learning, the BBD adapted its velocity and turning rate to successfully traverse various curved paths. By examining neuronal activity and synaptic changes during this behavior, we found that the cerebellar circuit selectively responded to motion cues in specific receptive fields of simulated middle temporal visual areas. The system described here prompts several hypotheses about the relationship between perception and motor control and may be useful in the development of general-purpose motor learning systems for machines.		20060217	https://pubmed.ncbi.nlm.nih.gov/16488974
Sausbier, M; Hu, H; Arntz, C; Feil, S; Kamm, S; Adelsberger, H; Sausbier, U; Sailer, C A; Feil, R; Hofmann, F; Korth, M; Shipston, M J; Knaus, H-G; Wolfer, D P; Pedroarena, C M; Storm, J F; Ruth, P	Cerebellar ataxia and Purkinje cell dysfunction caused by Ca2+-activated K+ channel deficiency.	Proc Natl Acad Sci U S A	2004	Proc Natl Acad Sci U S A. 2004 Jun 22;101(25):9474-8. doi: 10.1073/pnas.0401702101. Epub 2004 Jun 11.	Malfunctions of potassium channels are increasingly implicated as causes of neurological disorders. However, the functional roles of the large-conductance voltage- and Ca(2+)-activated K(+) channel (BK channel), a unique calcium, and voltage-activated potassium channel type have remained elusive. Here we report that mice lacking BK channels (BK(-/-)) show cerebellar dysfunction in the form of abnormal conditioned eye-blink reflex, abnormal locomotion and pronounced deficiency in motor coordination, which are likely consequences of cerebellar learning deficiency. At the cellular level, the BK(-/-) mice showed a dramatic reduction in spontaneous activity of the BK(-/-) cerebellar Purkinje neurons, which generate the sole output of the cerebellar cortex and, in addition, enhanced short-term depression at the only output synapses of the cerebellar cortex, in the deep cerebellar nuclei. The impairing cellular effects caused by the lack of postsynaptic BK channels were found to be due to depolarization-induced inactivation of the action potential mechanism. These results identify previously unknown roles of potassium channels in mammalian cerebellar function and motor control. In addition, they provide a previously undescribed animal model of cerebellar ataxia.		20040611	https://pubmed.ncbi.nlm.nih.gov/15194823
Doyon, Julien; Song, Allen W; Karni, Avi; Lalonde, Francois; Adams, Michelle M; Ungerleider, Leslie G	Experience-dependent changes in cerebellar contributions to motor sequence learning.	Proc Natl Acad Sci U S A	2002	Proc Natl Acad Sci U S A. 2002 Jan 22;99(2):1017-22. doi: 10.1073/pnas.022615199.	Studies in experimental animals and humans have stressed the role of the cerebellum in motor skill learning. Yet, the relative importance of the cerebellar cortex and deep nuclei, as well as the nature of the dynamic functional changes occurring between these and other motor-related structures during learning, remains in dispute. Using functional magnetic resonance imaging and a motor sequence learning paradigm in humans, we found evidence of an experience-dependent shift of activation from the cerebellar cortex to the dentate nucleus during early learning, and from a cerebellar-cortical to a striatal-cortical network with extended practice. The results indicate that intrinsic modulation within the cerebellum, in concert with activation of motor-related cortical regions, serves to set up a procedurally acquired sequence of movements that is then maintained elsewhere in the brain.		?	https://pubmed.ncbi.nlm.nih.gov/11805340
Bao, Shaowen; Chen, Lu; Kim, Jeansok J; Thompson, Richard F	Cerebellar cortical inhibition and classical eyeblink conditioning.	Proc Natl Acad Sci U S A	2002	Proc Natl Acad Sci U S A. 2002 Feb 5;99(3):1592-7. doi: 10.1073/pnas.032655399. Epub 2002 Jan 22.	The cerebellum is considered a brain structure in which memories for learned motor responses (e.g., conditioned eyeblink responses) are stored. Within the cerebellum, however, the relative importance of the cortex and the deep nuclei in motor learning/memory is not entirely clear. In this study, we show that the cerebellar cortex exerts both basal and stimulus-activated inhibition to the deep nuclei. Sequential application of a gamma-aminobutyric acid type A receptor (GABA(A)R) agonist and a noncompetitive GABA(A)R antagonist allows selective blockade of stimulus-activated inhibition. By using the same sequential agonist and antagonist methods in behaving animals, we demonstrate that the conditioned response (CR) expression and timing are completely dissociable and involve different inhibitory inputs; although the basal inhibition modulates CR expression, the conditioned stimulus-activated inhibition is required for the proper timing of the CR. In addition, complete blockade of cerebellar deep nuclear GABA(A)Rs prevents CR acquisition. Together, these results suggest that different aspects of the memories for eyeblink CRs are encoded in the cerebellar cortex and the cerebellar deep nuclei.		20020122	https://pubmed.ncbi.nlm.nih.gov/11805298
Henke, K; Weber, B; Kneifel, S; Wieser, H G; Buck, A	Human hippocampus associates information in memory.	Proc Natl Acad Sci U S A	1999	Proc Natl Acad Sci U S A. 1999 May 11;96(10):5884-9. doi: 10.1073/pnas.96.10.5884.	The hippocampal formation, one of the most complex and vulnerable brain structures, is recognized as a crucial brain area subserving human long-term memory. Yet, its specific functions in memory are controversial. Recent experimental results suggest that the hippocampal contribution to human memory is limited to episodic memory, novelty detection, semantic (deep) processing of information, and spatial memory. We measured the regional cerebral blood flow by positron-emission tomography while healthy volunteers learned pairs of words with different learning strategies. These led to different forms of learning, allowing us to test the degree to which they challenge hippocampal function. Neither novelty detection nor depth of processing activated the hippocampal formation as much as semantically associating the primarily unrelated words in memory. This is compelling evidence for another function of the human hippocampal formation in memory: establishing semantic associations.		?	https://pubmed.ncbi.nlm.nih.gov/10318979
Logan, C G; Grafton, S T	Functional anatomy of human eyeblink conditioning determined with regional cerebral glucose metabolism and positron-emission tomography.	Proc Natl Acad Sci U S A	1995	Proc Natl Acad Sci U S A. 1995 Aug 1;92(16):7500-4. doi: 10.1073/pnas.92.16.7500.	Relative cerebral glucose metabolism was examined with positron-emission tomography (PET) as a measure of neuronal activation during performance of the classically conditioned eyeblink response in 12 young adult subjects. Each subject received three sessions: (i) a control session with PET scan in which unpaired presentations of the tone conditioned stimulus and corneal airpuff unconditioned stimulus were administered, (ii) a paired training session to allow associative learning to occur, and (iii) a paired test session with PET scan. Brain regions exhibiting learning-related activation were identified as those areas that showed significant differences in glucose metabolism between the unpaired control condition and well-trained state in the 9 subjects who met the learning criterion. Areas showing significant activation included bilateral sites in the inferior cerebellar cortex/deep nuclei, anterior cerebellar vermis, contralateral cerebellar cortex and pontine tegmentum, ipsilateral inferior thalamus/red nucleus, ipsilateral hippocampal formation, ipsilateral lateral temporal cortex, and bilateral ventral striatum. Among all subjects, including those who did not meet the learning criterion, metabolic changes in ipsilateral cerebellar nuclei, bilateral cerebellar cortex, anterior vermis, contralateral pontine tegmentum, ipsilateral hippocampal formation, and bilateral striatum correlated with degree of learning. The localization to cerebellum and its associated brainstem circuitry is consistent with neurobiological studies in the rabbit model of eyeblink classical conditioning and neuropsychological studies in brain-damaged humans. In addition, these data support a role for the hippocampus in conditioning and suggest that the ventral striatum may also be involved.		?	https://pubmed.ncbi.nlm.nih.gov/7638220
