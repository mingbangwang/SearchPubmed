Authors	Title	Journal	Year	Publication_citation	Abstract	Keywords	Date_epublished	PMID
Shi, Jie-Yi; Wang, Xiaodong; Ding, Guang-Yu; Dong, Zhou; Han, Jing; Guan, Zehui; Ma, Li-Jie; Zheng, Yuxuan; Zhang, Lei; Yu, Guan-Zhen; Wang, Xiao-Ying; Ding, Zhen-Bin; Ke, Ai-Wu; Yang, Haoqing; Wang, Liming; Ai, Lirong; Cao, Ya; Zhou, Jian; Fan, Jia; Liu, Xiyang; Gao, Qiang	Exploring prognostic indicators in the pathological images of hepatocellular carcinoma based on deep learning.	Gut	2020	Gut. 2020 Sep 30. pii: gutjnl-2020-320930. doi: 10.1136/gutjnl-2020-320930.	OBJECTIVE: Tumour pathology contains rich information, including tissue structure and cell morphology, that reflects disease progression and patient survival. However, phenotypic information is subtle and complex, making the discovery of prognostic indicators from pathological images challenging. DESIGN: An interpretable, weakly supervised deep learning framework incorporating prior knowledge was proposed to analyse hepatocellular carcinoma (HCC) and explore new prognostic phenotypes on pathological whole-slide images (WSIs) from the Zhongshan cohort of 1125 HCC patients (2451 WSIs) and TCGA cohort of 320 HCC patients (320 WSIs). A 'tumour risk score (TRS)' was established to evaluate patient outcomes, and then risk activation mapping (RAM) was applied to visualise the pathological phenotypes of TRS. The multi-omics data of The Cancer Genome Atlas(TCGA) HCC were used to assess the potential pathogenesis underlying TRS. RESULTS: Survival analysis revealed that TRS was an independent prognosticator in both the Zhongshan cohort (p<0.0001) and TCGA cohort (p=0.0003). The predictive ability of TRS was superior to and independent of clinical staging systems, and TRS could evenly stratify patients into up to five groups with significantly different prognoses. Notably, sinusoidal capillarisation, prominent nucleoli and karyotheca, the nucleus/cytoplasm ratio and infiltrating inflammatory cells were identified as the main underlying features of TRS. The multi-omics data of TCGA HCC hint at the relevance of TRS to tumour immune infiltration and genetic alterations such as the FAT3 and RYR2 mutations. CONCLUSION: Our deep learning framework is an effective and labour-saving method for decoding pathological images, providing a valuable means for HCC risk stratification and precise patient treatment.	cancer; liver	20200930	https://pubmed.ncbi.nlm.nih.gov/32998878
Sirinukunwattana, Korsuk; Domingo, Enric; Richman, Susan D; Redmond, Keara L; Blake, Andrew; Verrill, Clare; Leedham, Simon J; Chatzipli, Aikaterini; Hardy, Claire; Whalley, Celina M; Wu, Chieh-Hsi; Beggs, Andrew D; McDermott, Ultan; Dunne, Philip D; Meade, Angela; Walker, Steven M; Murray, Graeme I; Samuel, Leslie; Seymour, Matthew; Tomlinson, Ian; Quirke, Phil; Maughan, Timothy; Rittscher, Jens; Koelzer, Viktor H	Image-based consensus molecular subtype (imCMS) classification of colorectal cancer using deep learning.	Gut	2021	Gut. 2021 Mar;70(3):544-554. doi: 10.1136/gutjnl-2019-319866. Epub 2020 Jul 20.	OBJECTIVE: Complex phenotypes captured on histological slides represent the biological processes at play in individual cancers, but the link to underlying molecular classification has not been clarified or systematised. In colorectal cancer (CRC), histological grading is a poor predictor of disease progression, and consensus molecular subtypes (CMSs) cannot be distinguished without gene expression profiling. We hypothesise that image analysis is a cost-effective tool to associate complex features of tissue organisation with molecular and outcome data and to resolve unclassifiable or heterogeneous cases. In this study, we present an image-based approach to predict CRC CMS from standard H&E sections using deep learning. DESIGN: Training and evaluation of a neural network were performed using a total of n=1206 tissue sections with comprehensive multi-omic data from three independent datasets (training on FOCUS trial, n=278 patients; test on rectal cancer biopsies, GRAMPIAN cohort, n=144 patients; and The Cancer Genome Atlas (TCGA), n=430 patients). Ground truth CMS calls were ascertained by matching random forest and single sample predictions from CMS classifier. RESULTS: Image-based CMS (imCMS) accurately classified slides in unseen datasets from TCGA (n=431 slides, AUC)=0.84) and rectal cancer biopsies (n=265 slides, AUC=0.85). imCMS spatially resolved intratumoural heterogeneity and provided secondary calls correlating with bioinformatic prediction from molecular data. imCMS classified samples previously unclassifiable by RNA expression profiling, reproduced the expected correlations with genomic and epigenetic alterations and showed similar prognostic associations as transcriptomic CMS. CONCLUSION: This study shows that a prediction of RNA expression classifiers can be made from H&E images, opening the door to simple, cheap and reliable biological stratification within routine workflows.	colorectal pathology; computerised image analysis; molecular pathology	20200720	https://pubmed.ncbi.nlm.nih.gov/32690604
Ebigbo, Alanna; Mendel, Robert; Probst, Andreas; Manzeneder, Johannes; Prinz, Friederike; de Souza, Luis A Jr; Papa, Joao; Palm, Christoph; Messmann, Helmut	Real-time use of artificial intelligence in the evaluation of cancer in Barrett's oesophagus.	Gut	2020	Gut. 2020 Apr;69(4):615-616. doi: 10.1136/gutjnl-2019-319460. Epub 2019 Sep 20.	?	Barrett's oesophagus; artificial intelligence; computer-aided diagnosis; deep learning; endoscopy	20190920	https://pubmed.ncbi.nlm.nih.gov/31541004
Guimaraes, Pedro; Keller, Andreas; Fehlmann, Tobias; Lammert, Frank; Casper, Markus	Deep-learning based detection of gastric precancerous conditions.	Gut	2020	Gut. 2020 Jan;69(1):4-6. doi: 10.1136/gutjnl-2019-319347. Epub 2019 Aug 2.	?	artificial intelligence; atrophic gastritis; computer-aided detection; computer-aided diagnosis	20190802	https://pubmed.ncbi.nlm.nih.gov/31375599
N Kalimuthu, Sangeetha; Wilson, Gavin W; Grant, Robert C; Seto, Matthew; O'Kane, Grainne; Vajpeyi, Rajkumar; Notta, Faiyaz; Gallinger, Steven; Chetty, Runjan	Morphological classification of pancreatic ductal adenocarcinoma that predicts molecular subtypes and correlates with clinical outcome.	Gut	2020	Gut. 2020 Feb;69(2):317-328. doi: 10.1136/gutjnl-2019-318217. Epub 2019 Jun 14.	INTRODUCTION: Transcriptional analyses have identified several distinct molecular subtypes in pancreatic ductal adenocarcinoma (PDAC) that have prognostic and potential therapeutic significance. However, to date, an indepth, clinicomorphological correlation of these molecular subtypes has not been performed. We sought to identify specific morphological patterns to compare with known molecular subtypes, interrogate their biological significance, and furthermore reappraise the current grading system in PDAC. DESIGN: We first assessed 86 primary, chemotherapy-naive PDAC resection specimens with matched RNA-Seq data for specific, reproducible morphological patterns. Differential expression was applied to the gene expression data using the morphological features. We next compared the differentially expressed gene signatures with previously published molecular subtypes. Overall survival (OS) was correlated with the morphological and molecular subtypes. RESULTS: We identified four morphological patterns that segregated into two components ('gland forming' and 'non-gland forming') based on the presence/absence of well-formed glands. A morphological cut-off (>/=40% 'non-gland forming') was established using RNA-Seq data, which identified two groups (A and B) with gene signatures that correlated with known molecular subtypes. There was a significant difference in OS between the groups. The morphological groups remained significantly prognostic within cancers that were moderately differentiated and classified as 'classical' using RNA-Seq. CONCLUSION: Our study has demonstrated that PDACs can be morphologically classified into distinct and biologically relevant categories which predict known molecular subtypes. These results provide the basis for an improved taxonomy of PDAC, which may lend itself to future treatment strategies and the development of deep learning models.	basal subtype; classical subtype; deep learning; pancreatic ductal adenocarcinoma; pattern-based morphological classification system	20190614	https://pubmed.ncbi.nlm.nih.gov/31201285
Wu, Lianlian; Zhang, Jun; Zhou, Wei; An, Ping; Shen, Lei; Liu, Jun; Jiang, Xiaoda; Huang, Xu; Mu, Ganggang; Wan, Xinyue; Lv, Xiaoguang; Gao, Juan; Cui, Ning; Hu, Shan; Chen, Yiyun; Hu, Xiao; Li, Jiangjie; Chen, Di; Gong, Dexin; He, Xinqi; Ding, Qianshan; Zhu, Xiaoyun; Li, Suqin; Wei, Xiao; Li, Xia; Wang, Xuemei; Zhou, Jie; Zhang, Mengjiao; Yu, Hong Gang	Randomised controlled trial of WISENSE, a real-time quality improving system for monitoring blind spots during esophagogastroduodenoscopy.	Gut	2019	Gut. 2019 Dec;68(12):2161-2169. doi: 10.1136/gutjnl-2018-317366. Epub 2019 Mar 11.	OBJECTIVE: Esophagogastroduodenoscopy (EGD) is the pivotal procedure in the diagnosis of upper gastrointestinal lesions. However, there are significant variations in EGD performance among endoscopists, impairing the discovery rate of gastric cancers and precursor lesions. The aim of this study was to construct a real-time quality improving system, WISENSE, to monitor blind spots, time the procedure and automatically generate photodocumentation during EGD and thus raise the quality of everyday endoscopy. DESIGN: WISENSE system was developed using the methods of deep convolutional neural networks and deep reinforcement learning. Patients referred because of health examination, symptoms, surveillance were recruited from Renmin hospital of Wuhan University. Enrolled patients were randomly assigned to groups that underwent EGD with or without the assistance of WISENSE. The primary end point was to ascertain if there was a difference in the rate of blind spots between WISENSE-assisted group and the control group. RESULTS: WISENSE monitored blind spots with an accuracy of 90.40% in real EGD videos. A total of 324 patients were recruited and randomised. 153 and 150 patients were analysed in the WISENSE and control group, respectively. Blind spot rate was lower in WISENSE group compared with the control (5.86% vs 22.46%, p<0.001), and the mean difference was -15.39% (95% CI -19.23 to -11.54). There was no significant adverse event. CONCLUSIONS: WISENSE significantly reduced blind spot rate of EGD procedure and could be used to improve the quality of everyday endoscopy. TRIAL REGISTRATION NUMBER: ChiCTR1800014809; Results.	endoscopy	20190311	https://pubmed.ncbi.nlm.nih.gov/30858305
Wang, Pu; Berzin, Tyler M; Glissen Brown, Jeremy Romek; Bharadwaj, Shishira; Becq, Aymeric; Xiao, Xun; Liu, Peixi; Li, Liangping; Song, Yan; Zhang, Di; Li, Yi; Xu, Guangre; Tu, Mengtian; Liu, Xiaogang	Real-time automatic detection system increases colonoscopic polyp and adenoma detection rates: a prospective randomised controlled study.	Gut	2019	Gut. 2019 Oct;68(10):1813-1819. doi: 10.1136/gutjnl-2018-317500. Epub 2019 Feb 27.	OBJECTIVE: The effect of colonoscopy on colorectal cancer mortality is limited by several factors, among them a certain miss rate, leading to limited adenoma detection rates (ADRs). We investigated the effect of an automatic polyp detection system based on deep learning on polyp detection rate and ADR. DESIGN: In an open, non-blinded trial, consecutive patients were prospectively randomised to undergo diagnostic colonoscopy with or without assistance of a real-time automatic polyp detection system providing a simultaneous visual notice and sound alarm on polyp detection. The primary outcome was ADR. RESULTS: Of 1058 patients included, 536 were randomised to standard colonoscopy, and 522 were randomised to colonoscopy with computer-aided diagnosis. The artificial intelligence (AI) system significantly increased ADR (29.1%vs20.3%, p<0.001) and the mean number of adenomas per patient (0.53vs0.31, p<0.001). This was due to a higher number of diminutive adenomas found (185vs102; p<0.001), while there was no statistical difference in larger adenomas (77vs58, p=0.075). In addition, the number of hyperplastic polyps was also significantly increased (114vs52, p<0.001). CONCLUSIONS: In a low prevalent ADR population, an automatic polyp detection system during colonoscopy resulted in a significant increase in the number of diminutive adenomas detected, as well as an increase in the rate of hyperplastic polyps. The cost-benefit ratio of such effects has to be determined further. TRIAL REGISTRATION NUMBER: ChiCTR-DDD-17012221; Results.	colonoscopy; colorectal cancer screening; computerised image analysis	20190227	https://pubmed.ncbi.nlm.nih.gov/30814121
Ebigbo, Alanna; Mendel, Robert; Probst, Andreas; Manzeneder, Johannes; Souza, Luis Antonio de Jr; Papa, Joao P; Palm, Christoph; Messmann, Helmut	Computer-aided diagnosis using deep learning in the evaluation of early oesophageal adenocarcinoma.	Gut	2019	Gut. 2019 Jul;68(7):1143-1145. doi: 10.1136/gutjnl-2018-317573. Epub 2018 Dec 3.	?	endoscopy	20181203	https://pubmed.ncbi.nlm.nih.gov/30510110
Wang, Kun; Lu, Xue; Zhou, Hui; Gao, Yongyan; Zheng, Jian; Tong, Minghui; Wu, Changjun; Liu, Changzhu; Huang, Liping; Jiang, Tian'an; Meng, Fankun; Lu, Yongping; Ai, Hong; Xie, Xiao-Yan; Yin, Li-Ping; Liang, Ping; Tian, Jie; Zheng, Rongqin	Deep learning Radiomics of shear wave elastography significantly improved diagnostic performance for assessing liver fibrosis in chronic hepatitis B: a prospective multicentre study.	Gut	2019	Gut. 2019 Apr;68(4):729-741. doi: 10.1136/gutjnl-2018-316204. Epub 2018 May 5.	OBJECTIVE: We aimed to evaluate the performance of the newly developed deep learning Radiomics of elastography (DLRE) for assessing liver fibrosis stages. DLRE adopts the radiomic strategy for quantitative analysis of the heterogeneity in two-dimensional shear wave elastography (2D-SWE) images. DESIGN: A prospective multicentre study was conducted to assess its accuracy in patients with chronic hepatitis B, in comparison with 2D-SWE, aspartate transaminase-to-platelet ratio index and fibrosis index based on four factors, by using liver biopsy as the reference standard. Its accuracy and robustness were also investigated by applying different number of acquisitions and different training cohorts, respectively. Data of 654 potentially eligible patients were prospectively enrolled from 12 hospitals, and finally 398 patients with 1990 images were included. Analysis of receiver operating characteristic (ROC) curves was performed to calculate the optimal area under the ROC curve (AUC) for cirrhosis (F4), advanced fibrosis (>/=F3) and significance fibrosis (>/=F2). RESULTS: AUCs of DLRE were 0.97 for F4 (95% CI 0.94 to 0.99), 0.98 for >/=F3 (95% CI 0.96 to 1.00) and 0.85 (95% CI 0.81 to 0.89) for >/=F2, which were significantly better than other methods except 2D-SWE in >/=F2. Its diagnostic accuracy improved as more images (especially >/=3 images) were acquired from each individual. No significant variation of the performance was found if different training cohorts were applied. CONCLUSION: DLRE shows the best overall performance in predicting liver fibrosis stages compared with 2D-SWE and biomarkers. It is valuable and practical for the non-invasive accurate diagnosis of liver fibrosis stages in HBV-infected patients. TRIAL REGISTRATION NUMBER: NCT02313649; Post-results.	cirrhosis; hepatitis B; ultrasonography	20180505	https://pubmed.ncbi.nlm.nih.gov/29730602
Byrne, Michael F; Chapados, Nicolas; Soudan, Florian; Oertel, Clemens; Linares Perez, Milagros; Kelly, Raymond; Iqbal, Nadeem; Chandelier, Florent; Rex, Douglas K	Real-time differentiation of adenomatous and hyperplastic diminutive colorectal polyps during analysis of unaltered videos of standard colonoscopy using a deep learning model.	Gut	2019	Gut. 2019 Jan;68(1):94-100. doi: 10.1136/gutjnl-2017-314547. Epub 2017 Oct 24.	BACKGROUND: In general, academic but not community endoscopists have demonstrated adequate endoscopic differentiation accuracy to make the 'resect and discard' paradigm for diminutive colorectal polyps workable. Computer analysis of video could potentially eliminate the obstacle of interobserver variability in endoscopic polyp interpretation and enable widespread acceptance of 'resect and discard'. STUDY DESIGN AND METHODS: We developed an artificial intelligence (AI) model for real-time assessment of endoscopic video images of colorectal polyps. A deep convolutional neural network model was used. Only narrow band imaging video frames were used, split equally between relevant multiclasses. Unaltered videos from routine exams not specifically designed or adapted for AI classification were used to train and validate the model. The model was tested on a separate series of 125 videos of consecutively encountered diminutive polyps that were proven to be adenomas or hyperplastic polyps. RESULTS: The AI model works with a confidence mechanism and did not generate sufficient confidence to predict the histology of 19 polyps in the test set, representing 15% of the polyps. For the remaining 106 diminutive polyps, the accuracy of the model was 94% (95% CI 86% to 97%), the sensitivity for identification of adenomas was 98% (95% CI 92% to 100%), specificity was 83% (95% CI 67% to 93%), negative predictive value 97% and positive predictive value 90%. CONCLUSIONS: An AI model trained on endoscopic video can differentiate diminutive adenomas from hyperplastic polyps with high accuracy. Additional study of this programme in a live patient clinical trial setting to address resect and discard is planned.	colorectal adenomas; endoscopic polypectomy; polyp	20171024	https://pubmed.ncbi.nlm.nih.gov/29066576
